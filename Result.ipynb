{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Да не посрамим землю русскую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "import re\n",
    "import string\n",
    "from joblib import dump, load\n",
    "import tensorflow.keras as keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import gc\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = pd.read_excel('data/dnn_class_predictions.xlsx', index_col = 0)\n",
    "train_data_set.columns = list(map(str, train_data_set.columns))\n",
    "\n",
    "prediction_data = pd.read_excel('data/test.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vars = ['Protein_(g)','Lipid_Tot_(g)','Carbohydrt_(g)']\n",
    "label = 'label'\n",
    "data = train_data_set[['Shrt_Desc','Protein_(g)','Lipid_Tot_(g)','Carbohydrt_(g)','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, r2_score,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "food_names = train_data_set['Shrt_Desc'].copy()\n",
    "\n",
    "def listToString(s):  \n",
    "    str1 = \"\"  \n",
    "    for ele in s:  \n",
    "        str1 = str1 + ele + ' '\n",
    "    return str1.lower()\n",
    "\n",
    "food_names = food_names.map(lambda x : x.split(','))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "#helpf = X_train\n",
    "\n",
    "food_names = food_names.map(lambda x : [lemmatizer.lemmatize(i,  wordnet.VERB) for i in x])\n",
    "food_names = food_names.map(lambda x : [word for word in x if word not in stop_words])\n",
    "food_names = food_names.map(lambda x : [nltk.word_tokenize(i) for i in x] )\n",
    "food_names = food_names.map(lambda x : [item for f in x for item in f])\n",
    "\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "food_names = food_names.map(lambda x : [i.translate(table) for i in x] )\n",
    "food_names = food_names.map(lambda x : list(filter(None, x)))\n",
    "food_names = food_names.map(lambda x : [re.sub(r'\\d', '', i) for i in x])\n",
    "food_names = food_names.map(lambda x : list(filter(None, x)))\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "corpus = []\n",
    "\n",
    "food_names.map(lambda x : corpus.append(listToString(x)))\n",
    "\n",
    "bag_of_words = count_vectorizer.fit_transform(corpus)\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "names_clf_train_x = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "names_clf_train_x\n",
    "\n",
    "train_data_set = pd.concat([train_data_set, names_clf_train_x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(train_data_set.drop('label', axis = 1), train_data_set[label], test_size = 0.2, random_state = 42)\n",
    "# train.to_excel('test_preds/clf3-trainset.xlsx')\n",
    "# test.to_excel('test_preds/clf3-testset.xlsx')\n",
    "# train_labels.to_csv('test_preds/clf3-train_labelsset.xlsx')\n",
    "# test_labels.to_csv('test_preds/clf3-test_labelsset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columnselector',\n",
       "                 ColumnSelector(cols=['Protein_(g)', 'Lipid_Tot_(g)',\n",
       "                                      'Carbohydrt_(g)'],\n",
       "                                drop_axis=False)),\n",
       "                ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=20, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=50, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 50, random_state = 42, max_depth=20)\n",
    "\n",
    "rf_pipe = make_pipeline(ColumnSelector(cols=real_vars),\n",
    "                        MinMaxScaler(),\n",
    "                        rf)\n",
    "rf_pipe.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, ..., 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pred=rf_pipe.predict(test)\n",
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691557618649854"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_labels,res_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6204, 5)\n",
      "(1552, 5)\n"
     ]
    }
   ],
   "source": [
    "pred_proba=rf_pipe.predict_proba(test)\n",
    "train_proba=rf_pipe.predict_proba(train)\n",
    "pd.DataFrame(train_proba).to_csv('test_preds/rf_train_pred.scv', index = False)\n",
    "pd.DataFrame(pred_proba).to_csv('test_preds/rf_test_pred.scv', index = False)\n",
    "print(train_proba.shape)\n",
    "print(pred_proba.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columnselector',\n",
       "                 ColumnSelector(cols=['Protein_(g)', 'Lipid_Tot_(g)',\n",
       "                                      'Carbohydrt_(g)'],\n",
       "                                drop_axis=False)),\n",
       "                ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                            criterion='friedman_mse', init=None,\n",
       "                                            learning_rate=0.01, loss='deviance',\n",
       "                                            max_depth=8, max_features=None,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=100,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='deprecated',\n",
       "                                            random_state=4, subsample=1.0,\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb=GradientBoostingClassifier(n_estimators=100, learning_rate=0.01,max_depth=8, random_state=4)\n",
    "\n",
    "gb_pipe = make_pipeline(ColumnSelector(cols=real_vars),\n",
    "                        MinMaxScaler(),\n",
    "                        gb)\n",
    "gb_pipe.fit(train,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbp=gb_pipe.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06170717, 0.06043455, 0.03994117, 0.8311683 , 0.00674882],\n",
       "       [0.0744772 , 0.7605725 , 0.06188676, 0.09486197, 0.00820157],\n",
       "       [0.06883886, 0.06772047, 0.0444289 , 0.81148297, 0.0075288 ],\n",
       "       ...,\n",
       "       [0.08489497, 0.08332212, 0.71463582, 0.10785148, 0.00929562],\n",
       "       [0.06631818, 0.06501806, 0.04298341, 0.81839953, 0.00728082],\n",
       "       [0.77334193, 0.06931407, 0.06278445, 0.08710392, 0.00745564]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_proba=gb_pipe.predict_proba(test)\n",
    "gb_train_proba=gb_pipe.predict_proba(train)\n",
    "pd.DataFrame(gb_train_proba).to_csv('test_preds/gb_train_pred.scv', index = False)\n",
    "pd.DataFrame(gb_proba).to_csv('test_preds/gb_test_pred.scv', index = False)\n",
    "gb_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_proba.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488022137106498"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_labels,gbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res_rf = rf_pipe.predict_proba(prediction_data)\n",
    "pred_res_gb = gb_pipe.predict_proba(prediction_data)\n",
    "\n",
    "pd.DataFrame(pred_res_rf).to_csv('main-preds/rf_main_pred.scv', index = False)\n",
    "pd.DataFrame(pred_res_gb).to_csv('main-preds/gb_main_pred.scv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras as keras\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# def learning_rate_reduction():\n",
    "#     return keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
    "#                                             patience=4, \n",
    "#                                             verbose=1, \n",
    "#                                             factor=0.4, \n",
    "#                                             min_lr=0.00002,\n",
    "#                                             mode='max')\n",
    "# def r2_keras(y_true, y_pred):\n",
    "#     from keras import backend as K\n",
    "#     SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "#     SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "#     return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# mcp_save = keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_acc', verbose = 1, mode='max')\n",
    "\n",
    "# def create_keras_model():\n",
    "#     model = keras.models.Sequential([\n",
    "#         keras.layers.BatchNormalization(input_shape = (3,)),\n",
    "#         keras.layers.Dense(5, activation=\"relu\"),\n",
    "#         keras.layers.BatchNormalization(),\n",
    "#         keras.layers.Dropout(0.2),\n",
    "#         keras.layers.Dense(1, activation=\"relu\"),\n",
    "#         keras.layers.Dense(5, activation=\"softmax\")])\n",
    "\n",
    "#     keras.callbacks.LambdaCallback(on_epoch_end = lambda: model.load_weights('.mdl_wts.hdf5'))\n",
    "\n",
    "#     model.compile(optimizer = keras.optimizers.Adam(),\n",
    "#                   loss = \"sparse_categorical_crossentropy\",\n",
    "#                   metrics = ['accuracy', r2_keras])\n",
    "#     return model\n",
    "\n",
    "# dnn_clf = KerasClassifier(build_fn = create_keras_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6204 samples, validate on 1552 samples\n",
      "Epoch 1/15\n",
      "6048/6204 [============================>.] - ETA: 0s - loss: 1.6450 - acc: 0.2682 - r2_keras: -11.3950\n",
      "Epoch 00001: val_acc improved from -inf to 0.33312, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 2s 249us/sample - loss: 1.6428 - acc: 0.2663 - r2_keras: -11.3973 - val_loss: 1.5592 - val_acc: 0.3331 - val_r2_keras: -11.5389\n",
      "Epoch 2/15\n",
      "5920/6204 [===========================>..] - ETA: 0s - loss: 1.4206 - acc: 0.3301 - r2_keras: -11.4529\n",
      "Epoch 00002: val_acc improved from 0.33312 to 0.51611, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 168us/sample - loss: 1.4147 - acc: 0.3348 - r2_keras: -11.4377 - val_loss: 1.3479 - val_acc: 0.5161 - val_r2_keras: -11.5264\n",
      "Epoch 3/15\n",
      "6080/6204 [============================>.] - ETA: 0s - loss: 1.2421 - acc: 0.5331 - r2_keras: -11.5794\n",
      "Epoch 00003: val_acc improved from 0.51611 to 0.55606, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 173us/sample - loss: 1.2404 - acc: 0.5345 - r2_keras: -11.5282 - val_loss: 1.1818 - val_acc: 0.5561 - val_r2_keras: -11.5169\n",
      "Epoch 4/15\n",
      "5824/6204 [===========================>..] - ETA: 0s - loss: 1.1274 - acc: 0.5580 - r2_keras: -11.4363\n",
      "Epoch 00004: val_acc improved from 0.55606 to 0.56443, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 175us/sample - loss: 1.1238 - acc: 0.5603 - r2_keras: -11.4175 - val_loss: 1.0856 - val_acc: 0.5644 - val_r2_keras: -11.4723\n",
      "Epoch 5/15\n",
      "5888/6204 [===========================>..] - ETA: 0s - loss: 1.0660 - acc: 0.5662 - r2_keras: -11.5118\n",
      "Epoch 00005: val_acc improved from 0.56443 to 0.56701, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 169us/sample - loss: 1.0655 - acc: 0.5677 - r2_keras: -11.4741 - val_loss: 1.0239 - val_acc: 0.5670 - val_r2_keras: -11.7071\n",
      "Epoch 6/15\n",
      "6112/6204 [============================>.] - ETA: 0s - loss: 1.0193 - acc: 0.5697 - r2_keras: -11.5322\n",
      "Epoch 00006: val_acc improved from 0.56701 to 0.57023, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 185us/sample - loss: 1.0195 - acc: 0.5688 - r2_keras: -11.5285 - val_loss: 0.9835 - val_acc: 0.5702 - val_r2_keras: -11.6860\n",
      "Epoch 7/15\n",
      "6016/6204 [============================>.] - ETA: 0s - loss: 1.0003 - acc: 0.5711 - r2_keras: -11.5326\n",
      "Epoch 00007: val_acc did not improve from 0.57023\n",
      "6204/6204 [==============================] - 1s 177us/sample - loss: 0.9980 - acc: 0.5719 - r2_keras: -11.5816 - val_loss: 0.9623 - val_acc: 0.5677 - val_r2_keras: -11.5431\n",
      "Epoch 8/15\n",
      "6112/6204 [============================>.] - ETA: 0s - loss: 0.9714 - acc: 0.5726 - r2_keras: -11.6126\n",
      "Epoch 00008: val_acc did not improve from 0.57023\n",
      "6204/6204 [==============================] - 1s 172us/sample - loss: 0.9719 - acc: 0.5724 - r2_keras: -11.6270 - val_loss: 0.9385 - val_acc: 0.5696 - val_r2_keras: -11.7407\n",
      "Epoch 9/15\n",
      "6144/6204 [============================>.] - ETA: 0s - loss: 0.9481 - acc: 0.5731 - r2_keras: -11.4500\n",
      "Epoch 00009: val_acc improved from 0.57023 to 0.57088, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 170us/sample - loss: 0.9487 - acc: 0.5730 - r2_keras: -11.4353 - val_loss: 0.9218 - val_acc: 0.5709 - val_r2_keras: -11.7565\n",
      "Epoch 10/15\n",
      "5856/6204 [===========================>..] - ETA: 0s - loss: 0.9360 - acc: 0.5710 - r2_keras: -11.5330\n",
      "Epoch 00010: val_acc improved from 0.57088 to 0.57474, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 174us/sample - loss: 0.9384 - acc: 0.5690 - r2_keras: -11.5054 - val_loss: 0.9081 - val_acc: 0.5747 - val_r2_keras: -11.6515\n",
      "Epoch 11/15\n",
      "5824/6204 [===========================>..] - ETA: 0s - loss: 0.9323 - acc: 0.5778 - r2_keras: -11.7942\n",
      "Epoch 00011: val_acc did not improve from 0.57474\n",
      "6204/6204 [==============================] - 1s 171us/sample - loss: 0.9339 - acc: 0.5780 - r2_keras: -11.7131 - val_loss: 0.9023 - val_acc: 0.5747 - val_r2_keras: -11.6637\n",
      "Epoch 12/15\n",
      "5856/6204 [===========================>..] - ETA: 0s - loss: 0.9192 - acc: 0.5782 - r2_keras: -11.5575\n",
      "Epoch 00012: val_acc did not improve from 0.57474\n",
      "6204/6204 [==============================] - 1s 170us/sample - loss: 0.9177 - acc: 0.5804 - r2_keras: -11.4919 - val_loss: 0.8942 - val_acc: 0.5728 - val_r2_keras: -11.9110\n",
      "Epoch 13/15\n",
      "6112/6204 [============================>.] - ETA: 0s - loss: 0.9124 - acc: 0.5803 - r2_keras: -11.5076\n",
      "Epoch 00013: val_acc improved from 0.57474 to 0.57668, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 171us/sample - loss: 0.9121 - acc: 0.5804 - r2_keras: -11.5426 - val_loss: 0.8833 - val_acc: 0.5767 - val_r2_keras: -11.7136\n",
      "Epoch 14/15\n",
      "6016/6204 [============================>.] - ETA: 0s - loss: 0.9073 - acc: 0.5813 - r2_keras: -11.5017\n",
      "Epoch 00014: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 170us/sample - loss: 0.9097 - acc: 0.5808 - r2_keras: -11.5007 - val_loss: 0.8791 - val_acc: 0.5728 - val_r2_keras: -11.7705\n",
      "Epoch 15/15\n",
      "5856/6204 [===========================>..] - ETA: 0s - loss: 0.9029 - acc: 0.5832 - r2_keras: -11.6913\n",
      "Epoch 00015: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 161us/sample - loss: 0.9039 - acc: 0.5832 - r2_keras: -11.6511 - val_loss: 0.8811 - val_acc: 0.5735 - val_r2_keras: -11.6359\n",
      "Train on 6204 samples, validate on 1552 samples\n",
      "Epoch 1/15\n",
      "6080/6204 [============================>.] - ETA: 0s - loss: 1.5852 - acc: 0.2630 - r2_keras: -11.1470\n",
      "Epoch 00001: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 134us/sample - loss: 1.5838 - acc: 0.2631 - r2_keras: -11.1174 - val_loss: 1.5485 - val_acc: 0.5245 - val_r2_keras: -11.0573\n",
      "Epoch 2/15\n",
      "5824/6204 [===========================>..] - ETA: 0s - loss: 1.4630 - acc: 0.3735 - r2_keras: -11.0273\n",
      "Epoch 00002: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 84us/sample - loss: 1.4604 - acc: 0.3815 - r2_keras: -11.1012 - val_loss: 1.4246 - val_acc: 0.5535 - val_r2_keras: -11.2568\n",
      "Epoch 3/15\n",
      "6016/6204 [============================>.] - ETA: 0s - loss: 1.3270 - acc: 0.5301 - r2_keras: -11.1508\n",
      "Epoch 00003: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 89us/sample - loss: 1.3252 - acc: 0.5292 - r2_keras: -11.1541 - val_loss: 1.2676 - val_acc: 0.5548 - val_r2_keras: -11.0663\n",
      "Epoch 4/15\n",
      "5952/6204 [===========================>..] - ETA: 0s - loss: 1.2214 - acc: 0.5427 - r2_keras: -11.2538\n",
      "Epoch 00004: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 92us/sample - loss: 1.2183 - acc: 0.5429 - r2_keras: -11.1732 - val_loss: 1.1670 - val_acc: 0.5586 - val_r2_keras: -11.2086\n",
      "Epoch 5/15\n",
      "6080/6204 [============================>.] - ETA: 0s - loss: 1.1597 - acc: 0.5502 - r2_keras: -11.1525\n",
      "Epoch 00005: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 88us/sample - loss: 1.1586 - acc: 0.5496 - r2_keras: -11.1300 - val_loss: 1.1155 - val_acc: 0.5644 - val_r2_keras: -11.4019\n",
      "Epoch 6/15\n",
      "5696/6204 [==========================>...] - ETA: 0s - loss: 1.1196 - acc: 0.5639 - r2_keras: -11.0971\n",
      "Epoch 00006: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 85us/sample - loss: 1.1222 - acc: 0.5596 - r2_keras: -11.1301 - val_loss: 1.0815 - val_acc: 0.5760 - val_r2_keras: -11.7625\n",
      "Epoch 7/15\n",
      "5952/6204 [===========================>..] - ETA: 0s - loss: 1.0959 - acc: 0.5607 - r2_keras: -11.2438\n",
      "Epoch 00007: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 90us/sample - loss: 1.0955 - acc: 0.5614 - r2_keras: -11.2570 - val_loss: 1.0557 - val_acc: 0.5754 - val_r2_keras: -11.2754\n",
      "Epoch 8/15\n",
      "5504/6204 [=========================>....] - ETA: 0s - loss: 1.0712 - acc: 0.5683 - r2_keras: -11.3139\n",
      "Epoch 00008: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 86us/sample - loss: 1.0699 - acc: 0.5662 - r2_keras: -11.2643 - val_loss: 1.0333 - val_acc: 0.5754 - val_r2_keras: -11.2225\n",
      "Epoch 9/15\n",
      "5952/6204 [===========================>..] - ETA: 0s - loss: 1.0491 - acc: 0.5680 - r2_keras: -11.1624\n",
      "Epoch 00009: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 82us/sample - loss: 1.0499 - acc: 0.5683 - r2_keras: -11.1709 - val_loss: 1.0157 - val_acc: 0.5754 - val_r2_keras: -11.4696\n",
      "Epoch 10/15\n",
      "5952/6204 [===========================>..] - ETA: 0s - loss: 1.0328 - acc: 0.5721 - r2_keras: -11.1377\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 111us/sample - loss: 1.0331 - acc: 0.5709 - r2_keras: -11.1818 - val_loss: 1.0015 - val_acc: 0.5760 - val_r2_keras: -11.2716\n",
      "Epoch 11/15\n",
      "5696/6204 [==========================>...] - ETA: 0s - loss: 1.0184 - acc: 0.5702 - r2_keras: -11.1731\n",
      "Epoch 00011: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 84us/sample - loss: 1.0210 - acc: 0.5711 - r2_keras: -11.2416 - val_loss: 0.9949 - val_acc: 0.5760 - val_r2_keras: -11.3438\n",
      "Epoch 12/15\n",
      "5824/6204 [===========================>..] - ETA: 0s - loss: 1.0175 - acc: 0.5716 - r2_keras: -11.2791\n",
      "Epoch 00012: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 97us/sample - loss: 1.0182 - acc: 0.5719 - r2_keras: -11.2173 - val_loss: 0.9895 - val_acc: 0.5760 - val_r2_keras: -11.1812\n",
      "Epoch 13/15\n",
      "6144/6204 [============================>.] - ETA: 0s - loss: 1.0070 - acc: 0.5721 - r2_keras: -11.2253\n",
      "Epoch 00013: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 90us/sample - loss: 1.0059 - acc: 0.5721 - r2_keras: -11.1868 - val_loss: 0.9845 - val_acc: 0.5741 - val_r2_keras: -11.5329\n",
      "Epoch 14/15\n",
      "5824/6204 [===========================>..] - ETA: 0s - loss: 1.0061 - acc: 0.5723 - r2_keras: -11.0989\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 84us/sample - loss: 1.0064 - acc: 0.5735 - r2_keras: -11.2327 - val_loss: 0.9794 - val_acc: 0.5760 - val_r2_keras: -11.2455\n",
      "Epoch 15/15\n",
      "5952/6204 [===========================>..] - ETA: 0s - loss: 1.0058 - acc: 0.5744 - r2_keras: -11.1343\n",
      "Epoch 00015: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 91us/sample - loss: 1.0076 - acc: 0.5732 - r2_keras: -11.2003 - val_loss: 0.9774 - val_acc: 0.5760 - val_r2_keras: -11.4749\n",
      "Train on 6204 samples, validate on 1552 samples\n",
      "Epoch 1/15\n",
      "4992/6204 [=======================>......] - ETA: 0s - loss: 2.0638 - acc: 0.1082 - r2_keras: -10.9063\n",
      "Epoch 00001: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 116us/sample - loss: 2.0340 - acc: 0.1169 - r2_keras: -10.9586 - val_loss: 1.5989 - val_acc: 0.2197 - val_r2_keras: -11.1447\n",
      "Epoch 2/15\n",
      "5248/6204 [========================>.....] - ETA: 0s - loss: 1.8157 - acc: 0.1149 - r2_keras: -10.9809\n",
      "Epoch 00002: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 48us/sample - loss: 1.8079 - acc: 0.1157 - r2_keras: -10.9682 - val_loss: 1.5752 - val_acc: 0.3383 - val_r2_keras: -10.8387\n",
      "Epoch 3/15\n",
      "5760/6204 [==========================>...] - ETA: 0s - loss: 1.7005 - acc: 0.1401 - r2_keras: -10.9600\n",
      "Epoch 00003: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 45us/sample - loss: 1.6972 - acc: 0.1425 - r2_keras: -11.0344 - val_loss: 1.5614 - val_acc: 0.3428 - val_r2_keras: -11.3861\n",
      "Epoch 4/15\n",
      "5504/6204 [=========================>....] - ETA: 0s - loss: 1.6253 - acc: 0.1844 - r2_keras: -11.0579\n",
      "Epoch 00004: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 47us/sample - loss: 1.6236 - acc: 0.1841 - r2_keras: -10.9672 - val_loss: 1.5500 - val_acc: 0.3383 - val_r2_keras: -10.8597\n",
      "Epoch 5/15\n",
      "5504/6204 [=========================>....] - ETA: 0s - loss: 1.5877 - acc: 0.2297 - r2_keras: -10.9177\n",
      "Epoch 00005: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 49us/sample - loss: 1.5865 - acc: 0.2353 - r2_keras: -10.9658 - val_loss: 1.5399 - val_acc: 0.3363 - val_r2_keras: -11.0280\n",
      "Epoch 6/15\n",
      "5376/6204 [========================>.....] - ETA: 0s - loss: 1.5561 - acc: 0.2816 - r2_keras: -10.9421\n",
      "Epoch 00006: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 46us/sample - loss: 1.5537 - acc: 0.2859 - r2_keras: -10.9624 - val_loss: 1.5312 - val_acc: 0.3357 - val_r2_keras: -11.0081\n",
      "Epoch 7/15\n",
      "5376/6204 [========================>.....] - ETA: 0s - loss: 1.5376 - acc: 0.3110 - r2_keras: -10.8694\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 59us/sample - loss: 1.5364 - acc: 0.3119 - r2_keras: -10.9288 - val_loss: 1.5233 - val_acc: 0.3351 - val_r2_keras: -11.1066\n",
      "Epoch 8/15\n",
      "5376/6204 [========================>.....] - ETA: 0s - loss: 1.5285 - acc: 0.3240 - r2_keras: -11.0003\n",
      "Epoch 00008: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 47us/sample - loss: 1.5272 - acc: 0.3267 - r2_keras: -10.9933 - val_loss: 1.5204 - val_acc: 0.3351 - val_r2_keras: -11.8558\n",
      "Epoch 9/15\n",
      "5632/6204 [==========================>...] - ETA: 0s - loss: 1.5215 - acc: 0.3267 - r2_keras: -10.9371\n",
      "Epoch 00009: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 46us/sample - loss: 1.5210 - acc: 0.3295 - r2_keras: -10.9600 - val_loss: 1.5176 - val_acc: 0.3351 - val_r2_keras: -11.0241\n",
      "Epoch 10/15\n",
      "5248/6204 [========================>.....] - ETA: 0s - loss: 1.5151 - acc: 0.3365 - r2_keras: -10.9644\n",
      "Epoch 00010: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 50us/sample - loss: 1.5163 - acc: 0.3343 - r2_keras: -10.9964 - val_loss: 1.5149 - val_acc: 0.3351 - val_r2_keras: -10.9420\n",
      "Epoch 11/15\n",
      "5632/6204 [==========================>...] - ETA: 0s - loss: 1.5115 - acc: 0.3400 - r2_keras: -11.0843\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 45us/sample - loss: 1.5119 - acc: 0.3362 - r2_keras: -10.9867 - val_loss: 1.5122 - val_acc: 0.3357 - val_r2_keras: -11.2874\n",
      "Epoch 12/15\n",
      "5504/6204 [=========================>....] - ETA: 0s - loss: 1.5072 - acc: 0.3401 - r2_keras: -10.9354\n",
      "Epoch 00012: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 45us/sample - loss: 1.5082 - acc: 0.3372 - r2_keras: -10.9565 - val_loss: 1.5112 - val_acc: 0.3357 - val_r2_keras: -10.9764\n",
      "Epoch 13/15\n",
      "5376/6204 [========================>.....] - ETA: 0s - loss: 1.5092 - acc: 0.3326 - r2_keras: -11.0031\n",
      "Epoch 00013: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 49us/sample - loss: 1.5079 - acc: 0.3345 - r2_keras: -10.9606 - val_loss: 1.5102 - val_acc: 0.3357 - val_r2_keras: -11.2285\n",
      "Epoch 14/15\n",
      "4992/6204 [=======================>......] - ETA: 0s - loss: 1.5086 - acc: 0.3317 - r2_keras: -10.9407\n",
      "Epoch 00014: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 49us/sample - loss: 1.5072 - acc: 0.3358 - r2_keras: -11.0395 - val_loss: 1.5092 - val_acc: 0.3357 - val_r2_keras: -12.4396\n",
      "Epoch 15/15\n",
      "6144/6204 [============================>.] - ETA: 0s - loss: 1.5042 - acc: 0.3382 - r2_keras: -10.9276\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 53us/sample - loss: 1.5044 - acc: 0.3377 - r2_keras: -10.9232 - val_loss: 1.5081 - val_acc: 0.3357 - val_r2_keras: -11.7155\n",
      "Train on 6204 samples, validate on 1552 samples\n",
      "Epoch 1/15\n",
      "4864/6204 [======================>.......] - ETA: 0s - loss: 1.5583 - acc: 0.2124 - r2_keras: -11.0044\n",
      "Epoch 00001: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 1s 115us/sample - loss: 1.5503 - acc: 0.2145 - r2_keras: -10.9994 - val_loss: 1.5123 - val_acc: 0.3724 - val_r2_keras: -10.9679\n",
      "Epoch 2/15\n",
      "5120/6204 [=======================>......] - ETA: 0s - loss: 1.4929 - acc: 0.2404 - r2_keras: -10.8321\n",
      "Epoch 00002: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 29us/sample - loss: 1.4861 - acc: 0.2426 - r2_keras: -10.8997 - val_loss: 1.4895 - val_acc: 0.5541 - val_r2_keras: -11.5077\n",
      "Epoch 3/15\n",
      "4864/6204 [======================>.......] - ETA: 0s - loss: 1.4382 - acc: 0.2732 - r2_keras: -10.8939\n",
      "Epoch 00003: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 31us/sample - loss: 1.4340 - acc: 0.2776 - r2_keras: -10.9011 - val_loss: 1.4624 - val_acc: 0.5573 - val_r2_keras: -10.8291\n",
      "Epoch 4/15\n",
      "6144/6204 [============================>.] - ETA: 0s - loss: 1.3956 - acc: 0.3013 - r2_keras: -10.9386\n",
      "Epoch 00004: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 33us/sample - loss: 1.3951 - acc: 0.3021 - r2_keras: -10.8778 - val_loss: 1.4322 - val_acc: 0.5528 - val_r2_keras: -11.0470\n",
      "Epoch 5/15\n",
      "5376/6204 [========================>.....] - ETA: 0s - loss: 1.3635 - acc: 0.3294 - r2_keras: -10.9322\n",
      "Epoch 00005: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 27us/sample - loss: 1.3616 - acc: 0.3353 - r2_keras: -10.8355 - val_loss: 1.4010 - val_acc: 0.5483 - val_r2_keras: -10.9139\n",
      "Epoch 6/15\n",
      "4608/6204 [=====================>........] - ETA: 0s - loss: 1.3280 - acc: 0.4060 - r2_keras: -10.9182\n",
      "Epoch 00006: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 32us/sample - loss: 1.3288 - acc: 0.4363 - r2_keras: -10.8981 - val_loss: 1.3681 - val_acc: 0.5638 - val_r2_keras: -10.6492\n",
      "Epoch 7/15\n",
      "4608/6204 [=====================>........] - ETA: 0s - loss: 1.3042 - acc: 0.5352 - r2_keras: -10.9500\n",
      "Epoch 00007: val_acc did not improve from 0.57668\n",
      "6204/6204 [==============================] - 0s 30us/sample - loss: 1.3004 - acc: 0.5403 - r2_keras: -10.8720 - val_loss: 1.3367 - val_acc: 0.5722 - val_r2_keras: -11.2241\n",
      "Epoch 8/15\n",
      "4352/6204 [====================>.........] - ETA: 0s - loss: 1.2849 - acc: 0.5365 - r2_keras: -10.8783\n",
      "Epoch 00008: val_acc improved from 0.57668 to 0.59085, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 1s 159us/sample - loss: 1.2814 - acc: 0.5448 - r2_keras: -10.8882 - val_loss: 1.3062 - val_acc: 0.5909 - val_r2_keras: -11.2301\n",
      "Epoch 9/15\n",
      "5632/6204 [==========================>...] - ETA: 0s - loss: 1.2527 - acc: 0.5616 - r2_keras: -10.9615\n",
      "Epoch 00009: val_acc improved from 0.59085 to 0.62113, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 43us/sample - loss: 1.2558 - acc: 0.5595 - r2_keras: -10.8879 - val_loss: 1.2763 - val_acc: 0.6211 - val_r2_keras: -11.5169\n",
      "Epoch 10/15\n",
      "5120/6204 [=======================>......] - ETA: 0s - loss: 1.2421 - acc: 0.5688 - r2_keras: -11.0982\n",
      "Epoch 00010: val_acc improved from 0.62113 to 0.66430, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 33us/sample - loss: 1.2367 - acc: 0.5727 - r2_keras: -10.9607 - val_loss: 1.2489 - val_acc: 0.6643 - val_r2_keras: -11.8797\n",
      "Epoch 11/15\n",
      "5632/6204 [==========================>...] - ETA: 0s - loss: 1.2209 - acc: 0.5710 - r2_keras: -10.9714\n",
      "Epoch 00011: val_acc improved from 0.66430 to 0.68943, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 35us/sample - loss: 1.2179 - acc: 0.5735 - r2_keras: -10.8936 - val_loss: 1.2230 - val_acc: 0.6894 - val_r2_keras: -11.0839\n",
      "Epoch 12/15\n",
      "6144/6204 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5789 - r2_keras: -10.9560\n",
      "Epoch 00012: val_acc improved from 0.68943 to 0.70168, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 51us/sample - loss: 1.2008 - acc: 0.5791 - r2_keras: -10.9770 - val_loss: 1.1995 - val_acc: 0.7017 - val_r2_keras: -11.1665\n",
      "Epoch 13/15\n",
      "5632/6204 [==========================>...] - ETA: 0s - loss: 1.1829 - acc: 0.5985 - r2_keras: -10.9233\n",
      "Epoch 00013: val_acc improved from 0.70168 to 0.71263, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 31us/sample - loss: 1.1802 - acc: 0.6011 - r2_keras: -11.1213 - val_loss: 1.1782 - val_acc: 0.7126 - val_r2_keras: -11.5489\n",
      "Epoch 14/15\n",
      "5120/6204 [=======================>......] - ETA: 0s - loss: 1.1704 - acc: 0.5881 - r2_keras: -10.9928\n",
      "Epoch 00014: val_acc improved from 0.71263 to 0.72101, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 43us/sample - loss: 1.1689 - acc: 0.5898 - r2_keras: -10.9037 - val_loss: 1.1567 - val_acc: 0.7210 - val_r2_keras: -11.0553\n",
      "Epoch 15/15\n",
      "4864/6204 [======================>.......] - ETA: 0s - loss: 1.1510 - acc: 0.5999 - r2_keras: -10.8780\n",
      "Epoch 00015: val_acc improved from 0.72101 to 0.72294, saving model to .mdl_wts.hdf5\n",
      "6204/6204 [==============================] - 0s 38us/sample - loss: 1.1493 - acc: 0.5990 - r2_keras: -10.9191 - val_loss: 1.1390 - val_acc: 0.7229 - val_r2_keras: -11.2724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25c60e4dac8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dnn_clf.fit(train,\n",
    "#           train_labels,\n",
    "#           batch_size = 32,\n",
    "#           epochs = 15,\n",
    "#           validation_data=(test,test_labels),\n",
    "#           callbacks=[learning_rate_reduction(), mcp_save])\n",
    "\n",
    "# dnn_clf.fit(train,\n",
    "#           train_labels,\n",
    "#           batch_size = 64,\n",
    "#           epochs = 15,\n",
    "#           validation_data=(test,test_labels),\n",
    "#           callbacks=[learning_rate_reduction(), mcp_save])\n",
    "\n",
    "# dnn_clf.fit(train,\n",
    "#           train_labels,\n",
    "#           batch_size = 128,\n",
    "#           epochs = 15,\n",
    "#           validation_data=(test,test_labels),\n",
    "#           callbacks=[learning_rate_reduction(), mcp_save])\n",
    "\n",
    "# dnn_clf.fit(train,\n",
    "#           train_labels,\n",
    "#           batch_size = 256,\n",
    "#           epochs = 15,\n",
    "#           validation_data=(test,test_labels),\n",
    "#           callbacks=[learning_rate_reduction(), mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import nltk\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "# import matplotlib\n",
    "# from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# from nltk.corpus import wordnet\n",
    "# from nltk.corpus import stopwords\n",
    "# import sklearn\n",
    "# import re\n",
    "# import string\n",
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.clear_session()\n",
    "\n",
    "# def learning_rate_reduction():\n",
    "#     return keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
    "#                                             patience=4, \n",
    "#                                             verbose=1, \n",
    "#                                             factor=0.4, \n",
    "#                                             min_lr=0.00002,\n",
    "#                                             mode='max')\n",
    "# def r2_keras(y_true, y_pred):\n",
    "#     from keras import backend as K\n",
    "#     SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "#     SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "#     return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# mcp_save = keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_acc', verbose = 1, mode='max')\n",
    "\n",
    "# def create_keras_mode_namel():\n",
    "#     model1 = keras.models.Sequential([\n",
    "#         keras.layers.Dense(256, input_shape= (3720,), activation='relu'),\n",
    "#         keras.layers.Dropout(0,4),\n",
    "#         keras.layers.Dense(128, activation='relu'),\n",
    "#         keras.layers.Dropout(0,2),\n",
    "#         keras.layers.Dense(64, activation='relu'),\n",
    "#         keras.layers.Dense(5, activation='sigmoid')])\n",
    "\n",
    "#     model1.compile(optimizer='adam',\n",
    "#                    loss='sparse_categorical_crossentropy', \n",
    "#                    metrics=['accuracy'])\n",
    "#     print(model1.summary())\n",
    "\n",
    "\n",
    "\n",
    "# name_clf = KerasClassifier(build_fn=create_keras_mode_namel, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_corp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-96469065d9a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_corp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_corp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels_corp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels_corp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_corp' is not defined"
     ]
    }
   ],
   "source": [
    "# print(train_corp.shape)\n",
    "# print(test_corp.shape)\n",
    "# print(train_labels_corp.shape)\n",
    "# print(test_labels_corp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-68f0c5e2e483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m           )\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[0;32m    140\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mloss_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-99d6be3340ad>\u001b[0m in \u001b[0;36mcreate_keras_mode_namel\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         keras.layers.Dense(5, activation='sigmoid')])\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     model1.compile(optimizer='adam',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    193\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    164\u001b[0m     output = tf_utils.smart_cond(training,\n\u001b[0;32m    165\u001b[0m                                  \u001b[0mdropped_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                                  lambda: array_ops.identity(inputs))\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[1;32m---> 59\u001b[1;33m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n\u001b[1;32m---> 59\u001b[1;33m                                  name=name)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       \u001b[0mcontext_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m       \u001b[0morig_res_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0morig_res_t\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true_fn must have a return value.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_summaries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_summaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mdropped_inputs\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m       return nn.dropout(\n\u001b[0;32m    159\u001b[0m           \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m           \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_noise_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m           \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           rate=self.rate)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m_get_noise_shape\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mconcrete_inputs_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mnoise_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m       \u001b[0mnoise_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcrete_inputs_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "name_clf.fit(train,\n",
    "          train_labels,\n",
    "          batch_size = 32,\n",
    "          epochs = 15,\n",
    "          validation_data=(test, test_labels),\n",
    "          )\n",
    "\n",
    "name_clf.fit(train,\n",
    "          train_labels,\n",
    "          batch_size = 64,\n",
    "          epochs = 15,\n",
    "          validation_data=(test, test_labels),\n",
    "          )\n",
    "\n",
    " \n",
    "name_clf.fit(train,\n",
    "          train_labels,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          validation_data=(test, test_labels),\n",
    "          )\n",
    "\n",
    " \n",
    "name_clf.fit(train,\n",
    "          train_labels,\n",
    "          batch_size = 256,\n",
    "          epochs = 15,\n",
    "          validation_data=(test, test_labels),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634020618556701"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(name_clf.predict(test_corp), test_labels_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataSet(name_clf.predict(test)).to_scv('test_preds/name_clf_test_pred.scv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3720"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train.columns[57:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-d09a714b09d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#gb_pipe.fit(train, train_labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#(dnn_clf.predict_proba(test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_clf_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#print(r2_score(test_labels, ensamble.predict(test)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[0;32m    140\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mloss_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-aef37ffba898>\u001b[0m in \u001b[0;36mcreate_keras_mode_namel\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         keras.layers.Dense(5, activation='sigmoid')])\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     model1.compile(optimizer='adam',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    193\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    164\u001b[0m     output = tf_utils.smart_cond(training,\n\u001b[0;32m    165\u001b[0m                                  \u001b[0mdropped_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                                  lambda: array_ops.identity(inputs))\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[1;32m---> 59\u001b[1;33m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n\u001b[1;32m---> 59\u001b[1;33m                                  name=name)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       \u001b[0mcontext_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m       \u001b[0morig_res_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0morig_res_t\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true_fn must have a return value.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_summaries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_summaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mdropped_inputs\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m       return nn.dropout(\n\u001b[0;32m    159\u001b[0m           \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m           \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_noise_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m           \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           rate=self.rate)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m_get_noise_shape\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mconcrete_inputs_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mnoise_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m       \u001b[0mnoise_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcrete_inputs_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "name_clf_pipe = make_pipeline(ColumnSelector(cols=list(train.columns[57:])),\n",
    "                              name_clf)\n",
    "\n",
    "dnn_clf_pipe = make_pipeline(ColumnSelector(cols=real_vars),\n",
    "                             dnn_clf)\n",
    "\n",
    "estimators = [gb_pipe, rf_pipe,name_clf_pipe]\n",
    "\n",
    "ensamble = StackingClassifier(classifiers = estimators, \n",
    "                              use_probas=True,\n",
    "                              meta_classifier=LogisticRegression())\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "# np.mean(n, axis =2)\n",
    "#gb_pipe.fit(train, train_labels)\n",
    "#(dnn_clf.predict_proba(test))\n",
    "print(name_clf_pipe.fit(train, train_labels))\n",
    "#print(r2_score(test_labels, ensamble.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shrt_Desc</th>\n",
       "      <th>Water_(g)</th>\n",
       "      <th>Protein_(g)</th>\n",
       "      <th>Lipid_Tot_(g)</th>\n",
       "      <th>Ash_(g)</th>\n",
       "      <th>Carbohydrt_(g)</th>\n",
       "      <th>Fiber_TD_(g)</th>\n",
       "      <th>Sugar_Tot_(g)</th>\n",
       "      <th>Calcium_(mg)</th>\n",
       "      <th>Iron_(mg)</th>\n",
       "      <th>...</th>\n",
       "      <th>GmWt_1</th>\n",
       "      <th>GmWt_Desc1</th>\n",
       "      <th>GmWt_2</th>\n",
       "      <th>GmWt_Desc2</th>\n",
       "      <th>Refuse_Pct</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SILK KEY LIME SOY YOGURT</td>\n",
       "      <td>77.59</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.24</td>\n",
       "      <td>17.65</td>\n",
       "      <td>0.6</td>\n",
       "      <td>12.35</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1 container</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>9.944793e-01</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>1.841329e-05</td>\n",
       "      <td>1.900786e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAST FOODS,SALAD,VEG,TOSSED,WO/DRSNG</td>\n",
       "      <td>95.51</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.53</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>.75 cup</td>\n",
       "      <td>207.00</td>\n",
       "      <td>1.5 cup</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>9.911026e-01</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>2.828437e-05</td>\n",
       "      <td>1.246810e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUTTLEFISH,MXD SP,CKD,MOIST HEAT</td>\n",
       "      <td>61.12</td>\n",
       "      <td>32.48</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3 oz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>1.549279e-03</td>\n",
       "      <td>0.994182</td>\n",
       "      <td>2.989389e-03</td>\n",
       "      <td>1.383081e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GROUND TURKEY,93% LN,7% FAT,RAW</td>\n",
       "      <td>72.63</td>\n",
       "      <td>18.73</td>\n",
       "      <td>8.34</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1 oz</td>\n",
       "      <td>453.00</td>\n",
       "      <td>1 lb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6.825158e-04</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>4.624214e-05</td>\n",
       "      <td>3.133727e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TURKEY,RTL PARTS,ENHANCED,BREAST,MEAT ONLY,CKD...</td>\n",
       "      <td>69.99</td>\n",
       "      <td>27.94</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3 oz</td>\n",
       "      <td>852.00</td>\n",
       "      <td>1 breast</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1.145381e-03</td>\n",
       "      <td>0.998463</td>\n",
       "      <td>3.048181e-04</td>\n",
       "      <td>2.030744e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>CEREALS,QUAKER,OATMEAL,REAL MEDLEYS,SMMR BERRY...</td>\n",
       "      <td>7.57</td>\n",
       "      <td>11.31</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.14</td>\n",
       "      <td>72.58</td>\n",
       "      <td>8.5</td>\n",
       "      <td>20.43</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1 package,  (1 NLEA serving)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>1.095290e-07</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>5.635981e-07</td>\n",
       "      <td>2.858141e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>VEAL,SHLDR,BLADE,LN,CKD,BRSD</td>\n",
       "      <td>59.24</td>\n",
       "      <td>32.66</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3 oz</td>\n",
       "      <td>174.00</td>\n",
       "      <td>1 piece, cooked, excluding refuse (yield from ...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1.262476e-04</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>1.182745e-03</td>\n",
       "      <td>1.946694e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>ONIONS,CKD,BLD,DRND,W/SALT</td>\n",
       "      <td>87.86</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1 cup</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1 tbsp, chopped</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>9.984369e-01</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>1.172247e-05</td>\n",
       "      <td>7.367324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>KEEBLER,FUDGE SHOPPE,JUMBO FUDGE STKS,MINT</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>27.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.60</td>\n",
       "      <td>1.8</td>\n",
       "      <td>50.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1 cookie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>7.587086e-09</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.750408e-06</td>\n",
       "      <td>6.862309e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>PORK,CURED,HAM,EX LN (APPROX 4% FAT),CND,UNHTD</td>\n",
       "      <td>73.52</td>\n",
       "      <td>18.49</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1 cup</td>\n",
       "      <td>28.35</td>\n",
       "      <td>1 oz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.898957e-03</td>\n",
       "      <td>0.997029</td>\n",
       "      <td>3.948643e-05</td>\n",
       "      <td>8.066366e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>862 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Shrt_Desc  Water_(g)  \\\n",
       "0                             SILK KEY LIME SOY YOGURT      77.59   \n",
       "1                 FAST FOODS,SALAD,VEG,TOSSED,WO/DRSNG      95.51   \n",
       "2                     CUTTLEFISH,MXD SP,CKD,MOIST HEAT      61.12   \n",
       "3                      GROUND TURKEY,93% LN,7% FAT,RAW      72.63   \n",
       "4    TURKEY,RTL PARTS,ENHANCED,BREAST,MEAT ONLY,CKD...      69.99   \n",
       "..                                                 ...        ...   \n",
       "857  CEREALS,QUAKER,OATMEAL,REAL MEDLEYS,SMMR BERRY...       7.57   \n",
       "858                       VEAL,SHLDR,BLADE,LN,CKD,BRSD      59.24   \n",
       "859                         ONIONS,CKD,BLD,DRND,W/SALT      87.86   \n",
       "860         KEEBLER,FUDGE SHOPPE,JUMBO FUDGE STKS,MINT       1.70   \n",
       "861     PORK,CURED,HAM,EX LN (APPROX 4% FAT),CND,UNHTD      73.52   \n",
       "\n",
       "     Protein_(g)  Lipid_Tot_(g)  Ash_(g)  Carbohydrt_(g)  Fiber_TD_(g)  \\\n",
       "0           2.35           1.18     1.24           17.65           0.6   \n",
       "1           1.25           0.07     0.53            3.22           NaN   \n",
       "2          32.48           1.40     3.36            1.64           0.0   \n",
       "3          18.73           8.34     0.92            0.00           0.0   \n",
       "4          27.94           2.08     1.40            0.00           0.0   \n",
       "..           ...            ...      ...             ...           ...   \n",
       "857        11.31           4.40     4.14           72.58           8.5   \n",
       "858        32.66           6.48     1.24            0.00           0.0   \n",
       "859         1.36           0.19     1.03            9.56           1.4   \n",
       "860         2.60          27.20      NaN           67.60           1.8   \n",
       "861        18.49           4.56     3.63            0.00           0.0   \n",
       "\n",
       "     Sugar_Tot_(g)  Calcium_(mg)  Iron_(mg)  ...  GmWt_1  \\\n",
       "0            12.35         176.0       0.64  ...   170.0   \n",
       "1              NaN          13.0       0.63  ...   104.0   \n",
       "2              NaN         180.0      10.84  ...    85.0   \n",
       "3             0.00          21.0       1.17  ...    28.0   \n",
       "4             0.00          15.0       0.59  ...    85.0   \n",
       "..             ...           ...        ...  ...     ...   \n",
       "857          20.43         124.0       3.13  ...    70.0   \n",
       "858           0.00          40.0       1.47  ...    85.0   \n",
       "859           4.73          22.0       0.24  ...   210.0   \n",
       "860          50.10           NaN       1.60  ...    31.0   \n",
       "861           0.00           6.0       0.94  ...   140.0   \n",
       "\n",
       "                       GmWt_Desc1  GmWt_2  \\\n",
       "0                     1 container     NaN   \n",
       "1                         .75 cup  207.00   \n",
       "2                            3 oz     NaN   \n",
       "3                            1 oz  453.00   \n",
       "4                            3 oz  852.00   \n",
       "..                            ...     ...   \n",
       "857  1 package,  (1 NLEA serving)     NaN   \n",
       "858                          3 oz  174.00   \n",
       "859                         1 cup   15.00   \n",
       "860                      1 cookie     NaN   \n",
       "861                         1 cup   28.35   \n",
       "\n",
       "                                            GmWt_Desc2  Refuse_Pct         0  \\\n",
       "0                                                  NaN         0.0  0.000233   \n",
       "1                                              1.5 cup         0.0  0.000029   \n",
       "2                                                  NaN         0.0  0.001141   \n",
       "3                                                 1 lb         0.0  0.000012   \n",
       "4                                             1 breast        24.0  0.000066   \n",
       "..                                                 ...         ...       ...   \n",
       "857                                                NaN         0.0  0.999966   \n",
       "858  1 piece, cooked, excluding refuse (yield from ...        39.0  0.000105   \n",
       "859                                    1 tbsp, chopped         0.0  0.000039   \n",
       "860                                                NaN         0.0  0.999986   \n",
       "861                                               1 oz         0.0  0.000025   \n",
       "\n",
       "                1         2             3             4  \n",
       "0    9.944793e-01  0.005251  1.841329e-05  1.900786e-05  \n",
       "1    9.911026e-01  0.008828  2.828437e-05  1.246810e-05  \n",
       "2    1.549279e-03  0.994182  2.989389e-03  1.383081e-04  \n",
       "3    6.825158e-04  0.999256  4.624214e-05  3.133727e-06  \n",
       "4    1.145381e-03  0.998463  3.048181e-04  2.030744e-05  \n",
       "..            ...       ...           ...           ...  \n",
       "857  1.095290e-07  0.000033  5.635981e-07  2.858141e-07  \n",
       "858  1.262476e-04  0.998566  1.182745e-03  1.946694e-05  \n",
       "859  9.984369e-01  0.001505  1.172247e-05  7.367324e-06  \n",
       "860  7.587086e-09  0.000011  2.750408e-06  6.862309e-07  \n",
       "861  2.898957e-03  0.997029  3.948643e-05  8.066366e-06  \n",
       "\n",
       "[862 rows x 56 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.read_excel('data/test.xlsx')\n",
    "\n",
    "pp = p[['Protein_(g)','Lipid_Tot_(g)','Carbohydrt_(g)']]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pp = scaler.fit_transform(pp)\n",
    "\n",
    "pp = pd.concat([p, pd.DataFrame(dnn_clf.predict_proba(pp))], axis = 1)\n",
    "pp\n",
    "#pd.DataFrame(dnn_clf.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MainModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/dnn1_class_predictions.xlsx')\n",
    "label = data['Energ_Kcal']\n",
    "train_data1 = pd.DataFrame()\n",
    "train_data1['Lip'] = data['Lipid_Tot_(g)']/100\n",
    "train_data1['Prot'] = data['Protein_(g)']/88\n",
    "train_data1['Carbohydrt'] = data['Carbohydrt_(g)']/100\n",
    "train_data1 =  train_data1.join(data.iloc[:, 54:69])\n",
    "from sklearn import model_selection \n",
    "X_train, X_test, Y_train,  Y_test = sklearn.model_selection.train_test_split(train_data1, label, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostRegressor(\n",
    "   iterations=200000,\n",
    "   learning_rate = 0.07521709965938336,\n",
    "   random_seed=63,\n",
    "   loss_function=\"MAE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 119.7805858\ttest: 129.9761673\tbest: 129.9761673 (0)\ttotal: 59.1ms\tremaining: 3h 16m 57s\n",
      "1:\tlearn: 110.9430530\ttest: 120.5130588\tbest: 120.5130588 (1)\ttotal: 61.3ms\tremaining: 1h 42m 11s\n",
      "2:\tlearn: 103.2495258\ttest: 112.3749352\tbest: 112.3749352 (2)\ttotal: 64.2ms\tremaining: 1h 11m 22s\n",
      "3:\tlearn: 96.0259332\ttest: 104.5588484\tbest: 104.5588484 (3)\ttotal: 66.7ms\tremaining: 55m 35s\n",
      "4:\tlearn: 89.0570069\ttest: 97.1821788\tbest: 97.1821788 (4)\ttotal: 69.1ms\tremaining: 46m 2s\n",
      "5:\tlearn: 82.6537015\ttest: 90.3579391\tbest: 90.3579391 (5)\ttotal: 71.4ms\tremaining: 39m 40s\n",
      "6:\tlearn: 76.6099933\ttest: 83.8724841\tbest: 83.8724841 (6)\ttotal: 73.7ms\tremaining: 35m 5s\n",
      "7:\tlearn: 71.2506559\ttest: 78.1560181\tbest: 78.1560181 (7)\ttotal: 76.1ms\tremaining: 31m 42s\n",
      "8:\tlearn: 66.3820471\ttest: 72.9097669\tbest: 72.9097669 (8)\ttotal: 78.9ms\tremaining: 29m 12s\n",
      "9:\tlearn: 62.3765014\ttest: 68.5717827\tbest: 68.5717827 (9)\ttotal: 81.3ms\tremaining: 27m 6s\n",
      "10:\tlearn: 58.5165278\ttest: 64.4336133\tbest: 64.4336133 (10)\ttotal: 83.7ms\tremaining: 25m 21s\n",
      "11:\tlearn: 54.9564281\ttest: 60.5837976\tbest: 60.5837976 (11)\ttotal: 86ms\tremaining: 23m 52s\n",
      "12:\tlearn: 51.4767790\ttest: 56.7805210\tbest: 56.7805210 (12)\ttotal: 88.7ms\tremaining: 22m 44s\n",
      "13:\tlearn: 48.8330784\ttest: 54.0724400\tbest: 54.0724400 (13)\ttotal: 91ms\tremaining: 21m 39s\n",
      "14:\tlearn: 45.8158525\ttest: 50.7621972\tbest: 50.7621972 (14)\ttotal: 93.7ms\tremaining: 20m 48s\n",
      "15:\tlearn: 43.0076354\ttest: 47.6808432\tbest: 47.6808432 (15)\ttotal: 96ms\tremaining: 20m\n",
      "16:\tlearn: 40.3153105\ttest: 44.7624084\tbest: 44.7624084 (16)\ttotal: 98.7ms\tremaining: 19m 21s\n",
      "17:\tlearn: 38.0529098\ttest: 42.3416402\tbest: 42.3416402 (17)\ttotal: 101ms\tremaining: 18m 42s\n",
      "18:\tlearn: 35.7478974\ttest: 39.7992751\tbest: 39.7992751 (18)\ttotal: 103ms\tremaining: 18m 7s\n",
      "19:\tlearn: 34.0478355\ttest: 38.0240145\tbest: 38.0240145 (19)\ttotal: 106ms\tremaining: 17m 35s\n",
      "20:\tlearn: 32.5406695\ttest: 36.4929719\tbest: 36.4929719 (20)\ttotal: 108ms\tremaining: 17m 5s\n",
      "21:\tlearn: 30.7126048\ttest: 34.4431303\tbest: 34.4431303 (21)\ttotal: 110ms\tremaining: 16m 43s\n",
      "22:\tlearn: 29.0433252\ttest: 32.5308248\tbest: 32.5308248 (22)\ttotal: 113ms\tremaining: 16m 21s\n",
      "23:\tlearn: 27.5641692\ttest: 30.9271311\tbest: 30.9271311 (23)\ttotal: 115ms\tremaining: 16m\n",
      "24:\tlearn: 26.2689143\ttest: 29.4394920\tbest: 29.4394920 (24)\ttotal: 118ms\tremaining: 15m 41s\n",
      "25:\tlearn: 25.0956970\ttest: 28.1541723\tbest: 28.1541723 (25)\ttotal: 120ms\tremaining: 15m 21s\n",
      "26:\tlearn: 23.9807137\ttest: 26.8458367\tbest: 26.8458367 (26)\ttotal: 122ms\tremaining: 15m 4s\n",
      "27:\tlearn: 23.2416790\ttest: 26.0671573\tbest: 26.0671573 (27)\ttotal: 124ms\tremaining: 14m 46s\n",
      "28:\tlearn: 22.2981718\ttest: 24.9897345\tbest: 24.9897345 (28)\ttotal: 127ms\tremaining: 14m 34s\n",
      "29:\tlearn: 21.5040119\ttest: 24.1210242\tbest: 24.1210242 (29)\ttotal: 129ms\tremaining: 14m 19s\n",
      "30:\tlearn: 20.7828947\ttest: 23.2870185\tbest: 23.2870185 (30)\ttotal: 132ms\tremaining: 14m 9s\n",
      "31:\tlearn: 20.0226517\ttest: 22.4653808\tbest: 22.4653808 (31)\ttotal: 134ms\tremaining: 13m 59s\n",
      "32:\tlearn: 19.5043517\ttest: 21.9072141\tbest: 21.9072141 (32)\ttotal: 137ms\tremaining: 13m 48s\n",
      "33:\tlearn: 19.0645583\ttest: 21.4163765\tbest: 21.4163765 (33)\ttotal: 139ms\tremaining: 13m 39s\n",
      "34:\tlearn: 18.4333761\ttest: 20.6971911\tbest: 20.6971911 (34)\ttotal: 142ms\tremaining: 13m 30s\n",
      "35:\tlearn: 17.9132917\ttest: 20.1290901\tbest: 20.1290901 (35)\ttotal: 144ms\tremaining: 13m 19s\n",
      "36:\tlearn: 17.4217041\ttest: 19.5604637\tbest: 19.5604637 (36)\ttotal: 147ms\tremaining: 13m 12s\n",
      "37:\tlearn: 16.9348944\ttest: 19.0142693\tbest: 19.0142693 (37)\ttotal: 149ms\tremaining: 13m 3s\n",
      "38:\tlearn: 16.5464478\ttest: 18.5969976\tbest: 18.5969976 (38)\ttotal: 151ms\tremaining: 12m 54s\n",
      "39:\tlearn: 16.0344362\ttest: 17.9982424\tbest: 17.9982424 (39)\ttotal: 153ms\tremaining: 12m 45s\n",
      "40:\tlearn: 15.6930785\ttest: 17.5594930\tbest: 17.5594930 (40)\ttotal: 155ms\tremaining: 12m 37s\n",
      "41:\tlearn: 15.3409596\ttest: 17.1571012\tbest: 17.1571012 (41)\ttotal: 158ms\tremaining: 12m 31s\n",
      "42:\tlearn: 15.1108296\ttest: 16.9023179\tbest: 16.9023179 (42)\ttotal: 160ms\tremaining: 12m 24s\n",
      "43:\tlearn: 14.8222052\ttest: 16.5156564\tbest: 16.5156564 (43)\ttotal: 162ms\tremaining: 12m 17s\n",
      "44:\tlearn: 14.5726544\ttest: 16.2038600\tbest: 16.2038600 (44)\ttotal: 164ms\tremaining: 12m 10s\n",
      "45:\tlearn: 14.3418501\ttest: 15.9265012\tbest: 15.9265012 (45)\ttotal: 167ms\tremaining: 12m 4s\n",
      "46:\tlearn: 14.1102855\ttest: 15.6765925\tbest: 15.6765925 (46)\ttotal: 169ms\tremaining: 11m 57s\n",
      "47:\tlearn: 13.8951302\ttest: 15.4216121\tbest: 15.4216121 (47)\ttotal: 171ms\tremaining: 11m 51s\n",
      "48:\tlearn: 13.7386160\ttest: 15.2464004\tbest: 15.2464004 (48)\ttotal: 173ms\tremaining: 11m 46s\n",
      "49:\tlearn: 13.4889016\ttest: 14.9345114\tbest: 14.9345114 (49)\ttotal: 175ms\tremaining: 11m 40s\n",
      "50:\tlearn: 13.2193928\ttest: 14.6064350\tbest: 14.6064350 (50)\ttotal: 177ms\tremaining: 11m 35s\n",
      "51:\tlearn: 13.0075429\ttest: 14.3589858\tbest: 14.3589858 (51)\ttotal: 180ms\tremaining: 11m 30s\n",
      "52:\tlearn: 12.8354740\ttest: 14.1456658\tbest: 14.1456658 (52)\ttotal: 182ms\tremaining: 11m 25s\n",
      "53:\tlearn: 12.6448240\ttest: 13.9081406\tbest: 13.9081406 (53)\ttotal: 184ms\tremaining: 11m 20s\n",
      "54:\tlearn: 12.5273595\ttest: 13.7677993\tbest: 13.7677993 (54)\ttotal: 187ms\tremaining: 11m 18s\n",
      "55:\tlearn: 12.3660601\ttest: 13.6031660\tbest: 13.6031660 (55)\ttotal: 189ms\tremaining: 11m 14s\n",
      "56:\tlearn: 12.2785702\ttest: 13.4982752\tbest: 13.4982752 (56)\ttotal: 191ms\tremaining: 11m 10s\n",
      "57:\tlearn: 12.0856159\ttest: 13.2840222\tbest: 13.2840222 (57)\ttotal: 193ms\tremaining: 11m 6s\n",
      "58:\tlearn: 11.9864145\ttest: 13.1603474\tbest: 13.1603474 (58)\ttotal: 196ms\tremaining: 11m 3s\n",
      "59:\tlearn: 11.8204150\ttest: 12.9409603\tbest: 12.9409603 (59)\ttotal: 199ms\tremaining: 11m 1s\n",
      "60:\tlearn: 11.6713727\ttest: 12.7808533\tbest: 12.7808533 (60)\ttotal: 201ms\tremaining: 10m 58s\n",
      "61:\tlearn: 11.5611703\ttest: 12.6415871\tbest: 12.6415871 (61)\ttotal: 203ms\tremaining: 10m 54s\n",
      "62:\tlearn: 11.4444092\ttest: 12.5293737\tbest: 12.5293737 (62)\ttotal: 206ms\tremaining: 10m 52s\n",
      "63:\tlearn: 11.3317702\ttest: 12.4056506\tbest: 12.4056506 (63)\ttotal: 208ms\tremaining: 10m 49s\n",
      "64:\tlearn: 11.2706196\ttest: 12.3265798\tbest: 12.3265798 (64)\ttotal: 210ms\tremaining: 10m 46s\n",
      "65:\tlearn: 11.1272952\ttest: 12.1706520\tbest: 12.1706520 (65)\ttotal: 212ms\tremaining: 10m 43s\n",
      "66:\tlearn: 11.0208019\ttest: 12.0778803\tbest: 12.0778803 (66)\ttotal: 215ms\tremaining: 10m 42s\n",
      "67:\tlearn: 10.8778010\ttest: 11.8974466\tbest: 11.8974466 (67)\ttotal: 218ms\tremaining: 10m 39s\n",
      "68:\tlearn: 10.7758249\ttest: 11.7742371\tbest: 11.7742371 (68)\ttotal: 220ms\tremaining: 10m 36s\n",
      "69:\tlearn: 10.6762253\ttest: 11.6698222\tbest: 11.6698222 (69)\ttotal: 222ms\tremaining: 10m 34s\n",
      "70:\tlearn: 10.5991123\ttest: 11.5655009\tbest: 11.5655009 (70)\ttotal: 226ms\tremaining: 10m 35s\n",
      "71:\tlearn: 10.4358376\ttest: 11.3687951\tbest: 11.3687951 (71)\ttotal: 228ms\tremaining: 10m 34s\n",
      "72:\tlearn: 10.3926981\ttest: 11.3255759\tbest: 11.3255759 (72)\ttotal: 231ms\tremaining: 10m 33s\n",
      "73:\tlearn: 10.3515190\ttest: 11.2807199\tbest: 11.2807199 (73)\ttotal: 234ms\tremaining: 10m 31s\n",
      "74:\tlearn: 10.2535534\ttest: 11.1822723\tbest: 11.1822723 (74)\ttotal: 237ms\tremaining: 10m 30s\n",
      "75:\tlearn: 10.1809614\ttest: 11.1043308\tbest: 11.1043308 (75)\ttotal: 240ms\tremaining: 10m 30s\n",
      "76:\tlearn: 10.1380671\ttest: 11.0504046\tbest: 11.0504046 (76)\ttotal: 242ms\tremaining: 10m 27s\n",
      "77:\tlearn: 10.0536286\ttest: 10.9540627\tbest: 10.9540627 (77)\ttotal: 244ms\tremaining: 10m 26s\n",
      "78:\tlearn: 9.9518348\ttest: 10.8286452\tbest: 10.8286452 (78)\ttotal: 247ms\tremaining: 10m 23s\n",
      "79:\tlearn: 9.8513471\ttest: 10.7202734\tbest: 10.7202734 (79)\ttotal: 249ms\tremaining: 10m 23s\n",
      "80:\tlearn: 9.7796639\ttest: 10.6463172\tbest: 10.6463172 (80)\ttotal: 252ms\tremaining: 10m 22s\n",
      "81:\tlearn: 9.7012349\ttest: 10.5646715\tbest: 10.5646715 (81)\ttotal: 259ms\tremaining: 10m 30s\n",
      "82:\tlearn: 9.6645580\ttest: 10.5309115\tbest: 10.5309115 (82)\ttotal: 262ms\tremaining: 10m 31s\n",
      "83:\tlearn: 9.5525674\ttest: 10.4188848\tbest: 10.4188848 (83)\ttotal: 266ms\tremaining: 10m 32s\n",
      "84:\tlearn: 9.4764617\ttest: 10.3232794\tbest: 10.3232794 (84)\ttotal: 268ms\tremaining: 10m 30s\n",
      "85:\tlearn: 9.3996497\ttest: 10.2396637\tbest: 10.2396637 (85)\ttotal: 270ms\tremaining: 10m 28s\n",
      "86:\tlearn: 9.3613296\ttest: 10.1933388\tbest: 10.1933388 (86)\ttotal: 273ms\tremaining: 10m 26s\n",
      "87:\tlearn: 9.3085109\ttest: 10.1265451\tbest: 10.1265451 (87)\ttotal: 275ms\tremaining: 10m 24s\n",
      "88:\tlearn: 9.2751199\ttest: 10.0897471\tbest: 10.0897471 (88)\ttotal: 277ms\tremaining: 10m 23s\n",
      "89:\tlearn: 9.2349988\ttest: 10.0397984\tbest: 10.0397984 (89)\ttotal: 280ms\tremaining: 10m 21s\n",
      "90:\tlearn: 9.1654698\ttest: 9.9854295\tbest: 9.9854295 (90)\ttotal: 283ms\tremaining: 10m 20s\n",
      "91:\tlearn: 9.1069378\ttest: 9.9182841\tbest: 9.9182841 (91)\ttotal: 285ms\tremaining: 10m 20s\n",
      "92:\tlearn: 9.0796929\ttest: 9.9096213\tbest: 9.9096213 (92)\ttotal: 289ms\tremaining: 10m 21s\n",
      "93:\tlearn: 9.0655686\ttest: 9.8945707\tbest: 9.8945707 (93)\ttotal: 292ms\tremaining: 10m 20s\n",
      "94:\tlearn: 9.0540021\ttest: 9.8778858\tbest: 9.8778858 (94)\ttotal: 294ms\tremaining: 10m 18s\n",
      "95:\tlearn: 8.9919025\ttest: 9.8194135\tbest: 9.8194135 (95)\ttotal: 296ms\tremaining: 10m 16s\n",
      "96:\tlearn: 8.9652839\ttest: 9.8000749\tbest: 9.8000749 (96)\ttotal: 298ms\tremaining: 10m 15s\n",
      "97:\tlearn: 8.9294783\ttest: 9.7627708\tbest: 9.7627708 (97)\ttotal: 301ms\tremaining: 10m 12s\n",
      "98:\tlearn: 8.9046252\ttest: 9.7311677\tbest: 9.7311677 (98)\ttotal: 303ms\tremaining: 10m 11s\n",
      "99:\tlearn: 8.8857008\ttest: 9.7094048\tbest: 9.7094048 (99)\ttotal: 305ms\tremaining: 10m 9s\n",
      "100:\tlearn: 8.8667428\ttest: 9.6910657\tbest: 9.6910657 (100)\ttotal: 308ms\tremaining: 10m 8s\n",
      "101:\tlearn: 8.8574787\ttest: 9.6796413\tbest: 9.6796413 (101)\ttotal: 310ms\tremaining: 10m 7s\n",
      "102:\tlearn: 8.8187685\ttest: 9.6306735\tbest: 9.6306735 (102)\ttotal: 312ms\tremaining: 10m 5s\n",
      "103:\tlearn: 8.7904144\ttest: 9.5943758\tbest: 9.5943758 (103)\ttotal: 315ms\tremaining: 10m 4s\n",
      "104:\tlearn: 8.7519917\ttest: 9.5540893\tbest: 9.5540893 (104)\ttotal: 317ms\tremaining: 10m 2s\n",
      "105:\tlearn: 8.7063330\ttest: 9.5120554\tbest: 9.5120554 (105)\ttotal: 319ms\tremaining: 10m 2s\n",
      "106:\tlearn: 8.6605484\ttest: 9.4909745\tbest: 9.4909745 (106)\ttotal: 322ms\tremaining: 10m 1s\n",
      "107:\tlearn: 8.5949932\ttest: 9.4299643\tbest: 9.4299643 (107)\ttotal: 324ms\tremaining: 10m\n",
      "108:\tlearn: 8.5742149\ttest: 9.4163753\tbest: 9.4163753 (108)\ttotal: 326ms\tremaining: 9m 58s\n",
      "109:\tlearn: 8.5470609\ttest: 9.3924098\tbest: 9.3924098 (109)\ttotal: 329ms\tremaining: 9m 58s\n",
      "110:\tlearn: 8.5390545\ttest: 9.3824692\tbest: 9.3824692 (110)\ttotal: 331ms\tremaining: 9m 56s\n",
      "111:\tlearn: 8.5252400\ttest: 9.3640143\tbest: 9.3640143 (111)\ttotal: 334ms\tremaining: 9m 56s\n",
      "112:\tlearn: 8.5116417\ttest: 9.3482979\tbest: 9.3482979 (112)\ttotal: 336ms\tremaining: 9m 54s\n",
      "113:\tlearn: 8.4898051\ttest: 9.3250525\tbest: 9.3250525 (113)\ttotal: 338ms\tremaining: 9m 53s\n",
      "114:\tlearn: 8.4397636\ttest: 9.2746069\tbest: 9.2746069 (114)\ttotal: 341ms\tremaining: 9m 52s\n",
      "115:\tlearn: 8.4190799\ttest: 9.2624433\tbest: 9.2624433 (115)\ttotal: 343ms\tremaining: 9m 50s\n",
      "116:\tlearn: 8.3963445\ttest: 9.2392535\tbest: 9.2392535 (116)\ttotal: 345ms\tremaining: 9m 49s\n",
      "117:\tlearn: 8.3427121\ttest: 9.1851548\tbest: 9.1851548 (117)\ttotal: 347ms\tremaining: 9m 48s\n",
      "118:\tlearn: 8.3084033\ttest: 9.1607270\tbest: 9.1607270 (118)\ttotal: 350ms\tremaining: 9m 47s\n",
      "119:\tlearn: 8.2797211\ttest: 9.1411211\tbest: 9.1411211 (119)\ttotal: 352ms\tremaining: 9m 45s\n",
      "120:\tlearn: 8.2739960\ttest: 9.1356784\tbest: 9.1356784 (120)\ttotal: 354ms\tremaining: 9m 45s\n",
      "121:\tlearn: 8.2289884\ttest: 9.0906780\tbest: 9.0906780 (121)\ttotal: 356ms\tremaining: 9m 43s\n",
      "122:\tlearn: 8.2138348\ttest: 9.0748570\tbest: 9.0748570 (122)\ttotal: 358ms\tremaining: 9m 42s\n",
      "123:\tlearn: 8.1902333\ttest: 9.0542491\tbest: 9.0542491 (123)\ttotal: 361ms\tremaining: 9m 41s\n",
      "124:\tlearn: 8.1698227\ttest: 9.0325508\tbest: 9.0325508 (124)\ttotal: 363ms\tremaining: 9m 40s\n",
      "125:\tlearn: 8.1581025\ttest: 9.0270057\tbest: 9.0270057 (125)\ttotal: 365ms\tremaining: 9m 39s\n",
      "126:\tlearn: 8.1315065\ttest: 9.0022380\tbest: 9.0022380 (126)\ttotal: 367ms\tremaining: 9m 38s\n",
      "127:\tlearn: 8.1052117\ttest: 8.9762661\tbest: 8.9762661 (127)\ttotal: 370ms\tremaining: 9m 37s\n",
      "128:\tlearn: 8.0766072\ttest: 8.9478325\tbest: 8.9478325 (128)\ttotal: 372ms\tremaining: 9m 35s\n",
      "129:\tlearn: 8.0653027\ttest: 8.9334029\tbest: 8.9334029 (129)\ttotal: 374ms\tremaining: 9m 35s\n",
      "130:\tlearn: 8.0251113\ttest: 8.9094937\tbest: 8.9094937 (130)\ttotal: 376ms\tremaining: 9m 34s\n",
      "131:\tlearn: 8.0087159\ttest: 8.8899803\tbest: 8.8899803 (131)\ttotal: 378ms\tremaining: 9m 33s\n",
      "132:\tlearn: 7.9952062\ttest: 8.8783819\tbest: 8.8783819 (132)\ttotal: 381ms\tremaining: 9m 32s\n",
      "133:\tlearn: 7.9684649\ttest: 8.8407130\tbest: 8.8407130 (133)\ttotal: 383ms\tremaining: 9m 31s\n",
      "134:\tlearn: 7.9495360\ttest: 8.8237855\tbest: 8.8237855 (134)\ttotal: 385ms\tremaining: 9m 30s\n",
      "135:\tlearn: 7.9197491\ttest: 8.7984936\tbest: 8.7984936 (135)\ttotal: 387ms\tremaining: 9m 29s\n",
      "136:\tlearn: 7.8884122\ttest: 8.7693169\tbest: 8.7693169 (136)\ttotal: 390ms\tremaining: 9m 28s\n",
      "137:\tlearn: 7.8735503\ttest: 8.7637723\tbest: 8.7637723 (137)\ttotal: 393ms\tremaining: 9m 29s\n",
      "138:\tlearn: 7.8596129\ttest: 8.7465499\tbest: 8.7465499 (138)\ttotal: 396ms\tremaining: 9m 29s\n",
      "139:\tlearn: 7.8335707\ttest: 8.7254981\tbest: 8.7254981 (139)\ttotal: 398ms\tremaining: 9m 28s\n",
      "140:\tlearn: 7.8122595\ttest: 8.7066635\tbest: 8.7066635 (140)\ttotal: 401ms\tremaining: 9m 28s\n",
      "141:\tlearn: 7.7818808\ttest: 8.6783776\tbest: 8.6783776 (141)\ttotal: 404ms\tremaining: 9m 28s\n",
      "142:\tlearn: 7.7611480\ttest: 8.6584531\tbest: 8.6584531 (142)\ttotal: 407ms\tremaining: 9m 28s\n",
      "143:\tlearn: 7.7553833\ttest: 8.6541298\tbest: 8.6541298 (143)\ttotal: 410ms\tremaining: 9m 28s\n",
      "144:\tlearn: 7.7375308\ttest: 8.6338933\tbest: 8.6338933 (144)\ttotal: 412ms\tremaining: 9m 27s\n",
      "145:\tlearn: 7.7060448\ttest: 8.6148583\tbest: 8.6148583 (145)\ttotal: 414ms\tremaining: 9m 26s\n",
      "146:\tlearn: 7.6840357\ttest: 8.5970980\tbest: 8.5970980 (146)\ttotal: 416ms\tremaining: 9m 25s\n",
      "147:\tlearn: 7.6539960\ttest: 8.5580422\tbest: 8.5580422 (147)\ttotal: 418ms\tremaining: 9m 24s\n",
      "148:\tlearn: 7.6183552\ttest: 8.5279490\tbest: 8.5279490 (148)\ttotal: 420ms\tremaining: 9m 23s\n",
      "149:\tlearn: 7.6048798\ttest: 8.5171923\tbest: 8.5171923 (149)\ttotal: 423ms\tremaining: 9m 23s\n",
      "150:\tlearn: 7.5855203\ttest: 8.5037215\tbest: 8.5037215 (150)\ttotal: 425ms\tremaining: 9m 22s\n",
      "151:\tlearn: 7.5512198\ttest: 8.4821644\tbest: 8.4821644 (151)\ttotal: 428ms\tremaining: 9m 22s\n",
      "152:\tlearn: 7.5283918\ttest: 8.4594108\tbest: 8.4594108 (152)\ttotal: 430ms\tremaining: 9m 21s\n",
      "153:\tlearn: 7.4952557\ttest: 8.4258025\tbest: 8.4258025 (153)\ttotal: 432ms\tremaining: 9m 20s\n",
      "154:\tlearn: 7.4708394\ttest: 8.4168721\tbest: 8.4168721 (154)\ttotal: 435ms\tremaining: 9m 20s\n",
      "155:\tlearn: 7.4483282\ttest: 8.3963248\tbest: 8.3963248 (155)\ttotal: 438ms\tremaining: 9m 20s\n",
      "156:\tlearn: 7.4304673\ttest: 8.3768620\tbest: 8.3768620 (156)\ttotal: 440ms\tremaining: 9m 20s\n",
      "157:\tlearn: 7.4168412\ttest: 8.3663152\tbest: 8.3663152 (157)\ttotal: 442ms\tremaining: 9m 19s\n",
      "158:\tlearn: 7.4035442\ttest: 8.3479943\tbest: 8.3479943 (158)\ttotal: 445ms\tremaining: 9m 18s\n",
      "159:\tlearn: 7.3788016\ttest: 8.3324348\tbest: 8.3324348 (159)\ttotal: 447ms\tremaining: 9m 18s\n",
      "160:\tlearn: 7.3542278\ttest: 8.3080326\tbest: 8.3080326 (160)\ttotal: 449ms\tremaining: 9m 17s\n",
      "161:\tlearn: 7.3382575\ttest: 8.2935644\tbest: 8.2935644 (161)\ttotal: 451ms\tremaining: 9m 16s\n",
      "162:\tlearn: 7.3228555\ttest: 8.2770567\tbest: 8.2770567 (162)\ttotal: 453ms\tremaining: 9m 15s\n",
      "163:\tlearn: 7.3112417\ttest: 8.2693135\tbest: 8.2693135 (163)\ttotal: 456ms\tremaining: 9m 15s\n",
      "164:\tlearn: 7.2868838\ttest: 8.2429146\tbest: 8.2429146 (164)\ttotal: 458ms\tremaining: 9m 14s\n",
      "165:\tlearn: 7.2636155\ttest: 8.2181153\tbest: 8.2181153 (165)\ttotal: 460ms\tremaining: 9m 14s\n",
      "166:\tlearn: 7.2489150\ttest: 8.2011720\tbest: 8.2011720 (166)\ttotal: 463ms\tremaining: 9m 13s\n",
      "167:\tlearn: 7.2239540\ttest: 8.1873243\tbest: 8.1873243 (167)\ttotal: 465ms\tremaining: 9m 13s\n",
      "168:\tlearn: 7.2160787\ttest: 8.1806240\tbest: 8.1806240 (168)\ttotal: 468ms\tremaining: 9m 12s\n",
      "169:\tlearn: 7.2038182\ttest: 8.1669667\tbest: 8.1669667 (169)\ttotal: 470ms\tremaining: 9m 12s\n",
      "170:\tlearn: 7.1843476\ttest: 8.1479932\tbest: 8.1479932 (170)\ttotal: 472ms\tremaining: 9m 11s\n",
      "171:\tlearn: 7.1727794\ttest: 8.1367348\tbest: 8.1367348 (171)\ttotal: 474ms\tremaining: 9m 11s\n",
      "172:\tlearn: 7.1481638\ttest: 8.1036348\tbest: 8.1036348 (172)\ttotal: 477ms\tremaining: 9m 10s\n",
      "173:\tlearn: 7.1315556\ttest: 8.0863325\tbest: 8.0863325 (173)\ttotal: 479ms\tremaining: 9m 9s\n",
      "174:\tlearn: 7.1161589\ttest: 8.0718849\tbest: 8.0718849 (174)\ttotal: 481ms\tremaining: 9m 8s\n",
      "175:\tlearn: 7.1048057\ttest: 8.0635916\tbest: 8.0635916 (175)\ttotal: 483ms\tremaining: 9m 8s\n",
      "176:\tlearn: 7.0923859\ttest: 8.0517379\tbest: 8.0517379 (176)\ttotal: 485ms\tremaining: 9m 7s\n",
      "177:\tlearn: 7.0793432\ttest: 8.0395129\tbest: 8.0395129 (177)\ttotal: 487ms\tremaining: 9m 6s\n",
      "178:\tlearn: 7.0592053\ttest: 8.0259231\tbest: 8.0259231 (178)\ttotal: 490ms\tremaining: 9m 6s\n",
      "179:\tlearn: 7.0504937\ttest: 8.0186996\tbest: 8.0186996 (179)\ttotal: 492ms\tremaining: 9m 6s\n",
      "180:\tlearn: 7.0410602\ttest: 8.0175687\tbest: 8.0175687 (180)\ttotal: 495ms\tremaining: 9m 5s\n",
      "181:\tlearn: 7.0222364\ttest: 7.9983624\tbest: 7.9983624 (181)\ttotal: 497ms\tremaining: 9m 5s\n",
      "182:\tlearn: 7.0123559\ttest: 7.9976185\tbest: 7.9976185 (182)\ttotal: 499ms\tremaining: 9m 4s\n",
      "183:\tlearn: 6.9918769\ttest: 7.9745128\tbest: 7.9745128 (183)\ttotal: 502ms\tremaining: 9m 4s\n",
      "184:\tlearn: 6.9765164\ttest: 7.9643769\tbest: 7.9643769 (184)\ttotal: 504ms\tremaining: 9m 4s\n",
      "185:\tlearn: 6.9664417\ttest: 7.9582682\tbest: 7.9582682 (185)\ttotal: 506ms\tremaining: 9m 3s\n",
      "186:\tlearn: 6.9517177\ttest: 7.9425714\tbest: 7.9425714 (186)\ttotal: 508ms\tremaining: 9m 2s\n",
      "187:\tlearn: 6.9367046\ttest: 7.9284834\tbest: 7.9284834 (187)\ttotal: 510ms\tremaining: 9m 2s\n",
      "188:\tlearn: 6.9264780\ttest: 7.9164359\tbest: 7.9164359 (188)\ttotal: 512ms\tremaining: 9m 1s\n",
      "189:\tlearn: 6.9130537\ttest: 7.9022719\tbest: 7.9022719 (189)\ttotal: 514ms\tremaining: 9m 1s\n",
      "190:\tlearn: 6.9071924\ttest: 7.8969948\tbest: 7.8969948 (190)\ttotal: 517ms\tremaining: 9m\n",
      "191:\tlearn: 6.8937354\ttest: 7.8827742\tbest: 7.8827742 (191)\ttotal: 519ms\tremaining: 9m\n",
      "192:\tlearn: 6.8825380\ttest: 7.8743516\tbest: 7.8743516 (192)\ttotal: 522ms\tremaining: 9m\n",
      "193:\tlearn: 6.8675459\ttest: 7.8617128\tbest: 7.8617128 (193)\ttotal: 525ms\tremaining: 9m\n",
      "194:\tlearn: 6.8597474\ttest: 7.8523387\tbest: 7.8523387 (194)\ttotal: 527ms\tremaining: 9m\n",
      "195:\tlearn: 6.8484964\ttest: 7.8439646\tbest: 7.8439646 (195)\ttotal: 529ms\tremaining: 8m 59s\n",
      "196:\tlearn: 6.8298143\ttest: 7.8307539\tbest: 7.8307539 (196)\ttotal: 532ms\tremaining: 8m 59s\n",
      "197:\tlearn: 6.8235389\ttest: 7.8243680\tbest: 7.8243680 (197)\ttotal: 534ms\tremaining: 8m 58s\n",
      "198:\tlearn: 6.8158968\ttest: 7.8204517\tbest: 7.8204517 (198)\ttotal: 537ms\tremaining: 8m 58s\n",
      "199:\tlearn: 6.7922472\ttest: 7.8005864\tbest: 7.8005864 (199)\ttotal: 539ms\tremaining: 8m 58s\n",
      "200:\tlearn: 6.7763707\ttest: 7.7889871\tbest: 7.7889871 (200)\ttotal: 541ms\tremaining: 8m 57s\n",
      "201:\tlearn: 6.7648137\ttest: 7.7819602\tbest: 7.7819602 (201)\ttotal: 544ms\tremaining: 8m 57s\n",
      "202:\tlearn: 6.7514567\ttest: 7.7707352\tbest: 7.7707352 (202)\ttotal: 546ms\tremaining: 8m 57s\n",
      "203:\tlearn: 6.7357907\ttest: 7.7517190\tbest: 7.7517190 (203)\ttotal: 548ms\tremaining: 8m 57s\n",
      "204:\tlearn: 6.7149007\ttest: 7.7344390\tbest: 7.7344390 (204)\ttotal: 551ms\tremaining: 8m 56s\n",
      "205:\tlearn: 6.6960859\ttest: 7.7187072\tbest: 7.7187072 (205)\ttotal: 553ms\tremaining: 8m 56s\n",
      "206:\tlearn: 6.6833084\ttest: 7.7086138\tbest: 7.7086138 (206)\ttotal: 555ms\tremaining: 8m 55s\n",
      "207:\tlearn: 6.6633559\ttest: 7.6924750\tbest: 7.6924750 (207)\ttotal: 557ms\tremaining: 8m 55s\n",
      "208:\tlearn: 6.6521442\ttest: 7.6822687\tbest: 7.6822687 (208)\ttotal: 560ms\tremaining: 8m 55s\n",
      "209:\tlearn: 6.6453911\ttest: 7.6835832\tbest: 7.6822687 (208)\ttotal: 563ms\tremaining: 8m 55s\n",
      "210:\tlearn: 6.6399240\ttest: 7.6819277\tbest: 7.6819277 (210)\ttotal: 565ms\tremaining: 8m 55s\n",
      "211:\tlearn: 6.6256531\ttest: 7.6732626\tbest: 7.6732626 (211)\ttotal: 568ms\tremaining: 8m 55s\n",
      "212:\tlearn: 6.6092190\ttest: 7.6557664\tbest: 7.6557664 (212)\ttotal: 571ms\tremaining: 8m 55s\n",
      "213:\tlearn: 6.5976684\ttest: 7.6485253\tbest: 7.6485253 (213)\ttotal: 574ms\tremaining: 8m 56s\n",
      "214:\tlearn: 6.5865151\ttest: 7.6380600\tbest: 7.6380600 (214)\ttotal: 578ms\tremaining: 8m 56s\n",
      "215:\tlearn: 6.5730944\ttest: 7.6216924\tbest: 7.6216924 (215)\ttotal: 580ms\tremaining: 8m 56s\n",
      "216:\tlearn: 6.5689181\ttest: 7.6161766\tbest: 7.6161766 (216)\ttotal: 582ms\tremaining: 8m 55s\n",
      "217:\tlearn: 6.5600735\ttest: 7.6133968\tbest: 7.6133968 (217)\ttotal: 586ms\tremaining: 8m 56s\n",
      "218:\tlearn: 6.5447678\ttest: 7.5968013\tbest: 7.5968013 (218)\ttotal: 588ms\tremaining: 8m 56s\n",
      "219:\tlearn: 6.5351619\ttest: 7.5858070\tbest: 7.5858070 (219)\ttotal: 591ms\tremaining: 8m 56s\n",
      "220:\tlearn: 6.5175998\ttest: 7.5663206\tbest: 7.5663206 (220)\ttotal: 593ms\tremaining: 8m 56s\n",
      "221:\tlearn: 6.5109672\ttest: 7.5592813\tbest: 7.5592813 (221)\ttotal: 596ms\tremaining: 8m 56s\n",
      "222:\tlearn: 6.5011853\ttest: 7.5519801\tbest: 7.5519801 (222)\ttotal: 598ms\tremaining: 8m 55s\n",
      "223:\tlearn: 6.4904095\ttest: 7.5467551\tbest: 7.5467551 (223)\ttotal: 600ms\tremaining: 8m 55s\n",
      "224:\tlearn: 6.4873442\ttest: 7.5434727\tbest: 7.5434727 (224)\ttotal: 602ms\tremaining: 8m 54s\n",
      "225:\tlearn: 6.4806731\ttest: 7.5346311\tbest: 7.5346311 (225)\ttotal: 604ms\tremaining: 8m 54s\n",
      "226:\tlearn: 6.4665809\ttest: 7.5292851\tbest: 7.5292851 (226)\ttotal: 606ms\tremaining: 8m 53s\n",
      "227:\tlearn: 6.4533111\ttest: 7.5174582\tbest: 7.5174582 (227)\ttotal: 609ms\tremaining: 8m 53s\n",
      "228:\tlearn: 6.4461218\ttest: 7.5120106\tbest: 7.5120106 (228)\ttotal: 611ms\tremaining: 8m 52s\n",
      "229:\tlearn: 6.4351356\ttest: 7.4997194\tbest: 7.4997194 (229)\ttotal: 613ms\tremaining: 8m 52s\n",
      "230:\tlearn: 6.4261957\ttest: 7.4935528\tbest: 7.4935528 (230)\ttotal: 615ms\tremaining: 8m 51s\n",
      "231:\tlearn: 6.4183174\ttest: 7.4891273\tbest: 7.4891273 (231)\ttotal: 617ms\tremaining: 8m 51s\n",
      "232:\tlearn: 6.4059582\ttest: 7.4771221\tbest: 7.4771221 (232)\ttotal: 619ms\tremaining: 8m 50s\n",
      "233:\tlearn: 6.3936887\ttest: 7.4701800\tbest: 7.4701800 (233)\ttotal: 621ms\tremaining: 8m 50s\n",
      "234:\tlearn: 6.3816296\ttest: 7.4592722\tbest: 7.4592722 (234)\ttotal: 623ms\tremaining: 8m 49s\n",
      "235:\tlearn: 6.3646675\ttest: 7.4497942\tbest: 7.4497942 (235)\ttotal: 626ms\tremaining: 8m 49s\n",
      "236:\tlearn: 6.3584619\ttest: 7.4476456\tbest: 7.4476456 (236)\ttotal: 628ms\tremaining: 8m 49s\n",
      "237:\tlearn: 6.3513304\ttest: 7.4458964\tbest: 7.4458964 (237)\ttotal: 630ms\tremaining: 8m 49s\n",
      "238:\tlearn: 6.3394317\ttest: 7.4335162\tbest: 7.4335162 (238)\ttotal: 633ms\tremaining: 8m 49s\n",
      "239:\tlearn: 6.3272020\ttest: 7.4261635\tbest: 7.4261635 (239)\ttotal: 635ms\tremaining: 8m 48s\n",
      "240:\tlearn: 6.3162678\ttest: 7.4181003\tbest: 7.4181003 (240)\ttotal: 638ms\tremaining: 8m 48s\n",
      "241:\tlearn: 6.3003464\ttest: 7.3966561\tbest: 7.3966561 (241)\ttotal: 640ms\tremaining: 8m 48s\n",
      "242:\tlearn: 6.2879571\ttest: 7.3821165\tbest: 7.3821165 (242)\ttotal: 642ms\tremaining: 8m 48s\n",
      "243:\tlearn: 6.2851368\ttest: 7.3795362\tbest: 7.3795362 (243)\ttotal: 645ms\tremaining: 8m 47s\n",
      "244:\tlearn: 6.2764207\ttest: 7.3727546\tbest: 7.3727546 (244)\ttotal: 647ms\tremaining: 8m 47s\n",
      "245:\tlearn: 6.2699840\ttest: 7.3695815\tbest: 7.3695815 (245)\ttotal: 649ms\tremaining: 8m 46s\n",
      "246:\tlearn: 6.2651623\ttest: 7.3653306\tbest: 7.3653306 (246)\ttotal: 651ms\tremaining: 8m 46s\n",
      "247:\tlearn: 6.2580493\ttest: 7.3622751\tbest: 7.3622751 (247)\ttotal: 653ms\tremaining: 8m 46s\n",
      "248:\tlearn: 6.2493690\ttest: 7.3569902\tbest: 7.3569902 (248)\ttotal: 655ms\tremaining: 8m 45s\n",
      "249:\tlearn: 6.2465632\ttest: 7.3542317\tbest: 7.3542317 (249)\ttotal: 657ms\tremaining: 8m 45s\n",
      "250:\tlearn: 6.2379105\ttest: 7.3443629\tbest: 7.3443629 (250)\ttotal: 659ms\tremaining: 8m 44s\n",
      "251:\tlearn: 6.2226479\ttest: 7.3374200\tbest: 7.3374200 (251)\ttotal: 662ms\tremaining: 8m 44s\n",
      "252:\tlearn: 6.2131889\ttest: 7.3277484\tbest: 7.3277484 (252)\ttotal: 664ms\tremaining: 8m 44s\n",
      "253:\tlearn: 6.2101639\ttest: 7.3268575\tbest: 7.3268575 (253)\ttotal: 667ms\tremaining: 8m 44s\n",
      "254:\tlearn: 6.2082095\ttest: 7.3248100\tbest: 7.3248100 (254)\ttotal: 669ms\tremaining: 8m 44s\n",
      "255:\tlearn: 6.1973192\ttest: 7.3169960\tbest: 7.3169960 (255)\ttotal: 672ms\tremaining: 8m 43s\n",
      "256:\tlearn: 6.1908131\ttest: 7.3115872\tbest: 7.3115872 (256)\ttotal: 674ms\tremaining: 8m 43s\n",
      "257:\tlearn: 6.1825445\ttest: 7.3072689\tbest: 7.3072689 (257)\ttotal: 677ms\tremaining: 8m 43s\n",
      "258:\tlearn: 6.1785801\ttest: 7.3050294\tbest: 7.3050294 (258)\ttotal: 679ms\tremaining: 8m 43s\n",
      "259:\tlearn: 6.1766745\ttest: 7.3044547\tbest: 7.3044547 (259)\ttotal: 682ms\tremaining: 8m 43s\n",
      "260:\tlearn: 6.1716906\ttest: 7.3009364\tbest: 7.3009364 (260)\ttotal: 684ms\tremaining: 8m 43s\n",
      "261:\tlearn: 6.1566286\ttest: 7.2873039\tbest: 7.2873039 (261)\ttotal: 686ms\tremaining: 8m 43s\n",
      "262:\tlearn: 6.1464827\ttest: 7.2835251\tbest: 7.2835251 (262)\ttotal: 688ms\tremaining: 8m 42s\n",
      "263:\tlearn: 6.1444285\ttest: 7.2817724\tbest: 7.2817724 (263)\ttotal: 690ms\tremaining: 8m 42s\n",
      "264:\tlearn: 6.1423081\ttest: 7.2819052\tbest: 7.2817724 (263)\ttotal: 692ms\tremaining: 8m 41s\n",
      "265:\tlearn: 6.1325363\ttest: 7.2733996\tbest: 7.2733996 (265)\ttotal: 695ms\tremaining: 8m 41s\n",
      "266:\tlearn: 6.1233438\ttest: 7.2603527\tbest: 7.2603527 (266)\ttotal: 697ms\tremaining: 8m 41s\n",
      "267:\tlearn: 6.1130612\ttest: 7.2515525\tbest: 7.2515525 (267)\ttotal: 700ms\tremaining: 8m 41s\n",
      "268:\tlearn: 6.1062919\ttest: 7.2479132\tbest: 7.2479132 (268)\ttotal: 702ms\tremaining: 8m 41s\n",
      "269:\tlearn: 6.0986855\ttest: 7.2421957\tbest: 7.2421957 (269)\ttotal: 704ms\tremaining: 8m 41s\n",
      "270:\tlearn: 6.0901051\ttest: 7.2351664\tbest: 7.2351664 (270)\ttotal: 706ms\tremaining: 8m 40s\n",
      "271:\tlearn: 6.0782282\ttest: 7.2206528\tbest: 7.2206528 (271)\ttotal: 708ms\tremaining: 8m 40s\n",
      "272:\tlearn: 6.0742482\ttest: 7.2180657\tbest: 7.2180657 (272)\ttotal: 711ms\tremaining: 8m 40s\n",
      "273:\tlearn: 6.0599569\ttest: 7.2050957\tbest: 7.2050957 (273)\ttotal: 713ms\tremaining: 8m 39s\n",
      "274:\tlearn: 6.0447366\ttest: 7.1853129\tbest: 7.1853129 (274)\ttotal: 716ms\tremaining: 8m 39s\n",
      "275:\tlearn: 6.0302515\ttest: 7.1723095\tbest: 7.1723095 (275)\ttotal: 718ms\tremaining: 8m 39s\n",
      "276:\tlearn: 6.0215915\ttest: 7.1634276\tbest: 7.1634276 (276)\ttotal: 721ms\tremaining: 8m 39s\n",
      "277:\tlearn: 6.0106402\ttest: 7.1540866\tbest: 7.1540866 (277)\ttotal: 723ms\tremaining: 8m 39s\n",
      "278:\tlearn: 5.9904560\ttest: 7.1384992\tbest: 7.1384992 (278)\ttotal: 726ms\tremaining: 8m 39s\n",
      "279:\tlearn: 5.9837866\ttest: 7.1342965\tbest: 7.1342965 (279)\ttotal: 729ms\tremaining: 8m 39s\n",
      "280:\tlearn: 5.9693785\ttest: 7.1184554\tbest: 7.1184554 (280)\ttotal: 732ms\tremaining: 8m 39s\n",
      "281:\tlearn: 5.9566299\ttest: 7.1040756\tbest: 7.1040756 (281)\ttotal: 734ms\tremaining: 8m 39s\n",
      "282:\tlearn: 5.9482834\ttest: 7.0972087\tbest: 7.0972087 (282)\ttotal: 737ms\tremaining: 8m 39s\n",
      "283:\tlearn: 5.9375033\ttest: 7.0852675\tbest: 7.0852675 (283)\ttotal: 739ms\tremaining: 8m 40s\n",
      "284:\tlearn: 5.9319179\ttest: 7.0822890\tbest: 7.0822890 (284)\ttotal: 742ms\tremaining: 8m 40s\n",
      "285:\tlearn: 5.9233526\ttest: 7.0723470\tbest: 7.0723470 (285)\ttotal: 746ms\tremaining: 8m 41s\n",
      "286:\tlearn: 5.9144287\ttest: 7.0692821\tbest: 7.0692821 (286)\ttotal: 748ms\tremaining: 8m 40s\n",
      "287:\tlearn: 5.9082536\ttest: 7.0599326\tbest: 7.0599326 (287)\ttotal: 751ms\tremaining: 8m 40s\n",
      "288:\tlearn: 5.9002103\ttest: 7.0544743\tbest: 7.0544743 (288)\ttotal: 753ms\tremaining: 8m 40s\n",
      "289:\tlearn: 5.8881322\ttest: 7.0455793\tbest: 7.0455793 (289)\ttotal: 755ms\tremaining: 8m 39s\n",
      "290:\tlearn: 5.8827241\ttest: 7.0368926\tbest: 7.0368926 (290)\ttotal: 758ms\tremaining: 8m 40s\n",
      "291:\tlearn: 5.8747378\ttest: 7.0317961\tbest: 7.0317961 (291)\ttotal: 760ms\tremaining: 8m 40s\n",
      "292:\tlearn: 5.8703919\ttest: 7.0245843\tbest: 7.0245843 (292)\ttotal: 764ms\tremaining: 8m 40s\n",
      "293:\tlearn: 5.8650289\ttest: 7.0195662\tbest: 7.0195662 (293)\ttotal: 767ms\tremaining: 8m 40s\n",
      "294:\tlearn: 5.8538309\ttest: 7.0098404\tbest: 7.0098404 (294)\ttotal: 770ms\tremaining: 8m 41s\n",
      "295:\tlearn: 5.8443985\ttest: 6.9971115\tbest: 6.9971115 (295)\ttotal: 772ms\tremaining: 8m 40s\n",
      "296:\tlearn: 5.8371830\ttest: 6.9891958\tbest: 6.9891958 (296)\ttotal: 774ms\tremaining: 8m 40s\n",
      "297:\tlearn: 5.8289768\ttest: 6.9839380\tbest: 6.9839380 (297)\ttotal: 776ms\tremaining: 8m 40s\n",
      "298:\tlearn: 5.8171338\ttest: 6.9724099\tbest: 6.9724099 (298)\ttotal: 778ms\tremaining: 8m 39s\n",
      "299:\tlearn: 5.8126186\ttest: 6.9684295\tbest: 6.9684295 (299)\ttotal: 781ms\tremaining: 8m 39s\n",
      "300:\tlearn: 5.8068779\ttest: 6.9637374\tbest: 6.9637374 (300)\ttotal: 784ms\tremaining: 8m 39s\n",
      "301:\tlearn: 5.8021460\ttest: 6.9563556\tbest: 6.9563556 (301)\ttotal: 786ms\tremaining: 8m 39s\n",
      "302:\tlearn: 5.7974923\ttest: 6.9539663\tbest: 6.9539663 (302)\ttotal: 789ms\tremaining: 8m 39s\n",
      "303:\tlearn: 5.7937023\ttest: 6.9496684\tbest: 6.9496684 (303)\ttotal: 791ms\tremaining: 8m 39s\n",
      "304:\tlearn: 5.7908268\ttest: 6.9465672\tbest: 6.9465672 (304)\ttotal: 793ms\tremaining: 8m 39s\n",
      "305:\tlearn: 5.7842557\ttest: 6.9425843\tbest: 6.9425843 (305)\ttotal: 796ms\tremaining: 8m 39s\n",
      "306:\tlearn: 5.7786114\ttest: 6.9388769\tbest: 6.9388769 (306)\ttotal: 798ms\tremaining: 8m 38s\n",
      "307:\tlearn: 5.7729680\ttest: 6.9372742\tbest: 6.9372742 (307)\ttotal: 801ms\tremaining: 8m 39s\n",
      "308:\tlearn: 5.7637908\ttest: 6.9285128\tbest: 6.9285128 (308)\ttotal: 803ms\tremaining: 8m 38s\n",
      "309:\tlearn: 5.7623302\ttest: 6.9264472\tbest: 6.9264472 (309)\ttotal: 805ms\tremaining: 8m 38s\n",
      "310:\tlearn: 5.7579072\ttest: 6.9236688\tbest: 6.9236688 (310)\ttotal: 807ms\tremaining: 8m 38s\n",
      "311:\tlearn: 5.7535381\ttest: 6.9198347\tbest: 6.9198347 (311)\ttotal: 810ms\tremaining: 8m 38s\n",
      "312:\tlearn: 5.7462721\ttest: 6.9118433\tbest: 6.9118433 (312)\ttotal: 812ms\tremaining: 8m 38s\n",
      "313:\tlearn: 5.7414985\ttest: 6.9097265\tbest: 6.9097265 (313)\ttotal: 814ms\tremaining: 8m 37s\n",
      "314:\tlearn: 5.7360766\ttest: 6.9058901\tbest: 6.9058901 (314)\ttotal: 817ms\tremaining: 8m 37s\n",
      "315:\tlearn: 5.7280455\ttest: 6.8990446\tbest: 6.8990446 (315)\ttotal: 819ms\tremaining: 8m 37s\n",
      "316:\tlearn: 5.7243808\ttest: 6.8964320\tbest: 6.8964320 (316)\ttotal: 822ms\tremaining: 8m 37s\n",
      "317:\tlearn: 5.7177060\ttest: 6.8935349\tbest: 6.8935349 (317)\ttotal: 824ms\tremaining: 8m 37s\n",
      "318:\tlearn: 5.7150643\ttest: 6.8920883\tbest: 6.8920883 (318)\ttotal: 826ms\tremaining: 8m 37s\n",
      "319:\tlearn: 5.7078983\ttest: 6.8881488\tbest: 6.8881488 (319)\ttotal: 828ms\tremaining: 8m 36s\n",
      "320:\tlearn: 5.6989840\ttest: 6.8761966\tbest: 6.8761966 (320)\ttotal: 830ms\tremaining: 8m 36s\n",
      "321:\tlearn: 5.6971694\ttest: 6.8747986\tbest: 6.8747986 (321)\ttotal: 833ms\tremaining: 8m 36s\n",
      "322:\tlearn: 5.6914692\ttest: 6.8744918\tbest: 6.8744918 (322)\ttotal: 835ms\tremaining: 8m 36s\n",
      "323:\tlearn: 5.6875256\ttest: 6.8718066\tbest: 6.8718066 (323)\ttotal: 837ms\tremaining: 8m 36s\n",
      "324:\tlearn: 5.6827717\ttest: 6.8682880\tbest: 6.8682880 (324)\ttotal: 839ms\tremaining: 8m 35s\n",
      "325:\tlearn: 5.6770763\ttest: 6.8639427\tbest: 6.8639427 (325)\ttotal: 842ms\tremaining: 8m 35s\n",
      "326:\tlearn: 5.6733044\ttest: 6.8628180\tbest: 6.8628180 (326)\ttotal: 844ms\tremaining: 8m 35s\n",
      "327:\tlearn: 5.6690858\ttest: 6.8579772\tbest: 6.8579772 (327)\ttotal: 846ms\tremaining: 8m 35s\n",
      "328:\tlearn: 5.6611134\ttest: 6.8558755\tbest: 6.8558755 (328)\ttotal: 849ms\tremaining: 8m 35s\n",
      "329:\tlearn: 5.6541681\ttest: 6.8469771\tbest: 6.8469771 (329)\ttotal: 852ms\tremaining: 8m 35s\n",
      "330:\tlearn: 5.6467555\ttest: 6.8421554\tbest: 6.8421554 (330)\ttotal: 854ms\tremaining: 8m 34s\n",
      "331:\tlearn: 5.6432642\ttest: 6.8402554\tbest: 6.8402554 (331)\ttotal: 856ms\tremaining: 8m 34s\n",
      "332:\tlearn: 5.6380659\ttest: 6.8367371\tbest: 6.8367371 (332)\ttotal: 858ms\tremaining: 8m 34s\n",
      "333:\tlearn: 5.6350694\ttest: 6.8341778\tbest: 6.8341778 (333)\ttotal: 860ms\tremaining: 8m 34s\n",
      "334:\tlearn: 5.6286036\ttest: 6.8305204\tbest: 6.8305204 (334)\ttotal: 863ms\tremaining: 8m 34s\n",
      "335:\tlearn: 5.6249073\ttest: 6.8286887\tbest: 6.8286887 (335)\ttotal: 865ms\tremaining: 8m 34s\n",
      "336:\tlearn: 5.6230492\ttest: 6.8303377\tbest: 6.8286887 (335)\ttotal: 868ms\tremaining: 8m 34s\n",
      "337:\tlearn: 5.6205812\ttest: 6.8296362\tbest: 6.8286887 (335)\ttotal: 870ms\tremaining: 8m 34s\n",
      "338:\tlearn: 5.6182002\ttest: 6.8289405\tbest: 6.8286887 (335)\ttotal: 872ms\tremaining: 8m 33s\n",
      "339:\tlearn: 5.6116885\ttest: 6.8236719\tbest: 6.8236719 (339)\ttotal: 875ms\tremaining: 8m 33s\n",
      "340:\tlearn: 5.6084613\ttest: 6.8236324\tbest: 6.8236324 (340)\ttotal: 878ms\tremaining: 8m 34s\n",
      "341:\tlearn: 5.6032154\ttest: 6.8197304\tbest: 6.8197304 (341)\ttotal: 880ms\tremaining: 8m 33s\n",
      "342:\tlearn: 5.5971810\ttest: 6.8165128\tbest: 6.8165128 (342)\ttotal: 882ms\tremaining: 8m 33s\n",
      "343:\tlearn: 5.5920404\ttest: 6.8113394\tbest: 6.8113394 (343)\ttotal: 884ms\tremaining: 8m 33s\n",
      "344:\tlearn: 5.5853921\ttest: 6.8076323\tbest: 6.8076323 (344)\ttotal: 886ms\tremaining: 8m 32s\n",
      "345:\tlearn: 5.5834197\ttest: 6.8072405\tbest: 6.8072405 (345)\ttotal: 888ms\tremaining: 8m 32s\n",
      "346:\tlearn: 5.5778009\ttest: 6.8035326\tbest: 6.8035326 (346)\ttotal: 891ms\tremaining: 8m 32s\n",
      "347:\tlearn: 5.5750288\ttest: 6.8020992\tbest: 6.8020992 (347)\ttotal: 893ms\tremaining: 8m 32s\n",
      "348:\tlearn: 5.5725882\ttest: 6.8008428\tbest: 6.8008428 (348)\ttotal: 895ms\tremaining: 8m 32s\n",
      "349:\tlearn: 5.5671058\ttest: 6.7956377\tbest: 6.7956377 (349)\ttotal: 898ms\tremaining: 8m 32s\n",
      "350:\tlearn: 5.5587030\ttest: 6.7928465\tbest: 6.7928465 (350)\ttotal: 901ms\tremaining: 8m 32s\n",
      "351:\tlearn: 5.5557644\ttest: 6.7906934\tbest: 6.7906934 (351)\ttotal: 904ms\tremaining: 8m 32s\n",
      "352:\tlearn: 5.5510633\ttest: 6.7887968\tbest: 6.7887968 (352)\ttotal: 906ms\tremaining: 8m 32s\n",
      "353:\tlearn: 5.5475664\ttest: 6.7827147\tbest: 6.7827147 (353)\ttotal: 909ms\tremaining: 8m 32s\n",
      "354:\tlearn: 5.5433344\ttest: 6.7758752\tbest: 6.7758752 (354)\ttotal: 911ms\tremaining: 8m 32s\n",
      "355:\tlearn: 5.5409475\ttest: 6.7767556\tbest: 6.7758752 (354)\ttotal: 914ms\tremaining: 8m 32s\n",
      "356:\tlearn: 5.5380132\ttest: 6.7751486\tbest: 6.7751486 (356)\ttotal: 916ms\tremaining: 8m 32s\n",
      "357:\tlearn: 5.5344307\ttest: 6.7697951\tbest: 6.7697951 (357)\ttotal: 918ms\tremaining: 8m 31s\n",
      "358:\tlearn: 5.5271253\ttest: 6.7642883\tbest: 6.7642883 (358)\ttotal: 920ms\tremaining: 8m 31s\n",
      "359:\tlearn: 5.5230148\ttest: 6.7617450\tbest: 6.7617450 (359)\ttotal: 922ms\tremaining: 8m 31s\n",
      "360:\tlearn: 5.5168890\ttest: 6.7598498\tbest: 6.7598498 (360)\ttotal: 925ms\tremaining: 8m 31s\n",
      "361:\tlearn: 5.5090583\ttest: 6.7521471\tbest: 6.7521471 (361)\ttotal: 929ms\tremaining: 8m 32s\n",
      "362:\tlearn: 5.5047700\ttest: 6.7488105\tbest: 6.7488105 (362)\ttotal: 932ms\tremaining: 8m 32s\n",
      "363:\tlearn: 5.5027216\ttest: 6.7475486\tbest: 6.7475486 (363)\ttotal: 935ms\tremaining: 8m 32s\n",
      "364:\tlearn: 5.4978548\ttest: 6.7428212\tbest: 6.7428212 (364)\ttotal: 938ms\tremaining: 8m 33s\n",
      "365:\tlearn: 5.4967484\ttest: 6.7415274\tbest: 6.7415274 (365)\ttotal: 941ms\tremaining: 8m 33s\n",
      "366:\tlearn: 5.4940623\ttest: 6.7389916\tbest: 6.7389916 (366)\ttotal: 944ms\tremaining: 8m 33s\n",
      "367:\tlearn: 5.4928348\ttest: 6.7390105\tbest: 6.7389916 (366)\ttotal: 946ms\tremaining: 8m 33s\n",
      "368:\tlearn: 5.4863630\ttest: 6.7286165\tbest: 6.7286165 (368)\ttotal: 948ms\tremaining: 8m 32s\n",
      "369:\tlearn: 5.4818983\ttest: 6.7264047\tbest: 6.7264047 (369)\ttotal: 950ms\tremaining: 8m 32s\n",
      "370:\tlearn: 5.4780938\ttest: 6.7217307\tbest: 6.7217307 (370)\ttotal: 952ms\tremaining: 8m 32s\n",
      "371:\tlearn: 5.4719143\ttest: 6.7131835\tbest: 6.7131835 (371)\ttotal: 955ms\tremaining: 8m 32s\n",
      "372:\tlearn: 5.4687876\ttest: 6.7097693\tbest: 6.7097693 (372)\ttotal: 957ms\tremaining: 8m 32s\n",
      "373:\tlearn: 5.4648156\ttest: 6.7064480\tbest: 6.7064480 (373)\ttotal: 960ms\tremaining: 8m 32s\n",
      "374:\tlearn: 5.4615372\ttest: 6.7018993\tbest: 6.7018993 (374)\ttotal: 962ms\tremaining: 8m 32s\n",
      "375:\tlearn: 5.4578547\ttest: 6.6991864\tbest: 6.6991864 (375)\ttotal: 964ms\tremaining: 8m 31s\n",
      "376:\tlearn: 5.4549992\ttest: 6.6962576\tbest: 6.6962576 (376)\ttotal: 966ms\tremaining: 8m 31s\n",
      "377:\tlearn: 5.4481882\ttest: 6.6880521\tbest: 6.6880521 (377)\ttotal: 968ms\tremaining: 8m 31s\n",
      "378:\tlearn: 5.4445216\ttest: 6.6882870\tbest: 6.6880521 (377)\ttotal: 971ms\tremaining: 8m 31s\n",
      "379:\tlearn: 5.4404074\ttest: 6.6869607\tbest: 6.6869607 (379)\ttotal: 974ms\tremaining: 8m 31s\n",
      "380:\tlearn: 5.4348042\ttest: 6.6816922\tbest: 6.6816922 (380)\ttotal: 977ms\tremaining: 8m 31s\n",
      "381:\tlearn: 5.4304576\ttest: 6.6788077\tbest: 6.6788077 (381)\ttotal: 979ms\tremaining: 8m 31s\n",
      "382:\tlearn: 5.4281085\ttest: 6.6746649\tbest: 6.6746649 (382)\ttotal: 982ms\tremaining: 8m 31s\n",
      "383:\tlearn: 5.4250772\ttest: 6.6724871\tbest: 6.6724871 (383)\ttotal: 984ms\tremaining: 8m 31s\n",
      "384:\tlearn: 5.4192991\ttest: 6.6679737\tbest: 6.6679737 (384)\ttotal: 987ms\tremaining: 8m 31s\n",
      "385:\tlearn: 5.4157749\ttest: 6.6672410\tbest: 6.6672410 (385)\ttotal: 989ms\tremaining: 8m 31s\n",
      "386:\tlearn: 5.4126826\ttest: 6.6646733\tbest: 6.6646733 (386)\ttotal: 992ms\tremaining: 8m 31s\n",
      "387:\tlearn: 5.4107949\ttest: 6.6643458\tbest: 6.6643458 (387)\ttotal: 994ms\tremaining: 8m 31s\n",
      "388:\tlearn: 5.4071026\ttest: 6.6604252\tbest: 6.6604252 (388)\ttotal: 997ms\tremaining: 8m 31s\n",
      "389:\tlearn: 5.4049268\ttest: 6.6587208\tbest: 6.6587208 (389)\ttotal: 999ms\tremaining: 8m 31s\n",
      "390:\tlearn: 5.4011248\ttest: 6.6565763\tbest: 6.6565763 (390)\ttotal: 1s\tremaining: 8m 31s\n",
      "391:\tlearn: 5.3976388\ttest: 6.6530140\tbest: 6.6530140 (391)\ttotal: 1s\tremaining: 8m 31s\n",
      "392:\tlearn: 5.3940903\ttest: 6.6488492\tbest: 6.6488492 (392)\ttotal: 1.01s\tremaining: 8m 31s\n",
      "393:\tlearn: 5.3910959\ttest: 6.6474155\tbest: 6.6474155 (393)\ttotal: 1.01s\tremaining: 8m 30s\n",
      "394:\tlearn: 5.3869764\ttest: 6.6451424\tbest: 6.6451424 (394)\ttotal: 1.01s\tremaining: 8m 30s\n",
      "395:\tlearn: 5.3853252\ttest: 6.6442703\tbest: 6.6442703 (395)\ttotal: 1.01s\tremaining: 8m 30s\n",
      "396:\tlearn: 5.3836123\ttest: 6.6420754\tbest: 6.6420754 (396)\ttotal: 1.01s\tremaining: 8m 30s\n",
      "397:\tlearn: 5.3816619\ttest: 6.6415242\tbest: 6.6415242 (397)\ttotal: 1.02s\tremaining: 8m 30s\n",
      "398:\tlearn: 5.3789725\ttest: 6.6410590\tbest: 6.6410590 (398)\ttotal: 1.02s\tremaining: 8m 30s\n",
      "399:\tlearn: 5.3735581\ttest: 6.6394281\tbest: 6.6394281 (399)\ttotal: 1.02s\tremaining: 8m 30s\n",
      "400:\tlearn: 5.3709096\ttest: 6.6359747\tbest: 6.6359747 (400)\ttotal: 1.03s\tremaining: 8m 30s\n",
      "401:\tlearn: 5.3653548\ttest: 6.6299809\tbest: 6.6299809 (401)\ttotal: 1.03s\tremaining: 8m 30s\n",
      "402:\tlearn: 5.3600781\ttest: 6.6276139\tbest: 6.6276139 (402)\ttotal: 1.03s\tremaining: 8m 31s\n",
      "403:\tlearn: 5.3538695\ttest: 6.6237898\tbest: 6.6237898 (403)\ttotal: 1.03s\tremaining: 8m 31s\n",
      "404:\tlearn: 5.3505468\ttest: 6.6228390\tbest: 6.6228390 (404)\ttotal: 1.04s\tremaining: 8m 30s\n",
      "405:\tlearn: 5.3462487\ttest: 6.6185860\tbest: 6.6185860 (405)\ttotal: 1.04s\tremaining: 8m 30s\n",
      "406:\tlearn: 5.3440813\ttest: 6.6170513\tbest: 6.6170513 (406)\ttotal: 1.04s\tremaining: 8m 30s\n",
      "407:\tlearn: 5.3375413\ttest: 6.6146563\tbest: 6.6146563 (407)\ttotal: 1.04s\tremaining: 8m 30s\n",
      "408:\tlearn: 5.3351316\ttest: 6.6140379\tbest: 6.6140379 (408)\ttotal: 1.05s\tremaining: 8m 30s\n",
      "409:\tlearn: 5.3301285\ttest: 6.6105377\tbest: 6.6105377 (409)\ttotal: 1.05s\tremaining: 8m 30s\n",
      "410:\tlearn: 5.3238759\ttest: 6.6055050\tbest: 6.6055050 (410)\ttotal: 1.05s\tremaining: 8m 30s\n",
      "411:\tlearn: 5.3130538\ttest: 6.5954345\tbest: 6.5954345 (411)\ttotal: 1.05s\tremaining: 8m 30s\n",
      "412:\tlearn: 5.3058098\ttest: 6.5892235\tbest: 6.5892235 (412)\ttotal: 1.06s\tremaining: 8m 30s\n",
      "413:\tlearn: 5.2965696\ttest: 6.5807023\tbest: 6.5807023 (413)\ttotal: 1.06s\tremaining: 8m 30s\n",
      "414:\tlearn: 5.2894744\ttest: 6.5722916\tbest: 6.5722916 (414)\ttotal: 1.06s\tremaining: 8m 30s\n",
      "415:\tlearn: 5.2815148\ttest: 6.5654857\tbest: 6.5654857 (415)\ttotal: 1.06s\tremaining: 8m 30s\n",
      "416:\tlearn: 5.2745877\ttest: 6.5589298\tbest: 6.5589298 (416)\ttotal: 1.07s\tremaining: 8m 30s\n",
      "417:\tlearn: 5.2674497\ttest: 6.5535690\tbest: 6.5535690 (417)\ttotal: 1.07s\tremaining: 8m 30s\n",
      "418:\tlearn: 5.2617644\ttest: 6.5467348\tbest: 6.5467348 (418)\ttotal: 1.07s\tremaining: 8m 30s\n",
      "419:\tlearn: 5.2587452\ttest: 6.5453720\tbest: 6.5453720 (419)\ttotal: 1.07s\tremaining: 8m 30s\n",
      "420:\tlearn: 5.2548496\ttest: 6.5436572\tbest: 6.5436572 (420)\ttotal: 1.08s\tremaining: 8m 30s\n",
      "421:\tlearn: 5.2506126\ttest: 6.5417129\tbest: 6.5417129 (421)\ttotal: 1.08s\tremaining: 8m 30s\n",
      "422:\tlearn: 5.2484302\ttest: 6.5417403\tbest: 6.5417129 (421)\ttotal: 1.08s\tremaining: 8m 30s\n",
      "423:\tlearn: 5.2443105\ttest: 6.5408271\tbest: 6.5408271 (423)\ttotal: 1.08s\tremaining: 8m 30s\n",
      "424:\tlearn: 5.2403807\ttest: 6.5386506\tbest: 6.5386506 (424)\ttotal: 1.09s\tremaining: 8m 30s\n",
      "425:\tlearn: 5.2359789\ttest: 6.5377029\tbest: 6.5377029 (425)\ttotal: 1.09s\tremaining: 8m 30s\n",
      "426:\tlearn: 5.2332880\ttest: 6.5357146\tbest: 6.5357146 (426)\ttotal: 1.09s\tremaining: 8m 30s\n",
      "427:\tlearn: 5.2314936\ttest: 6.5360216\tbest: 6.5357146 (426)\ttotal: 1.09s\tremaining: 8m 30s\n",
      "428:\tlearn: 5.2265577\ttest: 6.5298506\tbest: 6.5298506 (428)\ttotal: 1.1s\tremaining: 8m 30s\n",
      "429:\tlearn: 5.2227082\ttest: 6.5297477\tbest: 6.5297477 (429)\ttotal: 1.1s\tremaining: 8m 30s\n",
      "430:\tlearn: 5.2199963\ttest: 6.5280441\tbest: 6.5280441 (430)\ttotal: 1.1s\tremaining: 8m 30s\n",
      "431:\tlearn: 5.2116335\ttest: 6.5229559\tbest: 6.5229559 (431)\ttotal: 1.1s\tremaining: 8m 30s\n",
      "432:\tlearn: 5.2079802\ttest: 6.5212948\tbest: 6.5212948 (432)\ttotal: 1.11s\tremaining: 8m 30s\n",
      "433:\tlearn: 5.2062089\ttest: 6.5198346\tbest: 6.5198346 (433)\ttotal: 1.11s\tremaining: 8m 30s\n",
      "434:\tlearn: 5.1989945\ttest: 6.5126845\tbest: 6.5126845 (434)\ttotal: 1.11s\tremaining: 8m 30s\n",
      "435:\tlearn: 5.1954301\ttest: 6.5075231\tbest: 6.5075231 (435)\ttotal: 1.12s\tremaining: 8m 30s\n",
      "436:\tlearn: 5.1904287\ttest: 6.5005688\tbest: 6.5005688 (436)\ttotal: 1.12s\tremaining: 8m 30s\n",
      "437:\tlearn: 5.1880725\ttest: 6.4980088\tbest: 6.4980088 (437)\ttotal: 1.12s\tremaining: 8m 30s\n",
      "438:\tlearn: 5.1833257\ttest: 6.4937191\tbest: 6.4937191 (438)\ttotal: 1.12s\tremaining: 8m 30s\n",
      "439:\tlearn: 5.1800296\ttest: 6.4902039\tbest: 6.4902039 (439)\ttotal: 1.13s\tremaining: 8m 30s\n",
      "440:\tlearn: 5.1742423\ttest: 6.4856793\tbest: 6.4856793 (440)\ttotal: 1.13s\tremaining: 8m 30s\n",
      "441:\tlearn: 5.1703202\ttest: 6.4820056\tbest: 6.4820056 (441)\ttotal: 1.13s\tremaining: 8m 30s\n",
      "442:\tlearn: 5.1688127\ttest: 6.4814621\tbest: 6.4814621 (442)\ttotal: 1.13s\tremaining: 8m 30s\n",
      "443:\tlearn: 5.1675372\ttest: 6.4805645\tbest: 6.4805645 (443)\ttotal: 1.14s\tremaining: 8m 30s\n",
      "444:\tlearn: 5.1660175\ttest: 6.4802771\tbest: 6.4802771 (444)\ttotal: 1.14s\tremaining: 8m 30s\n",
      "445:\tlearn: 5.1632392\ttest: 6.4795559\tbest: 6.4795559 (445)\ttotal: 1.14s\tremaining: 8m 31s\n",
      "446:\tlearn: 5.1622494\ttest: 6.4787041\tbest: 6.4787041 (446)\ttotal: 1.14s\tremaining: 8m 31s\n",
      "447:\tlearn: 5.1609627\ttest: 6.4785070\tbest: 6.4785070 (447)\ttotal: 1.15s\tremaining: 8m 31s\n",
      "448:\tlearn: 5.1595339\ttest: 6.4775143\tbest: 6.4775143 (448)\ttotal: 1.15s\tremaining: 8m 32s\n",
      "449:\tlearn: 5.1586420\ttest: 6.4770587\tbest: 6.4770587 (449)\ttotal: 1.16s\tremaining: 8m 32s\n",
      "450:\tlearn: 5.1574366\ttest: 6.4771881\tbest: 6.4770587 (449)\ttotal: 1.16s\tremaining: 8m 32s\n",
      "451:\tlearn: 5.1524248\ttest: 6.4755692\tbest: 6.4755692 (451)\ttotal: 1.16s\tremaining: 8m 32s\n",
      "452:\tlearn: 5.1509871\ttest: 6.4754610\tbest: 6.4754610 (452)\ttotal: 1.17s\tremaining: 8m 33s\n",
      "453:\tlearn: 5.1447491\ttest: 6.4709441\tbest: 6.4709441 (453)\ttotal: 1.17s\tremaining: 8m 34s\n",
      "454:\tlearn: 5.1437464\ttest: 6.4704420\tbest: 6.4704420 (454)\ttotal: 1.17s\tremaining: 8m 34s\n",
      "455:\tlearn: 5.1416403\ttest: 6.4697723\tbest: 6.4697723 (455)\ttotal: 1.18s\tremaining: 8m 34s\n",
      "456:\tlearn: 5.1352369\ttest: 6.4616354\tbest: 6.4616354 (456)\ttotal: 1.18s\tremaining: 8m 35s\n",
      "457:\tlearn: 5.1315361\ttest: 6.4598601\tbest: 6.4598601 (457)\ttotal: 1.18s\tremaining: 8m 35s\n",
      "458:\tlearn: 5.1304802\ttest: 6.4594860\tbest: 6.4594860 (458)\ttotal: 1.18s\tremaining: 8m 35s\n",
      "459:\tlearn: 5.1296007\ttest: 6.4590488\tbest: 6.4590488 (459)\ttotal: 1.19s\tremaining: 8m 35s\n",
      "460:\tlearn: 5.1227613\ttest: 6.4523767\tbest: 6.4523767 (460)\ttotal: 1.19s\tremaining: 8m 35s\n",
      "461:\tlearn: 5.1209239\ttest: 6.4508903\tbest: 6.4508903 (461)\ttotal: 1.19s\tremaining: 8m 35s\n",
      "462:\tlearn: 5.1190043\ttest: 6.4495079\tbest: 6.4495079 (462)\ttotal: 1.2s\tremaining: 8m 35s\n",
      "463:\tlearn: 5.1176028\ttest: 6.4495316\tbest: 6.4495079 (462)\ttotal: 1.2s\tremaining: 8m 35s\n",
      "464:\tlearn: 5.1130957\ttest: 6.4482447\tbest: 6.4482447 (464)\ttotal: 1.2s\tremaining: 8m 35s\n",
      "465:\tlearn: 5.1085588\ttest: 6.4454462\tbest: 6.4454462 (465)\ttotal: 1.2s\tremaining: 8m 35s\n",
      "466:\tlearn: 5.1067577\ttest: 6.4441602\tbest: 6.4441602 (466)\ttotal: 1.21s\tremaining: 8m 35s\n",
      "467:\tlearn: 5.1062025\ttest: 6.4440164\tbest: 6.4440164 (467)\ttotal: 1.21s\tremaining: 8m 35s\n",
      "468:\tlearn: 5.1042417\ttest: 6.4433433\tbest: 6.4433433 (468)\ttotal: 1.21s\tremaining: 8m 35s\n",
      "469:\tlearn: 5.1026886\ttest: 6.4419874\tbest: 6.4419874 (469)\ttotal: 1.21s\tremaining: 8m 34s\n",
      "470:\tlearn: 5.1004539\ttest: 6.4420844\tbest: 6.4419874 (469)\ttotal: 1.22s\tremaining: 8m 34s\n",
      "471:\tlearn: 5.0970118\ttest: 6.4401546\tbest: 6.4401546 (471)\ttotal: 1.22s\tremaining: 8m 34s\n",
      "472:\tlearn: 5.0915638\ttest: 6.4364916\tbest: 6.4364916 (472)\ttotal: 1.22s\tremaining: 8m 34s\n",
      "473:\tlearn: 5.0884802\ttest: 6.4352562\tbest: 6.4352562 (473)\ttotal: 1.22s\tremaining: 8m 34s\n",
      "474:\tlearn: 5.0858431\ttest: 6.4333479\tbest: 6.4333479 (474)\ttotal: 1.23s\tremaining: 8m 35s\n",
      "475:\tlearn: 5.0798092\ttest: 6.4321222\tbest: 6.4321222 (475)\ttotal: 1.23s\tremaining: 8m 35s\n",
      "476:\tlearn: 5.0786480\ttest: 6.4312428\tbest: 6.4312428 (476)\ttotal: 1.23s\tremaining: 8m 35s\n",
      "477:\tlearn: 5.0771397\ttest: 6.4305227\tbest: 6.4305227 (477)\ttotal: 1.23s\tremaining: 8m 35s\n",
      "478:\tlearn: 5.0725914\ttest: 6.4261972\tbest: 6.4261972 (478)\ttotal: 1.24s\tremaining: 8m 35s\n",
      "479:\tlearn: 5.0709725\ttest: 6.4260055\tbest: 6.4260055 (479)\ttotal: 1.24s\tremaining: 8m 36s\n",
      "480:\tlearn: 5.0675188\ttest: 6.4251629\tbest: 6.4251629 (480)\ttotal: 1.25s\tremaining: 8m 36s\n",
      "481:\tlearn: 5.0650635\ttest: 6.4238999\tbest: 6.4238999 (481)\ttotal: 1.25s\tremaining: 8m 37s\n",
      "482:\tlearn: 5.0642468\ttest: 6.4236153\tbest: 6.4236153 (482)\ttotal: 1.25s\tremaining: 8m 37s\n",
      "483:\tlearn: 5.0628000\ttest: 6.4224932\tbest: 6.4224932 (483)\ttotal: 1.25s\tremaining: 8m 37s\n",
      "484:\tlearn: 5.0593571\ttest: 6.4213471\tbest: 6.4213471 (484)\ttotal: 1.26s\tremaining: 8m 37s\n",
      "485:\tlearn: 5.0560320\ttest: 6.4186731\tbest: 6.4186731 (485)\ttotal: 1.26s\tremaining: 8m 37s\n",
      "486:\tlearn: 5.0552200\ttest: 6.4180246\tbest: 6.4180246 (486)\ttotal: 1.26s\tremaining: 8m 38s\n",
      "487:\tlearn: 5.0489731\ttest: 6.4124282\tbest: 6.4124282 (487)\ttotal: 1.27s\tremaining: 8m 38s\n",
      "488:\tlearn: 5.0454770\ttest: 6.4126429\tbest: 6.4124282 (487)\ttotal: 1.27s\tremaining: 8m 38s\n",
      "489:\tlearn: 5.0402230\ttest: 6.4097083\tbest: 6.4097083 (489)\ttotal: 1.27s\tremaining: 8m 38s\n",
      "490:\tlearn: 5.0348953\ttest: 6.4077203\tbest: 6.4077203 (490)\ttotal: 1.28s\tremaining: 8m 38s\n",
      "491:\tlearn: 5.0333890\ttest: 6.4057745\tbest: 6.4057745 (491)\ttotal: 1.28s\tremaining: 8m 39s\n",
      "492:\tlearn: 5.0272577\ttest: 6.4026525\tbest: 6.4026525 (492)\ttotal: 1.28s\tremaining: 8m 39s\n",
      "493:\tlearn: 5.0226973\ttest: 6.4010249\tbest: 6.4010249 (493)\ttotal: 1.28s\tremaining: 8m 39s\n",
      "494:\tlearn: 5.0183907\ttest: 6.4007052\tbest: 6.4007052 (494)\ttotal: 1.29s\tremaining: 8m 39s\n",
      "495:\tlearn: 5.0152211\ttest: 6.3991627\tbest: 6.3991627 (495)\ttotal: 1.29s\tremaining: 8m 39s\n",
      "496:\tlearn: 5.0136556\ttest: 6.3978616\tbest: 6.3978616 (496)\ttotal: 1.29s\tremaining: 8m 39s\n",
      "497:\tlearn: 5.0079659\ttest: 6.3955316\tbest: 6.3955316 (497)\ttotal: 1.3s\tremaining: 8m 39s\n",
      "498:\tlearn: 5.0039351\ttest: 6.3911104\tbest: 6.3911104 (498)\ttotal: 1.3s\tremaining: 8m 39s\n",
      "499:\tlearn: 5.0028402\ttest: 6.3903713\tbest: 6.3903713 (499)\ttotal: 1.3s\tremaining: 8m 39s\n",
      "500:\tlearn: 5.0010567\ttest: 6.3887171\tbest: 6.3887171 (500)\ttotal: 1.3s\tremaining: 8m 39s\n",
      "501:\tlearn: 4.9965261\ttest: 6.3898417\tbest: 6.3887171 (500)\ttotal: 1.31s\tremaining: 8m 39s\n",
      "502:\tlearn: 4.9946184\ttest: 6.3882706\tbest: 6.3882706 (502)\ttotal: 1.31s\tremaining: 8m 39s\n",
      "503:\tlearn: 4.9909694\ttest: 6.3857157\tbest: 6.3857157 (503)\ttotal: 1.31s\tremaining: 8m 38s\n",
      "504:\tlearn: 4.9862647\ttest: 6.3834788\tbest: 6.3834788 (504)\ttotal: 1.31s\tremaining: 8m 38s\n",
      "505:\tlearn: 4.9829989\ttest: 6.3808803\tbest: 6.3808803 (505)\ttotal: 1.31s\tremaining: 8m 38s\n",
      "506:\tlearn: 4.9797332\ttest: 6.3784705\tbest: 6.3784705 (506)\ttotal: 1.32s\tremaining: 8m 38s\n",
      "507:\tlearn: 4.9758288\ttest: 6.3736430\tbest: 6.3736430 (507)\ttotal: 1.32s\tremaining: 8m 38s\n",
      "508:\tlearn: 4.9736949\ttest: 6.3713885\tbest: 6.3713885 (508)\ttotal: 1.32s\tremaining: 8m 38s\n",
      "509:\tlearn: 4.9717743\ttest: 6.3699847\tbest: 6.3699847 (509)\ttotal: 1.33s\tremaining: 8m 38s\n",
      "510:\tlearn: 4.9696430\ttest: 6.3699075\tbest: 6.3699075 (510)\ttotal: 1.33s\tremaining: 8m 38s\n",
      "511:\tlearn: 4.9664950\ttest: 6.3679397\tbest: 6.3679397 (511)\ttotal: 1.33s\tremaining: 8m 38s\n",
      "512:\tlearn: 4.9636796\ttest: 6.3652668\tbest: 6.3652668 (512)\ttotal: 1.33s\tremaining: 8m 38s\n",
      "513:\tlearn: 4.9618815\ttest: 6.3650413\tbest: 6.3650413 (513)\ttotal: 1.33s\tremaining: 8m 38s\n",
      "514:\tlearn: 4.9607152\ttest: 6.3643811\tbest: 6.3643811 (514)\ttotal: 1.34s\tremaining: 8m 37s\n",
      "515:\tlearn: 4.9564932\ttest: 6.3620900\tbest: 6.3620900 (515)\ttotal: 1.34s\tremaining: 8m 37s\n",
      "516:\tlearn: 4.9507157\ttest: 6.3552818\tbest: 6.3552818 (516)\ttotal: 1.34s\tremaining: 8m 37s\n",
      "517:\tlearn: 4.9483133\ttest: 6.3543115\tbest: 6.3543115 (517)\ttotal: 1.34s\tremaining: 8m 37s\n",
      "518:\tlearn: 4.9446527\ttest: 6.3489977\tbest: 6.3489977 (518)\ttotal: 1.34s\tremaining: 8m 37s\n",
      "519:\tlearn: 4.9429721\ttest: 6.3472772\tbest: 6.3472772 (519)\ttotal: 1.35s\tremaining: 8m 36s\n",
      "520:\tlearn: 4.9398380\ttest: 6.3463872\tbest: 6.3463872 (520)\ttotal: 1.35s\tremaining: 8m 36s\n",
      "521:\tlearn: 4.9339882\ttest: 6.3428897\tbest: 6.3428897 (521)\ttotal: 1.35s\tremaining: 8m 36s\n",
      "522:\tlearn: 4.9327955\ttest: 6.3428753\tbest: 6.3428753 (522)\ttotal: 1.35s\tremaining: 8m 36s\n",
      "523:\tlearn: 4.9306939\ttest: 6.3426521\tbest: 6.3426521 (523)\ttotal: 1.36s\tremaining: 8m 36s\n",
      "524:\tlearn: 4.9285707\ttest: 6.3409093\tbest: 6.3409093 (524)\ttotal: 1.36s\tremaining: 8m 36s\n",
      "525:\tlearn: 4.9227017\ttest: 6.3372457\tbest: 6.3372457 (525)\ttotal: 1.36s\tremaining: 8m 35s\n",
      "526:\tlearn: 4.9186403\ttest: 6.3347572\tbest: 6.3347572 (526)\ttotal: 1.36s\tremaining: 8m 35s\n",
      "527:\tlearn: 4.9170073\ttest: 6.3329219\tbest: 6.3329219 (527)\ttotal: 1.36s\tremaining: 8m 35s\n",
      "528:\tlearn: 4.9118495\ttest: 6.3297311\tbest: 6.3297311 (528)\ttotal: 1.37s\tremaining: 8m 35s\n",
      "529:\tlearn: 4.9063670\ttest: 6.3233833\tbest: 6.3233833 (529)\ttotal: 1.37s\tremaining: 8m 35s\n",
      "530:\tlearn: 4.8980707\ttest: 6.3168160\tbest: 6.3168160 (530)\ttotal: 1.37s\tremaining: 8m 35s\n",
      "531:\tlearn: 4.8901688\ttest: 6.3099083\tbest: 6.3099083 (531)\ttotal: 1.37s\tremaining: 8m 35s\n",
      "532:\tlearn: 4.8810534\ttest: 6.3116065\tbest: 6.3099083 (531)\ttotal: 1.38s\tremaining: 8m 35s\n",
      "533:\tlearn: 4.8780509\ttest: 6.3093552\tbest: 6.3093552 (533)\ttotal: 1.38s\tremaining: 8m 35s\n",
      "534:\tlearn: 4.8751785\ttest: 6.3078898\tbest: 6.3078898 (534)\ttotal: 1.38s\tremaining: 8m 35s\n",
      "535:\tlearn: 4.8717793\ttest: 6.3049292\tbest: 6.3049292 (535)\ttotal: 1.38s\tremaining: 8m 35s\n",
      "536:\tlearn: 4.8677149\ttest: 6.3023257\tbest: 6.3023257 (536)\ttotal: 1.39s\tremaining: 8m 35s\n",
      "537:\tlearn: 4.8651610\ttest: 6.3006044\tbest: 6.3006044 (537)\ttotal: 1.39s\tremaining: 8m 35s\n",
      "538:\tlearn: 4.8610998\ttest: 6.2974489\tbest: 6.2974489 (538)\ttotal: 1.39s\tremaining: 8m 35s\n",
      "539:\tlearn: 4.8581347\ttest: 6.2937086\tbest: 6.2937086 (539)\ttotal: 1.4s\tremaining: 8m 35s\n",
      "540:\tlearn: 4.8551434\ttest: 6.2926453\tbest: 6.2926453 (540)\ttotal: 1.4s\tremaining: 8m 35s\n",
      "541:\tlearn: 4.8496995\ttest: 6.2891544\tbest: 6.2891544 (541)\ttotal: 1.4s\tremaining: 8m 35s\n",
      "542:\tlearn: 4.8481765\ttest: 6.2888697\tbest: 6.2888697 (542)\ttotal: 1.4s\tremaining: 8m 35s\n",
      "543:\tlearn: 4.8471973\ttest: 6.2878167\tbest: 6.2878167 (543)\ttotal: 1.41s\tremaining: 8m 35s\n",
      "544:\tlearn: 4.8447062\ttest: 6.2878133\tbest: 6.2878133 (544)\ttotal: 1.41s\tremaining: 8m 35s\n",
      "545:\tlearn: 4.8391041\ttest: 6.2830065\tbest: 6.2830065 (545)\ttotal: 1.41s\tremaining: 8m 35s\n",
      "546:\tlearn: 4.8384007\ttest: 6.2817269\tbest: 6.2817269 (546)\ttotal: 1.41s\tremaining: 8m 35s\n",
      "547:\tlearn: 4.8366917\ttest: 6.2810350\tbest: 6.2810350 (547)\ttotal: 1.42s\tremaining: 8m 35s\n",
      "548:\tlearn: 4.8358898\ttest: 6.2803520\tbest: 6.2803520 (548)\ttotal: 1.42s\tremaining: 8m 36s\n",
      "549:\tlearn: 4.8330216\ttest: 6.2793061\tbest: 6.2793061 (549)\ttotal: 1.42s\tremaining: 8m 36s\n",
      "550:\tlearn: 4.8294139\ttest: 6.2760953\tbest: 6.2760953 (550)\ttotal: 1.43s\tremaining: 8m 36s\n",
      "551:\tlearn: 4.8219029\ttest: 6.2683956\tbest: 6.2683956 (551)\ttotal: 1.43s\tremaining: 8m 36s\n",
      "552:\tlearn: 4.8194307\ttest: 6.2671798\tbest: 6.2671798 (552)\ttotal: 1.43s\tremaining: 8m 35s\n",
      "553:\tlearn: 4.8158858\ttest: 6.2637525\tbest: 6.2637525 (553)\ttotal: 1.43s\tremaining: 8m 36s\n",
      "554:\tlearn: 4.8116816\ttest: 6.2613467\tbest: 6.2613467 (554)\ttotal: 1.44s\tremaining: 8m 35s\n",
      "555:\tlearn: 4.8073137\ttest: 6.2579759\tbest: 6.2579759 (555)\ttotal: 1.44s\tremaining: 8m 35s\n",
      "556:\tlearn: 4.8040768\ttest: 6.2560580\tbest: 6.2560580 (556)\ttotal: 1.44s\tremaining: 8m 35s\n",
      "557:\tlearn: 4.8027317\ttest: 6.2551957\tbest: 6.2551957 (557)\ttotal: 1.44s\tremaining: 8m 35s\n",
      "558:\tlearn: 4.7999470\ttest: 6.2533676\tbest: 6.2533676 (558)\ttotal: 1.44s\tremaining: 8m 35s\n",
      "559:\tlearn: 4.7968288\ttest: 6.2517722\tbest: 6.2517722 (559)\ttotal: 1.45s\tremaining: 8m 35s\n",
      "560:\tlearn: 4.7946114\ttest: 6.2513715\tbest: 6.2513715 (560)\ttotal: 1.45s\tremaining: 8m 35s\n",
      "561:\tlearn: 4.7922657\ttest: 6.2483053\tbest: 6.2483053 (561)\ttotal: 1.45s\tremaining: 8m 35s\n",
      "562:\tlearn: 4.7902599\ttest: 6.2453202\tbest: 6.2453202 (562)\ttotal: 1.45s\tremaining: 8m 34s\n",
      "563:\tlearn: 4.7866811\ttest: 6.2414810\tbest: 6.2414810 (563)\ttotal: 1.46s\tremaining: 8m 34s\n",
      "564:\tlearn: 4.7847802\ttest: 6.2399190\tbest: 6.2399190 (564)\ttotal: 1.46s\tremaining: 8m 34s\n",
      "565:\tlearn: 4.7823898\ttest: 6.2393925\tbest: 6.2393925 (565)\ttotal: 1.46s\tremaining: 8m 34s\n",
      "566:\tlearn: 4.7777982\ttest: 6.2330005\tbest: 6.2330005 (566)\ttotal: 1.46s\tremaining: 8m 34s\n",
      "567:\tlearn: 4.7736520\ttest: 6.2306041\tbest: 6.2306041 (567)\ttotal: 1.46s\tremaining: 8m 34s\n",
      "568:\tlearn: 4.7710968\ttest: 6.2287066\tbest: 6.2287066 (568)\ttotal: 1.47s\tremaining: 8m 34s\n",
      "569:\tlearn: 4.7687245\ttest: 6.2284425\tbest: 6.2284425 (569)\ttotal: 1.47s\tremaining: 8m 34s\n",
      "570:\tlearn: 4.7674483\ttest: 6.2283344\tbest: 6.2283344 (570)\ttotal: 1.47s\tremaining: 8m 33s\n",
      "571:\tlearn: 4.7651889\ttest: 6.2269194\tbest: 6.2269194 (571)\ttotal: 1.47s\tremaining: 8m 33s\n",
      "572:\tlearn: 4.7595629\ttest: 6.2195804\tbest: 6.2195804 (572)\ttotal: 1.48s\tremaining: 8m 33s\n",
      "573:\tlearn: 4.7565794\ttest: 6.2178446\tbest: 6.2178446 (573)\ttotal: 1.48s\tremaining: 8m 33s\n",
      "574:\tlearn: 4.7534169\ttest: 6.2181227\tbest: 6.2178446 (573)\ttotal: 1.48s\tremaining: 8m 33s\n",
      "575:\tlearn: 4.7521469\ttest: 6.2178696\tbest: 6.2178446 (573)\ttotal: 1.48s\tremaining: 8m 33s\n",
      "576:\tlearn: 4.7486741\ttest: 6.2132431\tbest: 6.2132431 (576)\ttotal: 1.49s\tremaining: 8m 33s\n",
      "577:\tlearn: 4.7459697\ttest: 6.2126886\tbest: 6.2126886 (577)\ttotal: 1.49s\tremaining: 8m 33s\n",
      "578:\tlearn: 4.7395565\ttest: 6.2103866\tbest: 6.2103866 (578)\ttotal: 1.49s\tremaining: 8m 33s\n",
      "579:\tlearn: 4.7385428\ttest: 6.2093285\tbest: 6.2093285 (579)\ttotal: 1.49s\tremaining: 8m 33s\n",
      "580:\tlearn: 4.7375938\ttest: 6.2089684\tbest: 6.2089684 (580)\ttotal: 1.5s\tremaining: 8m 33s\n",
      "581:\tlearn: 4.7362371\ttest: 6.2080859\tbest: 6.2080859 (581)\ttotal: 1.5s\tremaining: 8m 33s\n",
      "582:\tlearn: 4.7342273\ttest: 6.2082020\tbest: 6.2080859 (581)\ttotal: 1.5s\tremaining: 8m 33s\n",
      "583:\tlearn: 4.7320262\ttest: 6.2076967\tbest: 6.2076967 (583)\ttotal: 1.5s\tremaining: 8m 33s\n",
      "584:\tlearn: 4.7293294\ttest: 6.2045122\tbest: 6.2045122 (584)\ttotal: 1.5s\tremaining: 8m 33s\n",
      "585:\tlearn: 4.7280394\ttest: 6.2046481\tbest: 6.2045122 (584)\ttotal: 1.51s\tremaining: 8m 33s\n",
      "586:\tlearn: 4.7264516\ttest: 6.2043397\tbest: 6.2043397 (586)\ttotal: 1.51s\tremaining: 8m 33s\n",
      "587:\tlearn: 4.7235911\ttest: 6.2018430\tbest: 6.2018430 (587)\ttotal: 1.51s\tremaining: 8m 33s\n",
      "588:\tlearn: 4.7190170\ttest: 6.1998689\tbest: 6.1998689 (588)\ttotal: 1.52s\tremaining: 8m 33s\n",
      "589:\tlearn: 4.7168217\ttest: 6.1982641\tbest: 6.1982641 (589)\ttotal: 1.52s\tremaining: 8m 33s\n",
      "590:\tlearn: 4.7155846\ttest: 6.1972700\tbest: 6.1972700 (590)\ttotal: 1.52s\tremaining: 8m 33s\n",
      "591:\tlearn: 4.7123870\ttest: 6.1905680\tbest: 6.1905680 (591)\ttotal: 1.52s\tremaining: 8m 33s\n",
      "592:\tlearn: 4.7091755\ttest: 6.1854365\tbest: 6.1854365 (592)\ttotal: 1.52s\tremaining: 8m 32s\n",
      "593:\tlearn: 4.7057676\ttest: 6.1847942\tbest: 6.1847942 (593)\ttotal: 1.53s\tremaining: 8m 32s\n",
      "594:\tlearn: 4.7046073\ttest: 6.1846285\tbest: 6.1846285 (594)\ttotal: 1.53s\tremaining: 8m 32s\n",
      "595:\tlearn: 4.7025661\ttest: 6.1825635\tbest: 6.1825635 (595)\ttotal: 1.53s\tremaining: 8m 32s\n",
      "596:\tlearn: 4.6988027\ttest: 6.1796161\tbest: 6.1796161 (596)\ttotal: 1.53s\tremaining: 8m 32s\n",
      "597:\tlearn: 4.6937636\ttest: 6.1772873\tbest: 6.1772873 (597)\ttotal: 1.54s\tremaining: 8m 32s\n",
      "598:\tlearn: 4.6912747\ttest: 6.1764779\tbest: 6.1764779 (598)\ttotal: 1.54s\tremaining: 8m 32s\n",
      "599:\tlearn: 4.6898153\ttest: 6.1758186\tbest: 6.1758186 (599)\ttotal: 1.54s\tremaining: 8m 32s\n",
      "600:\tlearn: 4.6876663\ttest: 6.1748498\tbest: 6.1748498 (600)\ttotal: 1.54s\tremaining: 8m 32s\n",
      "601:\tlearn: 4.6861864\ttest: 6.1734964\tbest: 6.1734964 (601)\ttotal: 1.55s\tremaining: 8m 32s\n",
      "602:\tlearn: 4.6829653\ttest: 6.1709160\tbest: 6.1709160 (602)\ttotal: 1.55s\tremaining: 8m 32s\n",
      "603:\tlearn: 4.6818253\ttest: 6.1703268\tbest: 6.1703268 (603)\ttotal: 1.55s\tremaining: 8m 32s\n",
      "604:\tlearn: 4.6787972\ttest: 6.1669820\tbest: 6.1669820 (604)\ttotal: 1.55s\tremaining: 8m 31s\n",
      "605:\tlearn: 4.6771445\ttest: 6.1670353\tbest: 6.1669820 (604)\ttotal: 1.55s\tremaining: 8m 31s\n",
      "606:\tlearn: 4.6752868\ttest: 6.1664315\tbest: 6.1664315 (606)\ttotal: 1.56s\tremaining: 8m 31s\n",
      "607:\tlearn: 4.6698732\ttest: 6.1622349\tbest: 6.1622349 (607)\ttotal: 1.56s\tremaining: 8m 31s\n",
      "608:\tlearn: 4.6658758\ttest: 6.1584439\tbest: 6.1584439 (608)\ttotal: 1.56s\tremaining: 8m 31s\n",
      "609:\tlearn: 4.6633331\ttest: 6.1562097\tbest: 6.1562097 (609)\ttotal: 1.56s\tremaining: 8m 31s\n",
      "610:\tlearn: 4.6624036\ttest: 6.1560825\tbest: 6.1560825 (610)\ttotal: 1.57s\tremaining: 8m 31s\n",
      "611:\tlearn: 4.6598210\ttest: 6.1533388\tbest: 6.1533388 (611)\ttotal: 1.57s\tremaining: 8m 31s\n",
      "612:\tlearn: 4.6593496\ttest: 6.1523808\tbest: 6.1523808 (612)\ttotal: 1.57s\tremaining: 8m 31s\n",
      "613:\tlearn: 4.6549804\ttest: 6.1489671\tbest: 6.1489671 (613)\ttotal: 1.58s\tremaining: 8m 31s\n",
      "614:\tlearn: 4.6529618\ttest: 6.1479912\tbest: 6.1479912 (614)\ttotal: 1.58s\tremaining: 8m 31s\n",
      "615:\tlearn: 4.6499131\ttest: 6.1444527\tbest: 6.1444527 (615)\ttotal: 1.58s\tremaining: 8m 31s\n",
      "616:\tlearn: 4.6467668\ttest: 6.1438662\tbest: 6.1438662 (616)\ttotal: 1.58s\tremaining: 8m 31s\n",
      "617:\tlearn: 4.6401456\ttest: 6.1393109\tbest: 6.1393109 (617)\ttotal: 1.58s\tremaining: 8m 31s\n",
      "618:\tlearn: 4.6368221\ttest: 6.1382804\tbest: 6.1382804 (618)\ttotal: 1.59s\tremaining: 8m 31s\n",
      "619:\tlearn: 4.6342011\ttest: 6.1371743\tbest: 6.1371743 (619)\ttotal: 1.59s\tremaining: 8m 31s\n",
      "620:\tlearn: 4.6289940\ttest: 6.1349373\tbest: 6.1349373 (620)\ttotal: 1.59s\tremaining: 8m 31s\n",
      "621:\tlearn: 4.6267120\ttest: 6.1339139\tbest: 6.1339139 (621)\ttotal: 1.59s\tremaining: 8m 31s\n",
      "622:\tlearn: 4.6235911\ttest: 6.1319155\tbest: 6.1319155 (622)\ttotal: 1.6s\tremaining: 8m 31s\n",
      "623:\tlearn: 4.6212463\ttest: 6.1277863\tbest: 6.1277863 (623)\ttotal: 1.6s\tremaining: 8m 31s\n",
      "624:\tlearn: 4.6174109\ttest: 6.1230457\tbest: 6.1230457 (624)\ttotal: 1.6s\tremaining: 8m 31s\n",
      "625:\tlearn: 4.6148211\ttest: 6.1211924\tbest: 6.1211924 (625)\ttotal: 1.6s\tremaining: 8m 31s\n",
      "626:\tlearn: 4.6128476\ttest: 6.1195913\tbest: 6.1195913 (626)\ttotal: 1.61s\tremaining: 8m 31s\n",
      "627:\tlearn: 4.6111164\ttest: 6.1215351\tbest: 6.1195913 (626)\ttotal: 1.61s\tremaining: 8m 31s\n",
      "628:\tlearn: 4.6090810\ttest: 6.1211240\tbest: 6.1195913 (626)\ttotal: 1.61s\tremaining: 8m 30s\n",
      "629:\tlearn: 4.6082612\ttest: 6.1201465\tbest: 6.1195913 (626)\ttotal: 1.61s\tremaining: 8m 30s\n",
      "630:\tlearn: 4.6078834\ttest: 6.1199322\tbest: 6.1195913 (626)\ttotal: 1.62s\tremaining: 8m 30s\n",
      "631:\tlearn: 4.6068964\ttest: 6.1186598\tbest: 6.1186598 (631)\ttotal: 1.62s\tremaining: 8m 30s\n",
      "632:\tlearn: 4.6051162\ttest: 6.1158232\tbest: 6.1158232 (632)\ttotal: 1.62s\tremaining: 8m 30s\n",
      "633:\tlearn: 4.6043211\ttest: 6.1156487\tbest: 6.1156487 (633)\ttotal: 1.62s\tremaining: 8m 30s\n",
      "634:\tlearn: 4.6038416\ttest: 6.1150422\tbest: 6.1150422 (634)\ttotal: 1.62s\tremaining: 8m 30s\n",
      "635:\tlearn: 4.6023303\ttest: 6.1147474\tbest: 6.1147474 (635)\ttotal: 1.63s\tremaining: 8m 30s\n",
      "636:\tlearn: 4.6010582\ttest: 6.1136190\tbest: 6.1136190 (636)\ttotal: 1.63s\tremaining: 8m 30s\n",
      "637:\tlearn: 4.5991198\ttest: 6.1122550\tbest: 6.1122550 (637)\ttotal: 1.63s\tremaining: 8m 29s\n",
      "638:\tlearn: 4.5973441\ttest: 6.1118544\tbest: 6.1118544 (638)\ttotal: 1.63s\tremaining: 8m 30s\n",
      "639:\tlearn: 4.5947490\ttest: 6.1117573\tbest: 6.1117573 (639)\ttotal: 1.64s\tremaining: 8m 29s\n",
      "640:\tlearn: 4.5926961\ttest: 6.1111629\tbest: 6.1111629 (640)\ttotal: 1.64s\tremaining: 8m 29s\n",
      "641:\tlearn: 4.5920311\ttest: 6.1107661\tbest: 6.1107661 (641)\ttotal: 1.64s\tremaining: 8m 29s\n",
      "642:\tlearn: 4.5912783\ttest: 6.1101481\tbest: 6.1101481 (642)\ttotal: 1.64s\tremaining: 8m 29s\n",
      "643:\tlearn: 4.5890115\ttest: 6.1101467\tbest: 6.1101467 (643)\ttotal: 1.65s\tremaining: 8m 29s\n",
      "644:\tlearn: 4.5878491\ttest: 6.1095901\tbest: 6.1095901 (644)\ttotal: 1.65s\tremaining: 8m 29s\n",
      "645:\tlearn: 4.5862665\ttest: 6.1095912\tbest: 6.1095901 (644)\ttotal: 1.65s\tremaining: 8m 29s\n",
      "646:\tlearn: 4.5828690\ttest: 6.1088569\tbest: 6.1088569 (646)\ttotal: 1.65s\tremaining: 8m 29s\n",
      "647:\tlearn: 4.5818922\ttest: 6.1086145\tbest: 6.1086145 (647)\ttotal: 1.66s\tremaining: 8m 29s\n",
      "648:\tlearn: 4.5810779\ttest: 6.1079630\tbest: 6.1079630 (648)\ttotal: 1.66s\tremaining: 8m 29s\n",
      "649:\tlearn: 4.5807185\ttest: 6.1073657\tbest: 6.1073657 (649)\ttotal: 1.66s\tremaining: 8m 29s\n",
      "650:\tlearn: 4.5796852\ttest: 6.1063104\tbest: 6.1063104 (650)\ttotal: 1.66s\tremaining: 8m 29s\n",
      "651:\tlearn: 4.5783672\ttest: 6.1066119\tbest: 6.1063104 (650)\ttotal: 1.67s\tremaining: 8m 29s\n",
      "652:\tlearn: 4.5762747\ttest: 6.1048110\tbest: 6.1048110 (652)\ttotal: 1.67s\tremaining: 8m 29s\n",
      "653:\tlearn: 4.5740030\ttest: 6.1026304\tbest: 6.1026304 (653)\ttotal: 1.67s\tremaining: 8m 29s\n",
      "654:\tlearn: 4.5722716\ttest: 6.1019021\tbest: 6.1019021 (654)\ttotal: 1.67s\tremaining: 8m 28s\n",
      "655:\tlearn: 4.5706223\ttest: 6.1007363\tbest: 6.1007363 (655)\ttotal: 1.67s\tremaining: 8m 28s\n",
      "656:\tlearn: 4.5672502\ttest: 6.0984705\tbest: 6.0984705 (656)\ttotal: 1.68s\tremaining: 8m 28s\n",
      "657:\tlearn: 4.5667128\ttest: 6.0982986\tbest: 6.0982986 (657)\ttotal: 1.68s\tremaining: 8m 28s\n",
      "658:\tlearn: 4.5650645\ttest: 6.0966979\tbest: 6.0966979 (658)\ttotal: 1.68s\tremaining: 8m 28s\n",
      "659:\tlearn: 4.5639657\ttest: 6.0962340\tbest: 6.0962340 (659)\ttotal: 1.68s\tremaining: 8m 28s\n",
      "660:\tlearn: 4.5618165\ttest: 6.0953944\tbest: 6.0953944 (660)\ttotal: 1.69s\tremaining: 8m 28s\n",
      "661:\tlearn: 4.5576597\ttest: 6.0910589\tbest: 6.0910589 (661)\ttotal: 1.69s\tremaining: 8m 28s\n",
      "662:\tlearn: 4.5567217\ttest: 6.0906778\tbest: 6.0906778 (662)\ttotal: 1.69s\tremaining: 8m 28s\n",
      "663:\tlearn: 4.5545572\ttest: 6.0886877\tbest: 6.0886877 (663)\ttotal: 1.69s\tremaining: 8m 28s\n",
      "664:\tlearn: 4.5528731\ttest: 6.0886295\tbest: 6.0886295 (664)\ttotal: 1.7s\tremaining: 8m 28s\n",
      "665:\tlearn: 4.5514106\ttest: 6.0880688\tbest: 6.0880688 (665)\ttotal: 1.7s\tremaining: 8m 28s\n",
      "666:\tlearn: 4.5488912\ttest: 6.0848552\tbest: 6.0848552 (666)\ttotal: 1.7s\tremaining: 8m 28s\n",
      "667:\tlearn: 4.5470709\ttest: 6.0833332\tbest: 6.0833332 (667)\ttotal: 1.7s\tremaining: 8m 28s\n",
      "668:\tlearn: 4.5448228\ttest: 6.0794490\tbest: 6.0794490 (668)\ttotal: 1.7s\tremaining: 8m 28s\n",
      "669:\tlearn: 4.5444437\ttest: 6.0788652\tbest: 6.0788652 (669)\ttotal: 1.71s\tremaining: 8m 27s\n",
      "670:\tlearn: 4.5434321\ttest: 6.0781784\tbest: 6.0781784 (670)\ttotal: 1.71s\tremaining: 8m 27s\n",
      "671:\tlearn: 4.5410019\ttest: 6.0783390\tbest: 6.0781784 (670)\ttotal: 1.71s\tremaining: 8m 27s\n",
      "672:\tlearn: 4.5405804\ttest: 6.0782941\tbest: 6.0781784 (670)\ttotal: 1.71s\tremaining: 8m 27s\n",
      "673:\tlearn: 4.5396548\ttest: 6.0781142\tbest: 6.0781142 (673)\ttotal: 1.72s\tremaining: 8m 27s\n",
      "674:\tlearn: 4.5381797\ttest: 6.0780666\tbest: 6.0780666 (674)\ttotal: 1.72s\tremaining: 8m 27s\n",
      "675:\tlearn: 4.5376310\ttest: 6.0783249\tbest: 6.0780666 (674)\ttotal: 1.72s\tremaining: 8m 27s\n",
      "676:\tlearn: 4.5372639\ttest: 6.0776400\tbest: 6.0776400 (676)\ttotal: 1.72s\tremaining: 8m 27s\n",
      "677:\tlearn: 4.5350256\ttest: 6.0753982\tbest: 6.0753982 (677)\ttotal: 1.73s\tremaining: 8m 27s\n",
      "678:\tlearn: 4.5320436\ttest: 6.0735954\tbest: 6.0735954 (678)\ttotal: 1.73s\tremaining: 8m 27s\n",
      "679:\tlearn: 4.5312737\ttest: 6.0723017\tbest: 6.0723017 (679)\ttotal: 1.73s\tremaining: 8m 27s\n",
      "680:\tlearn: 4.5281358\ttest: 6.0710214\tbest: 6.0710214 (680)\ttotal: 1.74s\tremaining: 8m 27s\n",
      "681:\tlearn: 4.5267921\ttest: 6.0709612\tbest: 6.0709612 (681)\ttotal: 1.74s\tremaining: 8m 27s\n",
      "682:\tlearn: 4.5240741\ttest: 6.0681930\tbest: 6.0681930 (682)\ttotal: 1.74s\tremaining: 8m 27s\n",
      "683:\tlearn: 4.5222736\ttest: 6.0663668\tbest: 6.0663668 (683)\ttotal: 1.74s\tremaining: 8m 27s\n",
      "684:\tlearn: 4.5192619\ttest: 6.0663626\tbest: 6.0663626 (684)\ttotal: 1.75s\tremaining: 8m 27s\n",
      "685:\tlearn: 4.5178644\ttest: 6.0650571\tbest: 6.0650571 (685)\ttotal: 1.75s\tremaining: 8m 27s\n",
      "686:\tlearn: 4.5143484\ttest: 6.0630945\tbest: 6.0630945 (686)\ttotal: 1.75s\tremaining: 8m 28s\n",
      "687:\tlearn: 4.5120189\ttest: 6.0628682\tbest: 6.0628682 (687)\ttotal: 1.75s\tremaining: 8m 28s\n",
      "688:\tlearn: 4.5115936\ttest: 6.0619949\tbest: 6.0619949 (688)\ttotal: 1.76s\tremaining: 8m 28s\n",
      "689:\tlearn: 4.5088729\ttest: 6.0596371\tbest: 6.0596371 (689)\ttotal: 1.76s\tremaining: 8m 28s\n",
      "690:\tlearn: 4.5036841\ttest: 6.0545759\tbest: 6.0545759 (690)\ttotal: 1.76s\tremaining: 8m 28s\n",
      "691:\tlearn: 4.5017638\ttest: 6.0539213\tbest: 6.0539213 (691)\ttotal: 1.76s\tremaining: 8m 27s\n",
      "692:\tlearn: 4.4988588\ttest: 6.0514606\tbest: 6.0514606 (692)\ttotal: 1.77s\tremaining: 8m 27s\n",
      "693:\tlearn: 4.4974603\ttest: 6.0484442\tbest: 6.0484442 (693)\ttotal: 1.77s\tremaining: 8m 27s\n",
      "694:\tlearn: 4.4948135\ttest: 6.0481763\tbest: 6.0481763 (694)\ttotal: 1.77s\tremaining: 8m 27s\n",
      "695:\tlearn: 4.4909455\ttest: 6.0460709\tbest: 6.0460709 (695)\ttotal: 1.77s\tremaining: 8m 27s\n",
      "696:\tlearn: 4.4892906\ttest: 6.0458256\tbest: 6.0458256 (696)\ttotal: 1.78s\tremaining: 8m 28s\n",
      "697:\tlearn: 4.4874563\ttest: 6.0438078\tbest: 6.0438078 (697)\ttotal: 1.78s\tremaining: 8m 28s\n",
      "698:\tlearn: 4.4853311\ttest: 6.0446286\tbest: 6.0438078 (697)\ttotal: 1.78s\tremaining: 8m 28s\n",
      "699:\tlearn: 4.4841408\ttest: 6.0439204\tbest: 6.0438078 (697)\ttotal: 1.78s\tremaining: 8m 27s\n",
      "700:\tlearn: 4.4818282\ttest: 6.0398644\tbest: 6.0398644 (700)\ttotal: 1.79s\tremaining: 8m 27s\n",
      "701:\tlearn: 4.4787978\ttest: 6.0378663\tbest: 6.0378663 (701)\ttotal: 1.79s\tremaining: 8m 27s\n",
      "702:\tlearn: 4.4773939\ttest: 6.0369632\tbest: 6.0369632 (702)\ttotal: 1.79s\tremaining: 8m 27s\n",
      "703:\tlearn: 4.4743052\ttest: 6.0338046\tbest: 6.0338046 (703)\ttotal: 1.79s\tremaining: 8m 27s\n",
      "704:\tlearn: 4.4690391\ttest: 6.0304086\tbest: 6.0304086 (704)\ttotal: 1.79s\tremaining: 8m 27s\n",
      "705:\tlearn: 4.4651642\ttest: 6.0288239\tbest: 6.0288239 (705)\ttotal: 1.8s\tremaining: 8m 27s\n",
      "706:\tlearn: 4.4637856\ttest: 6.0276248\tbest: 6.0276248 (706)\ttotal: 1.8s\tremaining: 8m 27s\n",
      "707:\tlearn: 4.4609348\ttest: 6.0258061\tbest: 6.0258061 (707)\ttotal: 1.8s\tremaining: 8m 27s\n",
      "708:\tlearn: 4.4590462\ttest: 6.0251243\tbest: 6.0251243 (708)\ttotal: 1.81s\tremaining: 8m 27s\n",
      "709:\tlearn: 4.4567451\ttest: 6.0252875\tbest: 6.0251243 (708)\ttotal: 1.81s\tremaining: 8m 27s\n",
      "710:\tlearn: 4.4522170\ttest: 6.0224608\tbest: 6.0224608 (710)\ttotal: 1.81s\tremaining: 8m 27s\n",
      "711:\tlearn: 4.4512105\ttest: 6.0225034\tbest: 6.0224608 (710)\ttotal: 1.81s\tremaining: 8m 27s\n",
      "712:\tlearn: 4.4494340\ttest: 6.0222416\tbest: 6.0222416 (712)\ttotal: 1.82s\tremaining: 8m 27s\n",
      "713:\tlearn: 4.4467494\ttest: 6.0206444\tbest: 6.0206444 (713)\ttotal: 1.82s\tremaining: 8m 27s\n",
      "714:\tlearn: 4.4452282\ttest: 6.0200446\tbest: 6.0200446 (714)\ttotal: 1.82s\tremaining: 8m 27s\n",
      "715:\tlearn: 4.4441940\ttest: 6.0195651\tbest: 6.0195651 (715)\ttotal: 1.82s\tremaining: 8m 27s\n",
      "716:\tlearn: 4.4438170\ttest: 6.0193691\tbest: 6.0193691 (716)\ttotal: 1.82s\tremaining: 8m 27s\n",
      "717:\tlearn: 4.4429236\ttest: 6.0181465\tbest: 6.0181465 (717)\ttotal: 1.83s\tremaining: 8m 27s\n",
      "718:\tlearn: 4.4425895\ttest: 6.0184332\tbest: 6.0181465 (717)\ttotal: 1.83s\tremaining: 8m 27s\n",
      "719:\tlearn: 4.4406806\ttest: 6.0180998\tbest: 6.0180998 (719)\ttotal: 1.83s\tremaining: 8m 27s\n",
      "720:\tlearn: 4.4396964\ttest: 6.0170166\tbest: 6.0170166 (720)\ttotal: 1.83s\tremaining: 8m 26s\n",
      "721:\tlearn: 4.4381802\ttest: 6.0167823\tbest: 6.0167823 (721)\ttotal: 1.84s\tremaining: 8m 26s\n",
      "722:\tlearn: 4.4360268\ttest: 6.0158375\tbest: 6.0158375 (722)\ttotal: 1.84s\tremaining: 8m 26s\n",
      "723:\tlearn: 4.4346949\ttest: 6.0159752\tbest: 6.0158375 (722)\ttotal: 1.84s\tremaining: 8m 26s\n",
      "724:\tlearn: 4.4341957\ttest: 6.0157626\tbest: 6.0157626 (724)\ttotal: 1.84s\tremaining: 8m 26s\n",
      "725:\tlearn: 4.4331793\ttest: 6.0150058\tbest: 6.0150058 (725)\ttotal: 1.84s\tremaining: 8m 26s\n",
      "726:\tlearn: 4.4318041\ttest: 6.0153069\tbest: 6.0150058 (725)\ttotal: 1.85s\tremaining: 8m 26s\n",
      "727:\tlearn: 4.4314595\ttest: 6.0149929\tbest: 6.0149929 (727)\ttotal: 1.85s\tremaining: 8m 26s\n",
      "728:\tlearn: 4.4302263\ttest: 6.0135933\tbest: 6.0135933 (728)\ttotal: 1.85s\tremaining: 8m 26s\n",
      "729:\tlearn: 4.4289575\ttest: 6.0134120\tbest: 6.0134120 (729)\ttotal: 1.85s\tremaining: 8m 26s\n",
      "730:\tlearn: 4.4265706\ttest: 6.0119212\tbest: 6.0119212 (730)\ttotal: 1.86s\tremaining: 8m 26s\n",
      "731:\tlearn: 4.4257664\ttest: 6.0099380\tbest: 6.0099380 (731)\ttotal: 1.86s\tremaining: 8m 26s\n",
      "732:\tlearn: 4.4246226\ttest: 6.0095768\tbest: 6.0095768 (732)\ttotal: 1.86s\tremaining: 8m 25s\n",
      "733:\tlearn: 4.4242489\ttest: 6.0092115\tbest: 6.0092115 (733)\ttotal: 1.86s\tremaining: 8m 25s\n",
      "734:\tlearn: 4.4216588\ttest: 6.0070767\tbest: 6.0070767 (734)\ttotal: 1.86s\tremaining: 8m 25s\n",
      "735:\tlearn: 4.4173815\ttest: 6.0034357\tbest: 6.0034357 (735)\ttotal: 1.87s\tremaining: 8m 25s\n",
      "736:\tlearn: 4.4156669\ttest: 6.0030310\tbest: 6.0030310 (736)\ttotal: 1.87s\tremaining: 8m 25s\n",
      "737:\tlearn: 4.4133513\ttest: 6.0001745\tbest: 6.0001745 (737)\ttotal: 1.87s\tremaining: 8m 25s\n",
      "738:\tlearn: 4.4129583\ttest: 5.9995729\tbest: 5.9995729 (738)\ttotal: 1.87s\tremaining: 8m 25s\n",
      "739:\tlearn: 4.4108558\ttest: 5.9985412\tbest: 5.9985412 (739)\ttotal: 1.88s\tremaining: 8m 25s\n",
      "740:\tlearn: 4.4099009\ttest: 5.9983428\tbest: 5.9983428 (740)\ttotal: 1.88s\tremaining: 8m 25s\n",
      "741:\tlearn: 4.4094529\ttest: 5.9978052\tbest: 5.9978052 (741)\ttotal: 1.88s\tremaining: 8m 25s\n",
      "742:\tlearn: 4.4086836\ttest: 5.9964837\tbest: 5.9964837 (742)\ttotal: 1.88s\tremaining: 8m 25s\n",
      "743:\tlearn: 4.4071970\ttest: 5.9945191\tbest: 5.9945191 (743)\ttotal: 1.89s\tremaining: 8m 25s\n",
      "744:\tlearn: 4.4057941\ttest: 5.9941884\tbest: 5.9941884 (744)\ttotal: 1.89s\tremaining: 8m 24s\n",
      "745:\tlearn: 4.4039517\ttest: 5.9933707\tbest: 5.9933707 (745)\ttotal: 1.89s\tremaining: 8m 24s\n",
      "746:\tlearn: 4.4007890\ttest: 5.9923222\tbest: 5.9923222 (746)\ttotal: 1.89s\tremaining: 8m 24s\n",
      "747:\tlearn: 4.4001595\ttest: 5.9923499\tbest: 5.9923222 (746)\ttotal: 1.9s\tremaining: 8m 25s\n",
      "748:\tlearn: 4.3993460\ttest: 5.9917629\tbest: 5.9917629 (748)\ttotal: 1.9s\tremaining: 8m 24s\n",
      "749:\tlearn: 4.3985337\ttest: 5.9916239\tbest: 5.9916239 (749)\ttotal: 1.9s\tremaining: 8m 24s\n",
      "750:\tlearn: 4.3978535\ttest: 5.9915591\tbest: 5.9915591 (750)\ttotal: 1.9s\tremaining: 8m 24s\n",
      "751:\tlearn: 4.3962509\ttest: 5.9914323\tbest: 5.9914323 (751)\ttotal: 1.91s\tremaining: 8m 24s\n",
      "752:\tlearn: 4.3952385\ttest: 5.9906047\tbest: 5.9906047 (752)\ttotal: 1.91s\tremaining: 8m 24s\n",
      "753:\tlearn: 4.3941868\ttest: 5.9903856\tbest: 5.9903856 (753)\ttotal: 1.91s\tremaining: 8m 24s\n",
      "754:\tlearn: 4.3923872\ttest: 5.9888215\tbest: 5.9888215 (754)\ttotal: 1.91s\tremaining: 8m 25s\n",
      "755:\tlearn: 4.3920165\ttest: 5.9883789\tbest: 5.9883789 (755)\ttotal: 1.92s\tremaining: 8m 25s\n",
      "756:\tlearn: 4.3916240\ttest: 5.9884042\tbest: 5.9883789 (755)\ttotal: 1.92s\tremaining: 8m 25s\n",
      "757:\tlearn: 4.3912762\ttest: 5.9884177\tbest: 5.9883789 (755)\ttotal: 1.92s\tremaining: 8m 25s\n",
      "758:\tlearn: 4.3908847\ttest: 5.9882898\tbest: 5.9882898 (758)\ttotal: 1.92s\tremaining: 8m 25s\n",
      "759:\tlearn: 4.3901083\ttest: 5.9915747\tbest: 5.9882898 (758)\ttotal: 1.93s\tremaining: 8m 25s\n",
      "760:\tlearn: 4.3884137\ttest: 5.9912912\tbest: 5.9882898 (758)\ttotal: 1.93s\tremaining: 8m 25s\n",
      "761:\tlearn: 4.3873516\ttest: 5.9899420\tbest: 5.9882898 (758)\ttotal: 1.93s\tremaining: 8m 25s\n",
      "762:\tlearn: 4.3854570\ttest: 5.9890738\tbest: 5.9882898 (758)\ttotal: 1.93s\tremaining: 8m 25s\n",
      "763:\tlearn: 4.3834465\ttest: 5.9854665\tbest: 5.9854665 (763)\ttotal: 1.94s\tremaining: 8m 24s\n",
      "764:\tlearn: 4.3826794\ttest: 5.9858456\tbest: 5.9854665 (763)\ttotal: 1.94s\tremaining: 8m 24s\n",
      "765:\tlearn: 4.3811322\ttest: 5.9853816\tbest: 5.9853816 (765)\ttotal: 1.94s\tremaining: 8m 24s\n",
      "766:\tlearn: 4.3788218\ttest: 5.9839056\tbest: 5.9839056 (766)\ttotal: 1.94s\tremaining: 8m 24s\n",
      "767:\tlearn: 4.3775256\ttest: 5.9832205\tbest: 5.9832205 (767)\ttotal: 1.95s\tremaining: 8m 24s\n",
      "768:\tlearn: 4.3760129\ttest: 5.9820690\tbest: 5.9820690 (768)\ttotal: 1.95s\tremaining: 8m 24s\n",
      "769:\tlearn: 4.3748453\ttest: 5.9822296\tbest: 5.9820690 (768)\ttotal: 1.95s\tremaining: 8m 24s\n",
      "770:\tlearn: 4.3722283\ttest: 5.9810859\tbest: 5.9810859 (770)\ttotal: 1.95s\tremaining: 8m 24s\n",
      "771:\tlearn: 4.3682553\ttest: 5.9811590\tbest: 5.9810859 (770)\ttotal: 1.96s\tremaining: 8m 24s\n",
      "772:\tlearn: 4.3670167\ttest: 5.9803282\tbest: 5.9803282 (772)\ttotal: 1.96s\tremaining: 8m 24s\n",
      "773:\tlearn: 4.3661483\ttest: 5.9801209\tbest: 5.9801209 (773)\ttotal: 1.96s\tremaining: 8m 24s\n",
      "774:\tlearn: 4.3657653\ttest: 5.9794621\tbest: 5.9794621 (774)\ttotal: 1.96s\tremaining: 8m 24s\n",
      "775:\tlearn: 4.3643549\ttest: 5.9787732\tbest: 5.9787732 (775)\ttotal: 1.96s\tremaining: 8m 24s\n",
      "776:\tlearn: 4.3631686\ttest: 5.9784848\tbest: 5.9784848 (776)\ttotal: 1.97s\tremaining: 8m 24s\n",
      "777:\tlearn: 4.3622574\ttest: 5.9783192\tbest: 5.9783192 (777)\ttotal: 1.97s\tremaining: 8m 24s\n",
      "778:\tlearn: 4.3617388\ttest: 5.9789044\tbest: 5.9783192 (777)\ttotal: 1.97s\tremaining: 8m 24s\n",
      "779:\tlearn: 4.3561646\ttest: 5.9767517\tbest: 5.9767517 (779)\ttotal: 1.97s\tremaining: 8m 23s\n",
      "780:\tlearn: 4.3556085\ttest: 5.9763798\tbest: 5.9763798 (780)\ttotal: 1.98s\tremaining: 8m 23s\n",
      "781:\tlearn: 4.3549412\ttest: 5.9760970\tbest: 5.9760970 (781)\ttotal: 1.98s\tremaining: 8m 23s\n",
      "782:\tlearn: 4.3540544\ttest: 5.9755820\tbest: 5.9755820 (782)\ttotal: 1.98s\tremaining: 8m 23s\n",
      "783:\tlearn: 4.3527231\ttest: 5.9746792\tbest: 5.9746792 (783)\ttotal: 1.98s\tremaining: 8m 23s\n",
      "784:\tlearn: 4.3502592\ttest: 5.9740278\tbest: 5.9740278 (784)\ttotal: 1.98s\tremaining: 8m 23s\n",
      "785:\tlearn: 4.3470870\ttest: 5.9720405\tbest: 5.9720405 (785)\ttotal: 1.99s\tremaining: 8m 23s\n",
      "786:\tlearn: 4.3450935\ttest: 5.9711261\tbest: 5.9711261 (786)\ttotal: 1.99s\tremaining: 8m 23s\n",
      "787:\tlearn: 4.3435144\ttest: 5.9709486\tbest: 5.9709486 (787)\ttotal: 1.99s\tremaining: 8m 23s\n",
      "788:\tlearn: 4.3430816\ttest: 5.9707687\tbest: 5.9707687 (788)\ttotal: 1.99s\tremaining: 8m 23s\n",
      "789:\tlearn: 4.3375952\ttest: 5.9720681\tbest: 5.9707687 (788)\ttotal: 1.99s\tremaining: 8m 23s\n",
      "790:\tlearn: 4.3364879\ttest: 5.9708112\tbest: 5.9707687 (788)\ttotal: 2s\tremaining: 8m 23s\n",
      "791:\tlearn: 4.3313612\ttest: 5.9702795\tbest: 5.9702795 (791)\ttotal: 2s\tremaining: 8m 22s\n",
      "792:\tlearn: 4.3284107\ttest: 5.9693067\tbest: 5.9693067 (792)\ttotal: 2s\tremaining: 8m 22s\n",
      "793:\tlearn: 4.3234467\ttest: 5.9648014\tbest: 5.9648014 (793)\ttotal: 2s\tremaining: 8m 22s\n",
      "794:\tlearn: 4.3211434\ttest: 5.9626323\tbest: 5.9626323 (794)\ttotal: 2.01s\tremaining: 8m 22s\n",
      "795:\tlearn: 4.3172275\ttest: 5.9599340\tbest: 5.9599340 (795)\ttotal: 2.01s\tremaining: 8m 22s\n",
      "796:\tlearn: 4.3151023\ttest: 5.9583181\tbest: 5.9583181 (796)\ttotal: 2.01s\tremaining: 8m 22s\n",
      "797:\tlearn: 4.3142954\ttest: 5.9577715\tbest: 5.9577715 (797)\ttotal: 2.01s\tremaining: 8m 22s\n",
      "798:\tlearn: 4.3095674\ttest: 5.9544282\tbest: 5.9544282 (798)\ttotal: 2.02s\tremaining: 8m 22s\n",
      "799:\tlearn: 4.3067112\ttest: 5.9521601\tbest: 5.9521601 (799)\ttotal: 2.02s\tremaining: 8m 22s\n",
      "800:\tlearn: 4.3050719\ttest: 5.9512611\tbest: 5.9512611 (800)\ttotal: 2.02s\tremaining: 8m 22s\n",
      "801:\tlearn: 4.3037605\ttest: 5.9507431\tbest: 5.9507431 (801)\ttotal: 2.02s\tremaining: 8m 22s\n",
      "802:\tlearn: 4.3003615\ttest: 5.9501068\tbest: 5.9501068 (802)\ttotal: 2.02s\tremaining: 8m 22s\n",
      "803:\tlearn: 4.2998260\ttest: 5.9499020\tbest: 5.9499020 (803)\ttotal: 2.03s\tremaining: 8m 22s\n",
      "804:\tlearn: 4.2987306\ttest: 5.9493154\tbest: 5.9493154 (804)\ttotal: 2.03s\tremaining: 8m 22s\n",
      "805:\tlearn: 4.2947596\ttest: 5.9468821\tbest: 5.9468821 (805)\ttotal: 2.03s\tremaining: 8m 22s\n",
      "806:\tlearn: 4.2933420\ttest: 5.9461455\tbest: 5.9461455 (806)\ttotal: 2.03s\tremaining: 8m 22s\n",
      "807:\tlearn: 4.2908131\ttest: 5.9448135\tbest: 5.9448135 (807)\ttotal: 2.04s\tremaining: 8m 21s\n",
      "808:\tlearn: 4.2867348\ttest: 5.9437231\tbest: 5.9437231 (808)\ttotal: 2.04s\tremaining: 8m 21s\n",
      "809:\tlearn: 4.2844134\ttest: 5.9425965\tbest: 5.9425965 (809)\ttotal: 2.04s\tremaining: 8m 21s\n",
      "810:\tlearn: 4.2829952\ttest: 5.9421759\tbest: 5.9421759 (810)\ttotal: 2.04s\tremaining: 8m 21s\n",
      "811:\tlearn: 4.2808990\ttest: 5.9403135\tbest: 5.9403135 (811)\ttotal: 2.04s\tremaining: 8m 21s\n",
      "812:\tlearn: 4.2800844\ttest: 5.9397952\tbest: 5.9397952 (812)\ttotal: 2.05s\tremaining: 8m 21s\n",
      "813:\tlearn: 4.2739629\ttest: 5.9372452\tbest: 5.9372452 (813)\ttotal: 2.05s\tremaining: 8m 21s\n",
      "814:\tlearn: 4.2703540\ttest: 5.9354572\tbest: 5.9354572 (814)\ttotal: 2.05s\tremaining: 8m 21s\n",
      "815:\tlearn: 4.2694646\ttest: 5.9348869\tbest: 5.9348869 (815)\ttotal: 2.05s\tremaining: 8m 21s\n",
      "816:\tlearn: 4.2683125\ttest: 5.9352761\tbest: 5.9348869 (815)\ttotal: 2.06s\tremaining: 8m 21s\n",
      "817:\tlearn: 4.2670887\ttest: 5.9346614\tbest: 5.9346614 (817)\ttotal: 2.06s\tremaining: 8m 21s\n",
      "818:\tlearn: 4.2614790\ttest: 5.9325042\tbest: 5.9325042 (818)\ttotal: 2.06s\tremaining: 8m 21s\n",
      "819:\tlearn: 4.2606844\ttest: 5.9308206\tbest: 5.9308206 (819)\ttotal: 2.06s\tremaining: 8m 21s\n",
      "820:\tlearn: 4.2586306\ttest: 5.9299212\tbest: 5.9299212 (820)\ttotal: 2.06s\tremaining: 8m 21s\n",
      "821:\tlearn: 4.2541216\ttest: 5.9246931\tbest: 5.9246931 (821)\ttotal: 2.07s\tremaining: 8m 21s\n",
      "822:\tlearn: 4.2527868\ttest: 5.9241265\tbest: 5.9241265 (822)\ttotal: 2.07s\tremaining: 8m 21s\n",
      "823:\tlearn: 4.2520659\ttest: 5.9238324\tbest: 5.9238324 (823)\ttotal: 2.07s\tremaining: 8m 21s\n",
      "824:\tlearn: 4.2510074\ttest: 5.9236555\tbest: 5.9236555 (824)\ttotal: 2.08s\tremaining: 8m 21s\n",
      "825:\tlearn: 4.2490600\ttest: 5.9215642\tbest: 5.9215642 (825)\ttotal: 2.08s\tremaining: 8m 21s\n",
      "826:\tlearn: 4.2468556\ttest: 5.9200029\tbest: 5.9200029 (826)\ttotal: 2.08s\tremaining: 8m 21s\n",
      "827:\tlearn: 4.2447507\ttest: 5.9176923\tbest: 5.9176923 (827)\ttotal: 2.08s\tremaining: 8m 21s\n",
      "828:\tlearn: 4.2434443\ttest: 5.9171541\tbest: 5.9171541 (828)\ttotal: 2.09s\tremaining: 8m 21s\n",
      "829:\tlearn: 4.2420691\ttest: 5.9167775\tbest: 5.9167775 (829)\ttotal: 2.09s\tremaining: 8m 21s\n",
      "830:\tlearn: 4.2385821\ttest: 5.9165859\tbest: 5.9165859 (830)\ttotal: 2.09s\tremaining: 8m 21s\n",
      "831:\tlearn: 4.2360765\ttest: 5.9146324\tbest: 5.9146324 (831)\ttotal: 2.1s\tremaining: 8m 21s\n",
      "832:\tlearn: 4.2327011\ttest: 5.9146297\tbest: 5.9146297 (832)\ttotal: 2.1s\tremaining: 8m 21s\n",
      "833:\tlearn: 4.2322352\ttest: 5.9144364\tbest: 5.9144364 (833)\ttotal: 2.1s\tremaining: 8m 21s\n",
      "834:\tlearn: 4.2313986\ttest: 5.9137587\tbest: 5.9137587 (834)\ttotal: 2.1s\tremaining: 8m 21s\n",
      "835:\tlearn: 4.2307397\ttest: 5.9134988\tbest: 5.9134988 (835)\ttotal: 2.1s\tremaining: 8m 21s\n",
      "836:\tlearn: 4.2289073\ttest: 5.9137887\tbest: 5.9134988 (835)\ttotal: 2.11s\tremaining: 8m 21s\n",
      "837:\tlearn: 4.2272090\ttest: 5.9131364\tbest: 5.9131364 (837)\ttotal: 2.11s\tremaining: 8m 21s\n",
      "838:\tlearn: 4.2263863\ttest: 5.9125362\tbest: 5.9125362 (838)\ttotal: 2.11s\tremaining: 8m 21s\n",
      "839:\tlearn: 4.2244500\ttest: 5.9125318\tbest: 5.9125318 (839)\ttotal: 2.11s\tremaining: 8m 21s\n",
      "840:\tlearn: 4.2221105\ttest: 5.9091173\tbest: 5.9091173 (840)\ttotal: 2.12s\tremaining: 8m 21s\n",
      "841:\tlearn: 4.2217359\ttest: 5.9092060\tbest: 5.9091173 (840)\ttotal: 2.12s\tremaining: 8m 21s\n",
      "842:\tlearn: 4.2204321\ttest: 5.9094080\tbest: 5.9091173 (840)\ttotal: 2.12s\tremaining: 8m 21s\n",
      "843:\tlearn: 4.2177476\ttest: 5.9094801\tbest: 5.9091173 (840)\ttotal: 2.12s\tremaining: 8m 21s\n",
      "844:\tlearn: 4.2170770\ttest: 5.9090886\tbest: 5.9090886 (844)\ttotal: 2.13s\tremaining: 8m 21s\n",
      "845:\tlearn: 4.2141223\ttest: 5.9075503\tbest: 5.9075503 (845)\ttotal: 2.13s\tremaining: 8m 21s\n",
      "846:\tlearn: 4.2128687\ttest: 5.9068637\tbest: 5.9068637 (846)\ttotal: 2.13s\tremaining: 8m 20s\n",
      "847:\tlearn: 4.2101536\ttest: 5.9050602\tbest: 5.9050602 (847)\ttotal: 2.13s\tremaining: 8m 20s\n",
      "848:\tlearn: 4.2063105\ttest: 5.9022348\tbest: 5.9022348 (848)\ttotal: 2.13s\tremaining: 8m 20s\n",
      "849:\tlearn: 4.2051561\ttest: 5.9010403\tbest: 5.9010403 (849)\ttotal: 2.14s\tremaining: 8m 20s\n",
      "850:\tlearn: 4.2035854\ttest: 5.9021128\tbest: 5.9010403 (849)\ttotal: 2.14s\tremaining: 8m 20s\n",
      "851:\tlearn: 4.2027154\ttest: 5.9024798\tbest: 5.9010403 (849)\ttotal: 2.14s\tremaining: 8m 20s\n",
      "852:\tlearn: 4.2021628\ttest: 5.9022105\tbest: 5.9010403 (849)\ttotal: 2.14s\tremaining: 8m 20s\n",
      "853:\tlearn: 4.2006181\ttest: 5.9004092\tbest: 5.9004092 (853)\ttotal: 2.15s\tremaining: 8m 20s\n",
      "854:\tlearn: 4.2001931\ttest: 5.9004696\tbest: 5.9004092 (853)\ttotal: 2.15s\tremaining: 8m 20s\n",
      "855:\tlearn: 4.1996063\ttest: 5.8996986\tbest: 5.8996986 (855)\ttotal: 2.15s\tremaining: 8m 20s\n",
      "856:\tlearn: 4.1987645\ttest: 5.8992317\tbest: 5.8992317 (856)\ttotal: 2.15s\tremaining: 8m 20s\n",
      "857:\tlearn: 4.1980963\ttest: 5.8992768\tbest: 5.8992317 (856)\ttotal: 2.15s\tremaining: 8m 19s\n",
      "858:\tlearn: 4.1953297\ttest: 5.8981406\tbest: 5.8981406 (858)\ttotal: 2.16s\tremaining: 8m 19s\n",
      "859:\tlearn: 4.1940744\ttest: 5.8977673\tbest: 5.8977673 (859)\ttotal: 2.16s\tremaining: 8m 19s\n",
      "860:\tlearn: 4.1929367\ttest: 5.8967067\tbest: 5.8967067 (860)\ttotal: 2.16s\tremaining: 8m 19s\n",
      "861:\tlearn: 4.1908704\ttest: 5.8958166\tbest: 5.8958166 (861)\ttotal: 2.16s\tremaining: 8m 19s\n",
      "862:\tlearn: 4.1886154\ttest: 5.8945144\tbest: 5.8945144 (862)\ttotal: 2.17s\tremaining: 8m 19s\n",
      "863:\tlearn: 4.1861180\ttest: 5.8926237\tbest: 5.8926237 (863)\ttotal: 2.17s\tremaining: 8m 19s\n",
      "864:\tlearn: 4.1830684\ttest: 5.8912114\tbest: 5.8912114 (864)\ttotal: 2.17s\tremaining: 8m 19s\n",
      "865:\tlearn: 4.1818267\ttest: 5.8905689\tbest: 5.8905689 (865)\ttotal: 2.17s\tremaining: 8m 19s\n",
      "866:\tlearn: 4.1805761\ttest: 5.8896854\tbest: 5.8896854 (866)\ttotal: 2.17s\tremaining: 8m 19s\n",
      "867:\tlearn: 4.1783259\ttest: 5.8883831\tbest: 5.8883831 (867)\ttotal: 2.18s\tremaining: 8m 19s\n",
      "868:\tlearn: 4.1773469\ttest: 5.8876299\tbest: 5.8876299 (868)\ttotal: 2.18s\tremaining: 8m 19s\n",
      "869:\tlearn: 4.1759293\ttest: 5.8862202\tbest: 5.8862202 (869)\ttotal: 2.18s\tremaining: 8m 19s\n",
      "870:\tlearn: 4.1744795\ttest: 5.8848705\tbest: 5.8848705 (870)\ttotal: 2.19s\tremaining: 8m 19s\n",
      "871:\tlearn: 4.1738685\ttest: 5.8846514\tbest: 5.8846514 (871)\ttotal: 2.19s\tremaining: 8m 19s\n",
      "872:\tlearn: 4.1729005\ttest: 5.8836287\tbest: 5.8836287 (872)\ttotal: 2.19s\tremaining: 8m 19s\n",
      "873:\tlearn: 4.1722432\ttest: 5.8834028\tbest: 5.8834028 (873)\ttotal: 2.19s\tremaining: 8m 19s\n",
      "874:\tlearn: 4.1717703\ttest: 5.8830448\tbest: 5.8830448 (874)\ttotal: 2.19s\tremaining: 8m 19s\n",
      "875:\tlearn: 4.1693632\ttest: 5.8811796\tbest: 5.8811796 (875)\ttotal: 2.2s\tremaining: 8m 19s\n",
      "876:\tlearn: 4.1681140\ttest: 5.8797204\tbest: 5.8797204 (876)\ttotal: 2.2s\tremaining: 8m 19s\n",
      "877:\tlearn: 4.1666034\ttest: 5.8793980\tbest: 5.8793980 (877)\ttotal: 2.2s\tremaining: 8m 19s\n",
      "878:\tlearn: 4.1647644\ttest: 5.8772910\tbest: 5.8772910 (878)\ttotal: 2.21s\tremaining: 8m 19s\n",
      "879:\tlearn: 4.1639750\ttest: 5.8773310\tbest: 5.8772910 (878)\ttotal: 2.21s\tremaining: 8m 19s\n",
      "880:\tlearn: 4.1636250\ttest: 5.8771562\tbest: 5.8771562 (880)\ttotal: 2.21s\tremaining: 8m 20s\n",
      "881:\tlearn: 4.1627081\ttest: 5.8768115\tbest: 5.8768115 (881)\ttotal: 2.22s\tremaining: 8m 20s\n",
      "882:\tlearn: 4.1603373\ttest: 5.8754670\tbest: 5.8754670 (882)\ttotal: 2.22s\tremaining: 8m 20s\n",
      "883:\tlearn: 4.1589352\ttest: 5.8727907\tbest: 5.8727907 (883)\ttotal: 2.22s\tremaining: 8m 20s\n",
      "884:\tlearn: 4.1583557\ttest: 5.8725206\tbest: 5.8725206 (884)\ttotal: 2.23s\tremaining: 8m 20s\n",
      "885:\tlearn: 4.1577308\ttest: 5.8723124\tbest: 5.8723124 (885)\ttotal: 2.23s\tremaining: 8m 20s\n",
      "886:\tlearn: 4.1553610\ttest: 5.8713759\tbest: 5.8713759 (886)\ttotal: 2.23s\tremaining: 8m 20s\n",
      "887:\tlearn: 4.1538313\ttest: 5.8706388\tbest: 5.8706388 (887)\ttotal: 2.23s\tremaining: 8m 20s\n",
      "888:\tlearn: 4.1531682\ttest: 5.8702853\tbest: 5.8702853 (888)\ttotal: 2.24s\tremaining: 8m 21s\n",
      "889:\tlearn: 4.1524303\ttest: 5.8707111\tbest: 5.8702853 (888)\ttotal: 2.24s\tremaining: 8m 21s\n",
      "890:\tlearn: 4.1518561\ttest: 5.8704717\tbest: 5.8702853 (888)\ttotal: 2.24s\tremaining: 8m 21s\n",
      "891:\tlearn: 4.1506756\ttest: 5.8699731\tbest: 5.8699731 (891)\ttotal: 2.25s\tremaining: 8m 21s\n",
      "892:\tlearn: 4.1494004\ttest: 5.8677605\tbest: 5.8677605 (892)\ttotal: 2.25s\tremaining: 8m 21s\n",
      "893:\tlearn: 4.1480940\ttest: 5.8673523\tbest: 5.8673523 (893)\ttotal: 2.25s\tremaining: 8m 21s\n",
      "894:\tlearn: 4.1460870\ttest: 5.8696106\tbest: 5.8673523 (893)\ttotal: 2.26s\tremaining: 8m 22s\n",
      "895:\tlearn: 4.1414319\ttest: 5.8671176\tbest: 5.8671176 (895)\ttotal: 2.26s\tremaining: 8m 22s\n",
      "896:\tlearn: 4.1410502\ttest: 5.8668917\tbest: 5.8668917 (896)\ttotal: 2.26s\tremaining: 8m 22s\n",
      "897:\tlearn: 4.1373355\ttest: 5.8690304\tbest: 5.8668917 (896)\ttotal: 2.27s\tremaining: 8m 22s\n",
      "898:\tlearn: 4.1364974\ttest: 5.8680894\tbest: 5.8668917 (896)\ttotal: 2.27s\tremaining: 8m 22s\n",
      "899:\tlearn: 4.1351629\ttest: 5.8675263\tbest: 5.8668917 (896)\ttotal: 2.27s\tremaining: 8m 22s\n",
      "900:\tlearn: 4.1311115\ttest: 5.8631889\tbest: 5.8631889 (900)\ttotal: 2.27s\tremaining: 8m 22s\n",
      "901:\tlearn: 4.1304122\ttest: 5.8626183\tbest: 5.8626183 (901)\ttotal: 2.28s\tremaining: 8m 22s\n",
      "902:\tlearn: 4.1288382\ttest: 5.8622607\tbest: 5.8622607 (902)\ttotal: 2.28s\tremaining: 8m 22s\n",
      "903:\tlearn: 4.1248696\ttest: 5.8605169\tbest: 5.8605169 (903)\ttotal: 2.28s\tremaining: 8m 22s\n",
      "904:\tlearn: 4.1232970\ttest: 5.8598642\tbest: 5.8598642 (904)\ttotal: 2.28s\tremaining: 8m 22s\n",
      "905:\tlearn: 4.1198271\ttest: 5.8555710\tbest: 5.8555710 (905)\ttotal: 2.29s\tremaining: 8m 22s\n",
      "906:\tlearn: 4.1177860\ttest: 5.8547686\tbest: 5.8547686 (906)\ttotal: 2.29s\tremaining: 8m 22s\n",
      "907:\tlearn: 4.1171951\ttest: 5.8547299\tbest: 5.8547299 (907)\ttotal: 2.29s\tremaining: 8m 22s\n",
      "908:\tlearn: 4.1154726\ttest: 5.8550778\tbest: 5.8547299 (907)\ttotal: 2.29s\tremaining: 8m 22s\n",
      "909:\tlearn: 4.1118434\ttest: 5.8519816\tbest: 5.8519816 (909)\ttotal: 2.3s\tremaining: 8m 22s\n",
      "910:\tlearn: 4.1110706\ttest: 5.8519575\tbest: 5.8519575 (910)\ttotal: 2.3s\tremaining: 8m 22s\n",
      "911:\tlearn: 4.1014629\ttest: 5.8464686\tbest: 5.8464686 (911)\ttotal: 2.3s\tremaining: 8m 22s\n",
      "912:\tlearn: 4.0982966\ttest: 5.8445933\tbest: 5.8445933 (912)\ttotal: 2.3s\tremaining: 8m 22s\n",
      "913:\tlearn: 4.0960401\ttest: 5.8427871\tbest: 5.8427871 (913)\ttotal: 2.31s\tremaining: 8m 22s\n",
      "914:\tlearn: 4.0953803\ttest: 5.8423414\tbest: 5.8423414 (914)\ttotal: 2.31s\tremaining: 8m 22s\n",
      "915:\tlearn: 4.0947970\ttest: 5.8422567\tbest: 5.8422567 (915)\ttotal: 2.31s\tremaining: 8m 22s\n",
      "916:\tlearn: 4.0942702\ttest: 5.8415937\tbest: 5.8415937 (916)\ttotal: 2.31s\tremaining: 8m 22s\n",
      "917:\tlearn: 4.0931405\ttest: 5.8410313\tbest: 5.8410313 (917)\ttotal: 2.32s\tremaining: 8m 22s\n",
      "918:\tlearn: 4.0919768\ttest: 5.8394475\tbest: 5.8394475 (918)\ttotal: 2.32s\tremaining: 8m 22s\n",
      "919:\tlearn: 4.0901822\ttest: 5.8380515\tbest: 5.8380515 (919)\ttotal: 2.32s\tremaining: 8m 22s\n",
      "920:\tlearn: 4.0899921\ttest: 5.8376691\tbest: 5.8376691 (920)\ttotal: 2.32s\tremaining: 8m 22s\n",
      "921:\tlearn: 4.0896918\ttest: 5.8377414\tbest: 5.8376691 (920)\ttotal: 2.33s\tremaining: 8m 22s\n",
      "922:\tlearn: 4.0873108\ttest: 5.8365230\tbest: 5.8365230 (922)\ttotal: 2.33s\tremaining: 8m 22s\n",
      "923:\tlearn: 4.0866545\ttest: 5.8365918\tbest: 5.8365230 (922)\ttotal: 2.33s\tremaining: 8m 22s\n",
      "924:\tlearn: 4.0854552\ttest: 5.8357967\tbest: 5.8357967 (924)\ttotal: 2.33s\tremaining: 8m 22s\n",
      "925:\tlearn: 4.0848803\ttest: 5.8351548\tbest: 5.8351548 (925)\ttotal: 2.33s\tremaining: 8m 22s\n",
      "926:\tlearn: 4.0836271\ttest: 5.8337479\tbest: 5.8337479 (926)\ttotal: 2.34s\tremaining: 8m 22s\n",
      "927:\tlearn: 4.0833773\ttest: 5.8333644\tbest: 5.8333644 (927)\ttotal: 2.34s\tremaining: 8m 22s\n",
      "928:\tlearn: 4.0824924\ttest: 5.8324511\tbest: 5.8324511 (928)\ttotal: 2.34s\tremaining: 8m 22s\n",
      "929:\tlearn: 4.0809387\ttest: 5.8324864\tbest: 5.8324511 (928)\ttotal: 2.35s\tremaining: 8m 22s\n",
      "930:\tlearn: 4.0788672\ttest: 5.8304599\tbest: 5.8304599 (930)\ttotal: 2.35s\tremaining: 8m 21s\n",
      "931:\tlearn: 4.0774037\ttest: 5.8289093\tbest: 5.8289093 (931)\ttotal: 2.35s\tremaining: 8m 21s\n",
      "932:\tlearn: 4.0765013\ttest: 5.8285304\tbest: 5.8285304 (932)\ttotal: 2.35s\tremaining: 8m 21s\n",
      "933:\tlearn: 4.0759903\ttest: 5.8280058\tbest: 5.8280058 (933)\ttotal: 2.35s\tremaining: 8m 21s\n",
      "934:\tlearn: 4.0750061\ttest: 5.8259990\tbest: 5.8259990 (934)\ttotal: 2.36s\tremaining: 8m 21s\n",
      "935:\tlearn: 4.0738444\ttest: 5.8256902\tbest: 5.8256902 (935)\ttotal: 2.36s\tremaining: 8m 21s\n",
      "936:\tlearn: 4.0718424\ttest: 5.8255879\tbest: 5.8255879 (936)\ttotal: 2.36s\tremaining: 8m 21s\n",
      "937:\tlearn: 4.0709863\ttest: 5.8247794\tbest: 5.8247794 (937)\ttotal: 2.36s\tremaining: 8m 21s\n",
      "938:\tlearn: 4.0688948\ttest: 5.8224915\tbest: 5.8224915 (938)\ttotal: 2.37s\tremaining: 8m 21s\n",
      "939:\tlearn: 4.0684665\ttest: 5.8227239\tbest: 5.8224915 (938)\ttotal: 2.37s\tremaining: 8m 21s\n",
      "940:\tlearn: 4.0682818\ttest: 5.8226541\tbest: 5.8224915 (938)\ttotal: 2.37s\tremaining: 8m 21s\n",
      "941:\tlearn: 4.0674674\ttest: 5.8220525\tbest: 5.8220525 (941)\ttotal: 2.38s\tremaining: 8m 22s\n",
      "942:\tlearn: 4.0653317\ttest: 5.8210772\tbest: 5.8210772 (942)\ttotal: 2.38s\tremaining: 8m 22s\n",
      "943:\tlearn: 4.0646115\ttest: 5.8206318\tbest: 5.8206318 (943)\ttotal: 2.38s\tremaining: 8m 22s\n",
      "944:\tlearn: 4.0642428\ttest: 5.8204216\tbest: 5.8204216 (944)\ttotal: 2.38s\tremaining: 8m 22s\n",
      "945:\tlearn: 4.0629513\ttest: 5.8201280\tbest: 5.8201280 (945)\ttotal: 2.39s\tremaining: 8m 22s\n",
      "946:\tlearn: 4.0614794\ttest: 5.8185497\tbest: 5.8185497 (946)\ttotal: 2.39s\tremaining: 8m 22s\n",
      "947:\tlearn: 4.0590163\ttest: 5.8200312\tbest: 5.8185497 (946)\ttotal: 2.39s\tremaining: 8m 22s\n",
      "948:\tlearn: 4.0579887\ttest: 5.8189913\tbest: 5.8185497 (946)\ttotal: 2.39s\tremaining: 8m 22s\n",
      "949:\tlearn: 4.0565413\ttest: 5.8170910\tbest: 5.8170910 (949)\ttotal: 2.4s\tremaining: 8m 22s\n",
      "950:\tlearn: 4.0560982\ttest: 5.8165262\tbest: 5.8165262 (950)\ttotal: 2.4s\tremaining: 8m 22s\n",
      "951:\tlearn: 4.0552149\ttest: 5.8156847\tbest: 5.8156847 (951)\ttotal: 2.4s\tremaining: 8m 22s\n",
      "952:\tlearn: 4.0519950\ttest: 5.8139955\tbest: 5.8139955 (952)\ttotal: 2.4s\tremaining: 8m 22s\n",
      "953:\tlearn: 4.0513440\ttest: 5.8139441\tbest: 5.8139441 (953)\ttotal: 2.41s\tremaining: 8m 22s\n",
      "954:\tlearn: 4.0505355\ttest: 5.8131635\tbest: 5.8131635 (954)\ttotal: 2.41s\tremaining: 8m 22s\n",
      "955:\tlearn: 4.0493894\ttest: 5.8124915\tbest: 5.8124915 (955)\ttotal: 2.41s\tremaining: 8m 22s\n",
      "956:\tlearn: 4.0477895\ttest: 5.8111587\tbest: 5.8111587 (956)\ttotal: 2.41s\tremaining: 8m 22s\n",
      "957:\tlearn: 4.0475627\ttest: 5.8110031\tbest: 5.8110031 (957)\ttotal: 2.42s\tremaining: 8m 22s\n",
      "958:\tlearn: 4.0470870\ttest: 5.8103628\tbest: 5.8103628 (958)\ttotal: 2.42s\tremaining: 8m 22s\n",
      "959:\tlearn: 4.0468024\ttest: 5.8098728\tbest: 5.8098728 (959)\ttotal: 2.42s\tremaining: 8m 22s\n",
      "960:\tlearn: 4.0457156\ttest: 5.8073990\tbest: 5.8073990 (960)\ttotal: 2.42s\tremaining: 8m 22s\n",
      "961:\tlearn: 4.0448812\ttest: 5.8077469\tbest: 5.8073990 (960)\ttotal: 2.43s\tremaining: 8m 22s\n",
      "962:\tlearn: 4.0443939\ttest: 5.8079742\tbest: 5.8073990 (960)\ttotal: 2.43s\tremaining: 8m 22s\n",
      "963:\tlearn: 4.0429254\ttest: 5.8080144\tbest: 5.8073990 (960)\ttotal: 2.43s\tremaining: 8m 22s\n",
      "964:\tlearn: 4.0394516\ttest: 5.8066625\tbest: 5.8066625 (964)\ttotal: 2.43s\tremaining: 8m 22s\n",
      "965:\tlearn: 4.0385308\ttest: 5.8072818\tbest: 5.8066625 (964)\ttotal: 2.44s\tremaining: 8m 22s\n",
      "966:\tlearn: 4.0372316\ttest: 5.8074636\tbest: 5.8066625 (964)\ttotal: 2.44s\tremaining: 8m 22s\n",
      "967:\tlearn: 4.0370734\ttest: 5.8073198\tbest: 5.8066625 (964)\ttotal: 2.44s\tremaining: 8m 22s\n",
      "968:\tlearn: 4.0345958\ttest: 5.8056418\tbest: 5.8056418 (968)\ttotal: 2.44s\tremaining: 8m 22s\n",
      "969:\tlearn: 4.0335680\ttest: 5.8045145\tbest: 5.8045145 (969)\ttotal: 2.45s\tremaining: 8m 22s\n",
      "970:\tlearn: 4.0305936\ttest: 5.8076492\tbest: 5.8045145 (969)\ttotal: 2.45s\tremaining: 8m 22s\n",
      "971:\tlearn: 4.0301630\ttest: 5.8080326\tbest: 5.8045145 (969)\ttotal: 2.45s\tremaining: 8m 22s\n",
      "972:\tlearn: 4.0298530\ttest: 5.8077512\tbest: 5.8045145 (969)\ttotal: 2.46s\tremaining: 8m 22s\n",
      "973:\tlearn: 4.0292109\ttest: 5.8068936\tbest: 5.8045145 (969)\ttotal: 2.46s\tremaining: 8m 22s\n",
      "974:\tlearn: 4.0288941\ttest: 5.8062448\tbest: 5.8045145 (969)\ttotal: 2.46s\tremaining: 8m 22s\n",
      "975:\tlearn: 4.0283199\ttest: 5.8065844\tbest: 5.8045145 (969)\ttotal: 2.46s\tremaining: 8m 22s\n",
      "976:\tlearn: 4.0266541\ttest: 5.8050953\tbest: 5.8045145 (969)\ttotal: 2.46s\tremaining: 8m 21s\n",
      "977:\tlearn: 4.0255247\ttest: 5.8056341\tbest: 5.8045145 (969)\ttotal: 2.47s\tremaining: 8m 21s\n",
      "978:\tlearn: 4.0241357\ttest: 5.8036304\tbest: 5.8036304 (978)\ttotal: 2.47s\tremaining: 8m 21s\n",
      "979:\tlearn: 4.0233067\ttest: 5.8038001\tbest: 5.8036304 (978)\ttotal: 2.47s\tremaining: 8m 21s\n",
      "980:\tlearn: 4.0226749\ttest: 5.8029841\tbest: 5.8029841 (980)\ttotal: 2.47s\tremaining: 8m 21s\n",
      "981:\tlearn: 4.0211318\ttest: 5.8026481\tbest: 5.8026481 (981)\ttotal: 2.48s\tremaining: 8m 21s\n",
      "982:\tlearn: 4.0208912\ttest: 5.8023797\tbest: 5.8023797 (982)\ttotal: 2.48s\tremaining: 8m 21s\n",
      "983:\tlearn: 4.0205100\ttest: 5.8025343\tbest: 5.8023797 (982)\ttotal: 2.48s\tremaining: 8m 21s\n",
      "984:\tlearn: 4.0193373\ttest: 5.8020415\tbest: 5.8020415 (984)\ttotal: 2.48s\tremaining: 8m 21s\n",
      "985:\tlearn: 4.0187242\ttest: 5.8019683\tbest: 5.8019683 (985)\ttotal: 2.48s\tremaining: 8m 21s\n",
      "986:\tlearn: 4.0184618\ttest: 5.8013522\tbest: 5.8013522 (986)\ttotal: 2.49s\tremaining: 8m 21s\n",
      "987:\tlearn: 4.0180231\ttest: 5.8014586\tbest: 5.8013522 (986)\ttotal: 2.49s\tremaining: 8m 21s\n",
      "988:\tlearn: 4.0176683\ttest: 5.8018698\tbest: 5.8013522 (986)\ttotal: 2.49s\tremaining: 8m 21s\n",
      "989:\tlearn: 4.0158997\ttest: 5.7992172\tbest: 5.7992172 (989)\ttotal: 2.49s\tremaining: 8m 21s\n",
      "990:\tlearn: 4.0153657\ttest: 5.7991211\tbest: 5.7991211 (990)\ttotal: 2.5s\tremaining: 8m 21s\n",
      "991:\tlearn: 4.0148757\ttest: 5.7989043\tbest: 5.7989043 (991)\ttotal: 2.5s\tremaining: 8m 20s\n",
      "992:\tlearn: 4.0127024\ttest: 5.7955244\tbest: 5.7955244 (992)\ttotal: 2.5s\tremaining: 8m 20s\n",
      "993:\tlearn: 4.0121314\ttest: 5.7950093\tbest: 5.7950093 (993)\ttotal: 2.5s\tremaining: 8m 20s\n",
      "994:\tlearn: 4.0119169\ttest: 5.7949515\tbest: 5.7949515 (994)\ttotal: 2.5s\tremaining: 8m 20s\n",
      "995:\tlearn: 4.0103413\ttest: 5.7946537\tbest: 5.7946537 (995)\ttotal: 2.5s\tremaining: 8m 20s\n",
      "996:\tlearn: 4.0102440\ttest: 5.7945012\tbest: 5.7945012 (996)\ttotal: 2.51s\tremaining: 8m 20s\n",
      "997:\tlearn: 4.0097474\ttest: 5.7948738\tbest: 5.7945012 (996)\ttotal: 2.51s\tremaining: 8m 20s\n",
      "998:\tlearn: 4.0086907\ttest: 5.7936135\tbest: 5.7936135 (998)\ttotal: 2.51s\tremaining: 8m 20s\n",
      "999:\tlearn: 4.0078459\ttest: 5.7927812\tbest: 5.7927812 (999)\ttotal: 2.51s\tremaining: 8m 20s\n",
      "1000:\tlearn: 4.0069103\ttest: 5.7917469\tbest: 5.7917469 (1000)\ttotal: 2.52s\tremaining: 8m 20s\n",
      "1001:\tlearn: 4.0066198\ttest: 5.7915082\tbest: 5.7915082 (1001)\ttotal: 2.52s\tremaining: 8m 20s\n",
      "1002:\tlearn: 4.0059847\ttest: 5.7916578\tbest: 5.7915082 (1001)\ttotal: 2.52s\tremaining: 8m 20s\n",
      "1003:\tlearn: 4.0038030\ttest: 5.7912943\tbest: 5.7912943 (1003)\ttotal: 2.52s\tremaining: 8m 20s\n",
      "1004:\tlearn: 4.0029654\ttest: 5.7912838\tbest: 5.7912838 (1004)\ttotal: 2.52s\tremaining: 8m 20s\n",
      "1005:\tlearn: 4.0012497\ttest: 5.7906716\tbest: 5.7906716 (1005)\ttotal: 2.53s\tremaining: 8m 19s\n",
      "1006:\tlearn: 4.0009140\ttest: 5.7900766\tbest: 5.7900766 (1006)\ttotal: 2.53s\tremaining: 8m 19s\n",
      "1007:\tlearn: 4.0005868\ttest: 5.7896712\tbest: 5.7896712 (1007)\ttotal: 2.53s\tremaining: 8m 19s\n",
      "1008:\tlearn: 3.9992689\ttest: 5.7896506\tbest: 5.7896506 (1008)\ttotal: 2.53s\tremaining: 8m 19s\n",
      "1009:\tlearn: 3.9988174\ttest: 5.7894027\tbest: 5.7894027 (1009)\ttotal: 2.54s\tremaining: 8m 19s\n",
      "1010:\tlearn: 3.9983768\ttest: 5.7890661\tbest: 5.7890661 (1010)\ttotal: 2.54s\tremaining: 8m 19s\n",
      "1011:\tlearn: 3.9978268\ttest: 5.7884148\tbest: 5.7884148 (1011)\ttotal: 2.54s\tremaining: 8m 19s\n",
      "1012:\tlearn: 3.9975836\ttest: 5.7881301\tbest: 5.7881301 (1012)\ttotal: 2.54s\tremaining: 8m 19s\n",
      "1013:\tlearn: 3.9962671\ttest: 5.7873156\tbest: 5.7873156 (1013)\ttotal: 2.54s\tremaining: 8m 19s\n",
      "1014:\tlearn: 3.9949361\ttest: 5.7877187\tbest: 5.7873156 (1013)\ttotal: 2.55s\tremaining: 8m 19s\n",
      "1015:\tlearn: 3.9946975\ttest: 5.7875958\tbest: 5.7873156 (1013)\ttotal: 2.55s\tremaining: 8m 19s\n",
      "1016:\tlearn: 3.9940259\ttest: 5.7874562\tbest: 5.7873156 (1013)\ttotal: 2.55s\tremaining: 8m 19s\n",
      "1017:\tlearn: 3.9935363\ttest: 5.7870367\tbest: 5.7870367 (1017)\ttotal: 2.55s\tremaining: 8m 19s\n",
      "1018:\tlearn: 3.9928136\ttest: 5.7866992\tbest: 5.7866992 (1018)\ttotal: 2.56s\tremaining: 8m 19s\n",
      "1019:\tlearn: 3.9919119\ttest: 5.7855588\tbest: 5.7855588 (1019)\ttotal: 2.56s\tremaining: 8m 19s\n",
      "1020:\tlearn: 3.9907736\ttest: 5.7845180\tbest: 5.7845180 (1020)\ttotal: 2.56s\tremaining: 8m 18s\n",
      "1021:\tlearn: 3.9903627\ttest: 5.7842769\tbest: 5.7842769 (1021)\ttotal: 2.56s\tremaining: 8m 18s\n",
      "1022:\tlearn: 3.9897078\ttest: 5.7842053\tbest: 5.7842053 (1022)\ttotal: 2.56s\tremaining: 8m 18s\n",
      "1023:\tlearn: 3.9889115\ttest: 5.7839062\tbest: 5.7839062 (1023)\ttotal: 2.57s\tremaining: 8m 18s\n",
      "1024:\tlearn: 3.9880083\ttest: 5.7838900\tbest: 5.7838900 (1024)\ttotal: 2.57s\tremaining: 8m 18s\n",
      "1025:\tlearn: 3.9868063\ttest: 5.7830541\tbest: 5.7830541 (1025)\ttotal: 2.57s\tremaining: 8m 18s\n",
      "1026:\tlearn: 3.9857335\ttest: 5.7835523\tbest: 5.7830541 (1025)\ttotal: 2.57s\tremaining: 8m 18s\n",
      "1027:\tlearn: 3.9854618\ttest: 5.7840867\tbest: 5.7830541 (1025)\ttotal: 2.58s\tremaining: 8m 18s\n",
      "1028:\tlearn: 3.9841472\ttest: 5.7831326\tbest: 5.7830541 (1025)\ttotal: 2.58s\tremaining: 8m 18s\n",
      "1029:\tlearn: 3.9838443\ttest: 5.7829434\tbest: 5.7829434 (1029)\ttotal: 2.58s\tremaining: 8m 18s\n",
      "1030:\tlearn: 3.9830985\ttest: 5.7823645\tbest: 5.7823645 (1030)\ttotal: 2.58s\tremaining: 8m 18s\n",
      "1031:\tlearn: 3.9826239\ttest: 5.7819337\tbest: 5.7819337 (1031)\ttotal: 2.58s\tremaining: 8m 18s\n",
      "1032:\tlearn: 3.9820418\ttest: 5.7815046\tbest: 5.7815046 (1032)\ttotal: 2.59s\tremaining: 8m 18s\n",
      "1033:\tlearn: 3.9808853\ttest: 5.7796640\tbest: 5.7796640 (1033)\ttotal: 2.59s\tremaining: 8m 18s\n",
      "1034:\tlearn: 3.9767017\ttest: 5.7761363\tbest: 5.7761363 (1034)\ttotal: 2.59s\tremaining: 8m 18s\n",
      "1035:\tlearn: 3.9718930\ttest: 5.7763529\tbest: 5.7761363 (1034)\ttotal: 2.59s\tremaining: 8m 18s\n",
      "1036:\tlearn: 3.9707732\ttest: 5.7753545\tbest: 5.7753545 (1036)\ttotal: 2.6s\tremaining: 8m 18s\n",
      "1037:\tlearn: 3.9699103\ttest: 5.7752353\tbest: 5.7752353 (1037)\ttotal: 2.6s\tremaining: 8m 18s\n",
      "1038:\tlearn: 3.9694661\ttest: 5.7755356\tbest: 5.7752353 (1037)\ttotal: 2.6s\tremaining: 8m 18s\n",
      "1039:\tlearn: 3.9557287\ttest: 5.7644350\tbest: 5.7644350 (1039)\ttotal: 2.6s\tremaining: 8m 18s\n",
      "1040:\tlearn: 3.9536105\ttest: 5.7631152\tbest: 5.7631152 (1040)\ttotal: 2.61s\tremaining: 8m 18s\n",
      "1041:\tlearn: 3.9511868\ttest: 5.7618449\tbest: 5.7618449 (1041)\ttotal: 2.61s\tremaining: 8m 18s\n",
      "1042:\tlearn: 3.9502959\ttest: 5.7624763\tbest: 5.7618449 (1041)\ttotal: 2.61s\tremaining: 8m 18s\n",
      "1043:\tlearn: 3.9488138\ttest: 5.7610008\tbest: 5.7610008 (1043)\ttotal: 2.61s\tremaining: 8m 18s\n",
      "1044:\tlearn: 3.9451605\ttest: 5.7563857\tbest: 5.7563857 (1044)\ttotal: 2.62s\tremaining: 8m 18s\n",
      "1045:\tlearn: 3.9441308\ttest: 5.7556149\tbest: 5.7556149 (1045)\ttotal: 2.62s\tremaining: 8m 18s\n",
      "1046:\tlearn: 3.9432684\ttest: 5.7546864\tbest: 5.7546864 (1046)\ttotal: 2.62s\tremaining: 8m 17s\n",
      "1047:\tlearn: 3.9418790\ttest: 5.7546556\tbest: 5.7546556 (1047)\ttotal: 2.62s\tremaining: 8m 17s\n",
      "1048:\tlearn: 3.9414066\ttest: 5.7547754\tbest: 5.7546556 (1047)\ttotal: 2.62s\tremaining: 8m 17s\n",
      "1049:\tlearn: 3.9410589\ttest: 5.7546781\tbest: 5.7546556 (1047)\ttotal: 2.63s\tremaining: 8m 17s\n",
      "1050:\tlearn: 3.9402665\ttest: 5.7543449\tbest: 5.7543449 (1050)\ttotal: 2.63s\tremaining: 8m 17s\n",
      "1051:\tlearn: 3.9384767\ttest: 5.7547476\tbest: 5.7543449 (1050)\ttotal: 2.63s\tremaining: 8m 17s\n",
      "1052:\tlearn: 3.9380851\ttest: 5.7547397\tbest: 5.7543449 (1050)\ttotal: 2.63s\tremaining: 8m 17s\n",
      "1053:\tlearn: 3.9362575\ttest: 5.7524155\tbest: 5.7524155 (1053)\ttotal: 2.63s\tremaining: 8m 17s\n",
      "1054:\tlearn: 3.9341816\ttest: 5.7520026\tbest: 5.7520026 (1054)\ttotal: 2.64s\tremaining: 8m 17s\n",
      "1055:\tlearn: 3.9337854\ttest: 5.7518963\tbest: 5.7518963 (1055)\ttotal: 2.64s\tremaining: 8m 17s\n",
      "1056:\tlearn: 3.9333379\ttest: 5.7519798\tbest: 5.7518963 (1055)\ttotal: 2.64s\tremaining: 8m 17s\n",
      "1057:\tlearn: 3.9317615\ttest: 5.7513983\tbest: 5.7513983 (1057)\ttotal: 2.64s\tremaining: 8m 17s\n",
      "1058:\tlearn: 3.9287197\ttest: 5.7539820\tbest: 5.7513983 (1057)\ttotal: 2.65s\tremaining: 8m 17s\n",
      "1059:\tlearn: 3.9278686\ttest: 5.7541506\tbest: 5.7513983 (1057)\ttotal: 2.65s\tremaining: 8m 17s\n",
      "1060:\tlearn: 3.9270641\ttest: 5.7539628\tbest: 5.7513983 (1057)\ttotal: 2.65s\tremaining: 8m 17s\n",
      "1061:\tlearn: 3.9247046\ttest: 5.7511983\tbest: 5.7511983 (1061)\ttotal: 2.65s\tremaining: 8m 16s\n",
      "1062:\tlearn: 3.9228106\ttest: 5.7523704\tbest: 5.7511983 (1061)\ttotal: 2.65s\tremaining: 8m 16s\n",
      "1063:\tlearn: 3.9215229\ttest: 5.7523684\tbest: 5.7511983 (1061)\ttotal: 2.66s\tremaining: 8m 16s\n",
      "1064:\tlearn: 3.9207076\ttest: 5.7519846\tbest: 5.7511983 (1061)\ttotal: 2.66s\tremaining: 8m 16s\n",
      "1065:\tlearn: 3.9201748\ttest: 5.7518820\tbest: 5.7511983 (1061)\ttotal: 2.66s\tremaining: 8m 16s\n",
      "1066:\tlearn: 3.9191767\ttest: 5.7513992\tbest: 5.7511983 (1061)\ttotal: 2.66s\tremaining: 8m 16s\n",
      "1067:\tlearn: 3.9186898\ttest: 5.7513277\tbest: 5.7511983 (1061)\ttotal: 2.67s\tremaining: 8m 16s\n",
      "1068:\tlearn: 3.9175705\ttest: 5.7514798\tbest: 5.7511983 (1061)\ttotal: 2.67s\tremaining: 8m 16s\n",
      "1069:\tlearn: 3.9166995\ttest: 5.7513615\tbest: 5.7511983 (1061)\ttotal: 2.67s\tremaining: 8m 16s\n",
      "1070:\tlearn: 3.9163953\ttest: 5.7509295\tbest: 5.7509295 (1070)\ttotal: 2.67s\tremaining: 8m 16s\n",
      "1071:\tlearn: 3.9152053\ttest: 5.7497602\tbest: 5.7497602 (1071)\ttotal: 2.67s\tremaining: 8m 16s\n",
      "1072:\tlearn: 3.9146570\ttest: 5.7494974\tbest: 5.7494974 (1072)\ttotal: 2.68s\tremaining: 8m 16s\n",
      "1073:\tlearn: 3.9132565\ttest: 5.7487119\tbest: 5.7487119 (1073)\ttotal: 2.68s\tremaining: 8m 16s\n",
      "1074:\tlearn: 3.9114398\ttest: 5.7482883\tbest: 5.7482883 (1074)\ttotal: 2.68s\tremaining: 8m 16s\n",
      "1075:\tlearn: 3.9110754\ttest: 5.7479334\tbest: 5.7479334 (1075)\ttotal: 2.68s\tremaining: 8m 16s\n",
      "1076:\tlearn: 3.9105017\ttest: 5.7484136\tbest: 5.7479334 (1075)\ttotal: 2.69s\tremaining: 8m 16s\n",
      "1077:\tlearn: 3.9085281\ttest: 5.7468323\tbest: 5.7468323 (1077)\ttotal: 2.69s\tremaining: 8m 16s\n",
      "1078:\tlearn: 3.9074761\ttest: 5.7470490\tbest: 5.7468323 (1077)\ttotal: 2.69s\tremaining: 8m 16s\n",
      "1079:\tlearn: 3.9066518\ttest: 5.7463620\tbest: 5.7463620 (1079)\ttotal: 2.69s\tremaining: 8m 16s\n",
      "1080:\tlearn: 3.9055010\ttest: 5.7454641\tbest: 5.7454641 (1080)\ttotal: 2.7s\tremaining: 8m 16s\n",
      "1081:\tlearn: 3.9038869\ttest: 5.7456501\tbest: 5.7454641 (1080)\ttotal: 2.7s\tremaining: 8m 16s\n",
      "1082:\tlearn: 3.9021258\ttest: 5.7468812\tbest: 5.7454641 (1080)\ttotal: 2.7s\tremaining: 8m 16s\n",
      "1083:\tlearn: 3.9018237\ttest: 5.7465573\tbest: 5.7454641 (1080)\ttotal: 2.71s\tremaining: 8m 16s\n",
      "1084:\tlearn: 3.8988645\ttest: 5.7448019\tbest: 5.7448019 (1084)\ttotal: 2.71s\tremaining: 8m 16s\n",
      "1085:\tlearn: 3.8984612\ttest: 5.7446011\tbest: 5.7446011 (1085)\ttotal: 2.71s\tremaining: 8m 16s\n",
      "1086:\tlearn: 3.8982045\ttest: 5.7445181\tbest: 5.7445181 (1086)\ttotal: 2.71s\tremaining: 8m 16s\n",
      "1087:\tlearn: 3.8979856\ttest: 5.7442856\tbest: 5.7442856 (1087)\ttotal: 2.71s\tremaining: 8m 16s\n",
      "1088:\tlearn: 3.8960964\ttest: 5.7441898\tbest: 5.7441898 (1088)\ttotal: 2.72s\tremaining: 8m 16s\n",
      "1089:\tlearn: 3.8949695\ttest: 5.7435828\tbest: 5.7435828 (1089)\ttotal: 2.72s\tremaining: 8m 16s\n",
      "1090:\tlearn: 3.8934450\ttest: 5.7417304\tbest: 5.7417304 (1090)\ttotal: 2.72s\tremaining: 8m 16s\n",
      "1091:\tlearn: 3.8931296\ttest: 5.7413233\tbest: 5.7413233 (1091)\ttotal: 2.72s\tremaining: 8m 16s\n",
      "1092:\tlearn: 3.8915019\ttest: 5.7409098\tbest: 5.7409098 (1092)\ttotal: 2.73s\tremaining: 8m 15s\n",
      "1093:\tlearn: 3.8909959\ttest: 5.7407859\tbest: 5.7407859 (1093)\ttotal: 2.73s\tremaining: 8m 15s\n",
      "1094:\tlearn: 3.8900948\ttest: 5.7411252\tbest: 5.7407859 (1093)\ttotal: 2.73s\tremaining: 8m 15s\n",
      "1095:\tlearn: 3.8887484\ttest: 5.7397876\tbest: 5.7397876 (1095)\ttotal: 2.73s\tremaining: 8m 15s\n",
      "1096:\tlearn: 3.8866777\ttest: 5.7396375\tbest: 5.7396375 (1096)\ttotal: 2.73s\tremaining: 8m 15s\n",
      "1097:\tlearn: 3.8852993\ttest: 5.7391251\tbest: 5.7391251 (1097)\ttotal: 2.74s\tremaining: 8m 15s\n",
      "1098:\tlearn: 3.8841831\ttest: 5.7396316\tbest: 5.7391251 (1097)\ttotal: 2.74s\tremaining: 8m 15s\n",
      "1099:\tlearn: 3.8828587\ttest: 5.7387361\tbest: 5.7387361 (1099)\ttotal: 2.74s\tremaining: 8m 15s\n",
      "1100:\tlearn: 3.8800119\ttest: 5.7358345\tbest: 5.7358345 (1100)\ttotal: 2.74s\tremaining: 8m 15s\n",
      "1101:\tlearn: 3.8789976\ttest: 5.7363518\tbest: 5.7358345 (1100)\ttotal: 2.75s\tremaining: 8m 15s\n",
      "1102:\tlearn: 3.8783368\ttest: 5.7360313\tbest: 5.7358345 (1100)\ttotal: 2.75s\tremaining: 8m 15s\n",
      "1103:\tlearn: 3.8776519\ttest: 5.7361431\tbest: 5.7358345 (1100)\ttotal: 2.75s\tremaining: 8m 15s\n",
      "1104:\tlearn: 3.8764415\ttest: 5.7357539\tbest: 5.7357539 (1104)\ttotal: 2.75s\tremaining: 8m 15s\n",
      "1105:\tlearn: 3.8749762\ttest: 5.7355041\tbest: 5.7355041 (1105)\ttotal: 2.76s\tremaining: 8m 15s\n",
      "1106:\tlearn: 3.8744354\ttest: 5.7355645\tbest: 5.7355041 (1105)\ttotal: 2.76s\tremaining: 8m 15s\n",
      "1107:\tlearn: 3.8735412\ttest: 5.7351396\tbest: 5.7351396 (1107)\ttotal: 2.76s\tremaining: 8m 15s\n",
      "1108:\tlearn: 3.8728808\ttest: 5.7350666\tbest: 5.7350666 (1108)\ttotal: 2.76s\tremaining: 8m 15s\n",
      "1109:\tlearn: 3.8721250\ttest: 5.7346694\tbest: 5.7346694 (1109)\ttotal: 2.77s\tremaining: 8m 15s\n",
      "1110:\tlearn: 3.8719133\ttest: 5.7345381\tbest: 5.7345381 (1110)\ttotal: 2.77s\tremaining: 8m 15s\n",
      "1111:\tlearn: 3.8715264\ttest: 5.7349280\tbest: 5.7345381 (1110)\ttotal: 2.77s\tremaining: 8m 15s\n",
      "1112:\tlearn: 3.8713296\ttest: 5.7347678\tbest: 5.7345381 (1110)\ttotal: 2.77s\tremaining: 8m 15s\n",
      "1113:\tlearn: 3.8710353\ttest: 5.7345697\tbest: 5.7345381 (1110)\ttotal: 2.78s\tremaining: 8m 15s\n",
      "1114:\tlearn: 3.8700966\ttest: 5.7340928\tbest: 5.7340928 (1114)\ttotal: 2.78s\tremaining: 8m 15s\n",
      "1115:\tlearn: 3.8698259\ttest: 5.7340844\tbest: 5.7340844 (1115)\ttotal: 2.78s\tremaining: 8m 15s\n",
      "1116:\tlearn: 3.8676238\ttest: 5.7359261\tbest: 5.7340844 (1115)\ttotal: 2.78s\tremaining: 8m 15s\n",
      "1117:\tlearn: 3.8674321\ttest: 5.7352681\tbest: 5.7340844 (1115)\ttotal: 2.79s\tremaining: 8m 15s\n",
      "1118:\tlearn: 3.8669520\ttest: 5.7347884\tbest: 5.7340844 (1115)\ttotal: 2.79s\tremaining: 8m 15s\n",
      "1119:\tlearn: 3.8659982\ttest: 5.7347749\tbest: 5.7340844 (1115)\ttotal: 2.79s\tremaining: 8m 15s\n",
      "1120:\tlearn: 3.8641379\ttest: 5.7369112\tbest: 5.7340844 (1115)\ttotal: 2.79s\tremaining: 8m 15s\n",
      "1121:\tlearn: 3.8628633\ttest: 5.7360081\tbest: 5.7340844 (1115)\ttotal: 2.79s\tremaining: 8m 15s\n",
      "1122:\tlearn: 3.8621679\ttest: 5.7361929\tbest: 5.7340844 (1115)\ttotal: 2.8s\tremaining: 8m 15s\n",
      "1123:\tlearn: 3.8615122\ttest: 5.7354549\tbest: 5.7340844 (1115)\ttotal: 2.8s\tremaining: 8m 15s\n",
      "1124:\tlearn: 3.8596002\ttest: 5.7339294\tbest: 5.7339294 (1124)\ttotal: 2.8s\tremaining: 8m 15s\n",
      "1125:\tlearn: 3.8585790\ttest: 5.7330139\tbest: 5.7330139 (1125)\ttotal: 2.81s\tremaining: 8m 15s\n",
      "1126:\tlearn: 3.8577124\ttest: 5.7323409\tbest: 5.7323409 (1126)\ttotal: 2.81s\tremaining: 8m 15s\n",
      "1127:\tlearn: 3.8569628\ttest: 5.7319349\tbest: 5.7319349 (1127)\ttotal: 2.81s\tremaining: 8m 15s\n",
      "1128:\tlearn: 3.8564401\ttest: 5.7316899\tbest: 5.7316899 (1128)\ttotal: 2.81s\tremaining: 8m 15s\n",
      "1129:\tlearn: 3.8554496\ttest: 5.7304332\tbest: 5.7304332 (1129)\ttotal: 2.81s\tremaining: 8m 15s\n",
      "1130:\tlearn: 3.8534543\ttest: 5.7318216\tbest: 5.7304332 (1129)\ttotal: 2.82s\tremaining: 8m 15s\n",
      "1131:\tlearn: 3.8530068\ttest: 5.7320608\tbest: 5.7304332 (1129)\ttotal: 2.82s\tremaining: 8m 15s\n",
      "1132:\tlearn: 3.8516300\ttest: 5.7314037\tbest: 5.7304332 (1129)\ttotal: 2.82s\tremaining: 8m 15s\n",
      "1133:\tlearn: 3.8511042\ttest: 5.7311603\tbest: 5.7304332 (1129)\ttotal: 2.82s\tremaining: 8m 15s\n",
      "1134:\tlearn: 3.8479768\ttest: 5.7295369\tbest: 5.7295369 (1134)\ttotal: 2.83s\tremaining: 8m 15s\n",
      "1135:\tlearn: 3.8449707\ttest: 5.7288707\tbest: 5.7288707 (1135)\ttotal: 2.83s\tremaining: 8m 15s\n",
      "1136:\tlearn: 3.8445708\ttest: 5.7284161\tbest: 5.7284161 (1136)\ttotal: 2.83s\tremaining: 8m 15s\n",
      "1137:\tlearn: 3.8427167\ttest: 5.7285460\tbest: 5.7284161 (1136)\ttotal: 2.83s\tremaining: 8m 15s\n",
      "1138:\tlearn: 3.8413276\ttest: 5.7282176\tbest: 5.7282176 (1138)\ttotal: 2.83s\tremaining: 8m 15s\n",
      "1139:\tlearn: 3.8398468\ttest: 5.7279088\tbest: 5.7279088 (1139)\ttotal: 2.84s\tremaining: 8m 15s\n",
      "1140:\tlearn: 3.8389011\ttest: 5.7275168\tbest: 5.7275168 (1140)\ttotal: 2.84s\tremaining: 8m 15s\n",
      "1141:\tlearn: 3.8377057\ttest: 5.7273438\tbest: 5.7273438 (1141)\ttotal: 2.84s\tremaining: 8m 14s\n",
      "1142:\tlearn: 3.8375514\ttest: 5.7272929\tbest: 5.7272929 (1142)\ttotal: 2.84s\tremaining: 8m 14s\n",
      "1143:\tlearn: 3.8373620\ttest: 5.7273617\tbest: 5.7272929 (1142)\ttotal: 2.85s\tremaining: 8m 14s\n",
      "1144:\tlearn: 3.8366135\ttest: 5.7271961\tbest: 5.7271961 (1144)\ttotal: 2.85s\tremaining: 8m 14s\n",
      "1145:\tlearn: 3.8357298\ttest: 5.7269147\tbest: 5.7269147 (1145)\ttotal: 2.85s\tremaining: 8m 14s\n",
      "1146:\tlearn: 3.8344810\ttest: 5.7258176\tbest: 5.7258176 (1146)\ttotal: 2.85s\tremaining: 8m 14s\n",
      "1147:\tlearn: 3.8343362\ttest: 5.7259408\tbest: 5.7258176 (1146)\ttotal: 2.85s\tremaining: 8m 14s\n",
      "1148:\tlearn: 3.8333321\ttest: 5.7248059\tbest: 5.7248059 (1148)\ttotal: 2.86s\tremaining: 8m 14s\n",
      "1149:\tlearn: 3.8328004\ttest: 5.7248446\tbest: 5.7248059 (1148)\ttotal: 2.86s\tremaining: 8m 14s\n",
      "1150:\tlearn: 3.8313962\ttest: 5.7226917\tbest: 5.7226917 (1150)\ttotal: 2.86s\tremaining: 8m 14s\n",
      "1151:\tlearn: 3.8310598\ttest: 5.7223521\tbest: 5.7223521 (1151)\ttotal: 2.86s\tremaining: 8m 14s\n",
      "1152:\tlearn: 3.8303402\ttest: 5.7225236\tbest: 5.7223521 (1151)\ttotal: 2.87s\tremaining: 8m 14s\n",
      "1153:\tlearn: 3.8293508\ttest: 5.7250408\tbest: 5.7223521 (1151)\ttotal: 2.87s\tremaining: 8m 14s\n",
      "1154:\tlearn: 3.8271859\ttest: 5.7230462\tbest: 5.7223521 (1151)\ttotal: 2.87s\tremaining: 8m 14s\n",
      "1155:\tlearn: 3.8266949\ttest: 5.7215740\tbest: 5.7215740 (1155)\ttotal: 2.87s\tremaining: 8m 14s\n",
      "1156:\tlearn: 3.8249290\ttest: 5.7211096\tbest: 5.7211096 (1156)\ttotal: 2.88s\tremaining: 8m 14s\n",
      "1157:\tlearn: 3.8240778\ttest: 5.7205174\tbest: 5.7205174 (1157)\ttotal: 2.88s\tremaining: 8m 14s\n",
      "1158:\tlearn: 3.8238327\ttest: 5.7199985\tbest: 5.7199985 (1158)\ttotal: 2.88s\tremaining: 8m 14s\n",
      "1159:\tlearn: 3.8227194\ttest: 5.7230954\tbest: 5.7199985 (1158)\ttotal: 2.88s\tremaining: 8m 14s\n",
      "1160:\tlearn: 3.8206751\ttest: 5.7233473\tbest: 5.7199985 (1158)\ttotal: 2.89s\tremaining: 8m 14s\n",
      "1161:\tlearn: 3.8199930\ttest: 5.7226862\tbest: 5.7199985 (1158)\ttotal: 2.89s\tremaining: 8m 14s\n",
      "1162:\tlearn: 3.8181705\ttest: 5.7230179\tbest: 5.7199985 (1158)\ttotal: 2.89s\tremaining: 8m 14s\n",
      "1163:\tlearn: 3.8130864\ttest: 5.7197718\tbest: 5.7197718 (1163)\ttotal: 2.9s\tremaining: 8m 14s\n",
      "1164:\tlearn: 3.8116275\ttest: 5.7179483\tbest: 5.7179483 (1164)\ttotal: 2.9s\tremaining: 8m 14s\n",
      "1165:\tlearn: 3.8110753\ttest: 5.7177090\tbest: 5.7177090 (1165)\ttotal: 2.9s\tremaining: 8m 14s\n",
      "1166:\tlearn: 3.8105209\ttest: 5.7176442\tbest: 5.7176442 (1166)\ttotal: 2.9s\tremaining: 8m 14s\n",
      "1167:\tlearn: 3.8089262\ttest: 5.7169913\tbest: 5.7169913 (1167)\ttotal: 2.91s\tremaining: 8m 14s\n",
      "1168:\tlearn: 3.8083975\ttest: 5.7165816\tbest: 5.7165816 (1168)\ttotal: 2.91s\tremaining: 8m 14s\n",
      "1169:\tlearn: 3.8068220\ttest: 5.7166866\tbest: 5.7165816 (1168)\ttotal: 2.91s\tremaining: 8m 14s\n",
      "1170:\tlearn: 3.8045117\ttest: 5.7144334\tbest: 5.7144334 (1170)\ttotal: 2.91s\tremaining: 8m 14s\n",
      "1171:\tlearn: 3.8034960\ttest: 5.7134239\tbest: 5.7134239 (1171)\ttotal: 2.92s\tremaining: 8m 14s\n",
      "1172:\tlearn: 3.8032536\ttest: 5.7133914\tbest: 5.7133914 (1172)\ttotal: 2.92s\tremaining: 8m 15s\n",
      "1173:\tlearn: 3.8025692\ttest: 5.7125918\tbest: 5.7125918 (1173)\ttotal: 2.92s\tremaining: 8m 15s\n",
      "1174:\tlearn: 3.8010124\ttest: 5.7110842\tbest: 5.7110842 (1174)\ttotal: 2.92s\tremaining: 8m 15s\n",
      "1175:\tlearn: 3.7995063\ttest: 5.7095301\tbest: 5.7095301 (1175)\ttotal: 2.93s\tremaining: 8m 14s\n",
      "1176:\tlearn: 3.7987101\ttest: 5.7090021\tbest: 5.7090021 (1176)\ttotal: 2.93s\tremaining: 8m 14s\n",
      "1177:\tlearn: 3.7981965\ttest: 5.7085371\tbest: 5.7085371 (1177)\ttotal: 2.93s\tremaining: 8m 14s\n",
      "1178:\tlearn: 3.7972651\ttest: 5.7079984\tbest: 5.7079984 (1178)\ttotal: 2.93s\tremaining: 8m 14s\n",
      "1179:\tlearn: 3.7967360\ttest: 5.7079930\tbest: 5.7079930 (1179)\ttotal: 2.94s\tremaining: 8m 14s\n",
      "1180:\tlearn: 3.7955740\ttest: 5.7082732\tbest: 5.7079930 (1179)\ttotal: 2.94s\tremaining: 8m 14s\n",
      "1181:\tlearn: 3.7946926\ttest: 5.7075040\tbest: 5.7075040 (1181)\ttotal: 2.94s\tremaining: 8m 14s\n",
      "1182:\tlearn: 3.7944147\ttest: 5.7073968\tbest: 5.7073968 (1182)\ttotal: 2.94s\tremaining: 8m 14s\n",
      "1183:\tlearn: 3.7941104\ttest: 5.7073283\tbest: 5.7073283 (1183)\ttotal: 2.94s\tremaining: 8m 14s\n",
      "1184:\tlearn: 3.7919369\ttest: 5.7077749\tbest: 5.7073283 (1183)\ttotal: 2.95s\tremaining: 8m 14s\n",
      "1185:\tlearn: 3.7915034\ttest: 5.7072031\tbest: 5.7072031 (1185)\ttotal: 2.95s\tremaining: 8m 14s\n",
      "1186:\tlearn: 3.7879967\ttest: 5.7075133\tbest: 5.7072031 (1185)\ttotal: 2.95s\tremaining: 8m 14s\n",
      "1187:\tlearn: 3.7868630\ttest: 5.7067402\tbest: 5.7067402 (1187)\ttotal: 2.95s\tremaining: 8m 14s\n",
      "1188:\tlearn: 3.7859081\ttest: 5.7061754\tbest: 5.7061754 (1188)\ttotal: 2.96s\tremaining: 8m 14s\n",
      "1189:\tlearn: 3.7855912\ttest: 5.7058566\tbest: 5.7058566 (1189)\ttotal: 2.96s\tremaining: 8m 14s\n",
      "1190:\tlearn: 3.7852003\ttest: 5.7055457\tbest: 5.7055457 (1190)\ttotal: 2.96s\tremaining: 8m 14s\n",
      "1191:\tlearn: 3.7842564\ttest: 5.7048457\tbest: 5.7048457 (1191)\ttotal: 2.96s\tremaining: 8m 14s\n",
      "1192:\tlearn: 3.7824056\ttest: 5.7031737\tbest: 5.7031737 (1192)\ttotal: 2.96s\tremaining: 8m 14s\n",
      "1193:\tlearn: 3.7817665\ttest: 5.7028352\tbest: 5.7028352 (1193)\ttotal: 2.97s\tremaining: 8m 14s\n",
      "1194:\tlearn: 3.7810790\ttest: 5.7020664\tbest: 5.7020664 (1194)\ttotal: 2.97s\tremaining: 8m 14s\n",
      "1195:\tlearn: 3.7785723\ttest: 5.7010667\tbest: 5.7010667 (1195)\ttotal: 2.97s\tremaining: 8m 14s\n",
      "1196:\tlearn: 3.7782211\ttest: 5.7009621\tbest: 5.7009621 (1196)\ttotal: 2.97s\tremaining: 8m 14s\n",
      "1197:\tlearn: 3.7775610\ttest: 5.7006742\tbest: 5.7006742 (1197)\ttotal: 2.98s\tremaining: 8m 14s\n",
      "1198:\tlearn: 3.7772088\ttest: 5.7008158\tbest: 5.7006742 (1197)\ttotal: 2.98s\tremaining: 8m 14s\n",
      "1199:\tlearn: 3.7763332\ttest: 5.7005285\tbest: 5.7005285 (1199)\ttotal: 2.98s\tremaining: 8m 14s\n",
      "1200:\tlearn: 3.7759561\ttest: 5.7005017\tbest: 5.7005017 (1200)\ttotal: 2.98s\tremaining: 8m 13s\n",
      "1201:\tlearn: 3.7747542\ttest: 5.7005411\tbest: 5.7005017 (1200)\ttotal: 2.99s\tremaining: 8m 14s\n",
      "1202:\tlearn: 3.7722559\ttest: 5.6984228\tbest: 5.6984228 (1202)\ttotal: 2.99s\tremaining: 8m 13s\n",
      "1203:\tlearn: 3.7716016\ttest: 5.6969115\tbest: 5.6969115 (1203)\ttotal: 2.99s\tremaining: 8m 13s\n",
      "1204:\tlearn: 3.7709423\ttest: 5.6968737\tbest: 5.6968737 (1204)\ttotal: 2.99s\tremaining: 8m 13s\n",
      "1205:\tlearn: 3.7702641\ttest: 5.6967324\tbest: 5.6967324 (1205)\ttotal: 3s\tremaining: 8m 13s\n",
      "1206:\tlearn: 3.7697137\ttest: 5.6967111\tbest: 5.6967111 (1206)\ttotal: 3s\tremaining: 8m 13s\n",
      "1207:\tlearn: 3.7693107\ttest: 5.6961098\tbest: 5.6961098 (1207)\ttotal: 3s\tremaining: 8m 13s\n",
      "1208:\tlearn: 3.7691889\ttest: 5.6959068\tbest: 5.6959068 (1208)\ttotal: 3s\tremaining: 8m 13s\n",
      "1209:\tlearn: 3.7685518\ttest: 5.6954361\tbest: 5.6954361 (1209)\ttotal: 3s\tremaining: 8m 13s\n",
      "1210:\tlearn: 3.7667017\ttest: 5.6948607\tbest: 5.6948607 (1210)\ttotal: 3.01s\tremaining: 8m 13s\n",
      "1211:\tlearn: 3.7651247\ttest: 5.6936452\tbest: 5.6936452 (1211)\ttotal: 3.01s\tremaining: 8m 13s\n",
      "1212:\tlearn: 3.7645472\ttest: 5.6935160\tbest: 5.6935160 (1212)\ttotal: 3.01s\tremaining: 8m 13s\n",
      "1213:\tlearn: 3.7642376\ttest: 5.6934447\tbest: 5.6934447 (1213)\ttotal: 3.02s\tremaining: 8m 13s\n",
      "1214:\tlearn: 3.7633188\ttest: 5.6932108\tbest: 5.6932108 (1214)\ttotal: 3.02s\tremaining: 8m 13s\n",
      "1215:\tlearn: 3.7630630\ttest: 5.6932845\tbest: 5.6932108 (1214)\ttotal: 3.02s\tremaining: 8m 13s\n",
      "1216:\tlearn: 3.7617694\ttest: 5.6934672\tbest: 5.6932108 (1214)\ttotal: 3.02s\tremaining: 8m 13s\n",
      "1217:\tlearn: 3.7612100\ttest: 5.6932959\tbest: 5.6932108 (1214)\ttotal: 3.02s\tremaining: 8m 13s\n",
      "1218:\tlearn: 3.7609828\ttest: 5.6931888\tbest: 5.6931888 (1218)\ttotal: 3.02s\tremaining: 8m 13s\n",
      "1219:\tlearn: 3.7604079\ttest: 5.6933710\tbest: 5.6931888 (1218)\ttotal: 3.03s\tremaining: 8m 13s\n",
      "1220:\tlearn: 3.7596521\ttest: 5.6922382\tbest: 5.6922382 (1220)\ttotal: 3.03s\tremaining: 8m 13s\n",
      "1221:\tlearn: 3.7588041\ttest: 5.6912463\tbest: 5.6912463 (1221)\ttotal: 3.03s\tremaining: 8m 13s\n",
      "1222:\tlearn: 3.7582129\ttest: 5.6918220\tbest: 5.6912463 (1221)\ttotal: 3.03s\tremaining: 8m 13s\n",
      "1223:\tlearn: 3.7565301\ttest: 5.6910471\tbest: 5.6910471 (1223)\ttotal: 3.04s\tremaining: 8m 13s\n",
      "1224:\tlearn: 3.7560315\ttest: 5.6909828\tbest: 5.6909828 (1224)\ttotal: 3.04s\tremaining: 8m 13s\n",
      "1225:\tlearn: 3.7546497\ttest: 5.6904398\tbest: 5.6904398 (1225)\ttotal: 3.04s\tremaining: 8m 13s\n",
      "1226:\tlearn: 3.7540720\ttest: 5.6906337\tbest: 5.6904398 (1225)\ttotal: 3.05s\tremaining: 8m 13s\n",
      "1227:\tlearn: 3.7525267\ttest: 5.6902567\tbest: 5.6902567 (1227)\ttotal: 3.05s\tremaining: 8m 13s\n",
      "1228:\tlearn: 3.7517113\ttest: 5.6900973\tbest: 5.6900973 (1228)\ttotal: 3.05s\tremaining: 8m 13s\n",
      "1229:\tlearn: 3.7515388\ttest: 5.6899611\tbest: 5.6899611 (1229)\ttotal: 3.05s\tremaining: 8m 13s\n",
      "1230:\tlearn: 3.7507193\ttest: 5.6897214\tbest: 5.6897214 (1230)\ttotal: 3.05s\tremaining: 8m 13s\n",
      "1231:\tlearn: 3.7497992\ttest: 5.6890689\tbest: 5.6890689 (1231)\ttotal: 3.06s\tremaining: 8m 13s\n",
      "1232:\tlearn: 3.7492057\ttest: 5.6888448\tbest: 5.6888448 (1232)\ttotal: 3.06s\tremaining: 8m 13s\n",
      "1233:\tlearn: 3.7485475\ttest: 5.6884769\tbest: 5.6884769 (1233)\ttotal: 3.06s\tremaining: 8m 13s\n",
      "1234:\tlearn: 3.7479784\ttest: 5.6882200\tbest: 5.6882200 (1234)\ttotal: 3.06s\tremaining: 8m 13s\n",
      "1235:\tlearn: 3.7472064\ttest: 5.6880932\tbest: 5.6880932 (1235)\ttotal: 3.06s\tremaining: 8m 12s\n",
      "1236:\tlearn: 3.7459041\ttest: 5.6864326\tbest: 5.6864326 (1236)\ttotal: 3.07s\tremaining: 8m 12s\n",
      "1237:\tlearn: 3.7451768\ttest: 5.6867159\tbest: 5.6864326 (1236)\ttotal: 3.07s\tremaining: 8m 12s\n",
      "1238:\tlearn: 3.7441813\ttest: 5.6865094\tbest: 5.6864326 (1236)\ttotal: 3.07s\tremaining: 8m 12s\n",
      "1239:\tlearn: 3.7431256\ttest: 5.6859369\tbest: 5.6859369 (1239)\ttotal: 3.07s\tremaining: 8m 12s\n",
      "1240:\tlearn: 3.7427292\ttest: 5.6854990\tbest: 5.6854990 (1240)\ttotal: 3.08s\tremaining: 8m 12s\n",
      "1241:\tlearn: 3.7425047\ttest: 5.6854191\tbest: 5.6854191 (1241)\ttotal: 3.08s\tremaining: 8m 12s\n",
      "1242:\tlearn: 3.7416876\ttest: 5.6850570\tbest: 5.6850570 (1242)\ttotal: 3.08s\tremaining: 8m 12s\n",
      "1243:\tlearn: 3.7400985\ttest: 5.6837601\tbest: 5.6837601 (1243)\ttotal: 3.08s\tremaining: 8m 12s\n",
      "1244:\tlearn: 3.7385968\ttest: 5.6821226\tbest: 5.6821226 (1244)\ttotal: 3.09s\tremaining: 8m 12s\n",
      "1245:\tlearn: 3.7380391\ttest: 5.6821610\tbest: 5.6821226 (1244)\ttotal: 3.09s\tremaining: 8m 12s\n",
      "1246:\tlearn: 3.7372294\ttest: 5.6818514\tbest: 5.6818514 (1246)\ttotal: 3.09s\tremaining: 8m 12s\n",
      "1247:\tlearn: 3.7365621\ttest: 5.6815048\tbest: 5.6815048 (1247)\ttotal: 3.1s\tremaining: 8m 12s\n",
      "1248:\tlearn: 3.7354731\ttest: 5.6814570\tbest: 5.6814570 (1248)\ttotal: 3.1s\tremaining: 8m 13s\n",
      "1249:\tlearn: 3.7351136\ttest: 5.6812778\tbest: 5.6812778 (1249)\ttotal: 3.1s\tremaining: 8m 13s\n",
      "1250:\tlearn: 3.7346668\ttest: 5.6813202\tbest: 5.6812778 (1249)\ttotal: 3.1s\tremaining: 8m 13s\n",
      "1251:\tlearn: 3.7343068\ttest: 5.6811200\tbest: 5.6811200 (1251)\ttotal: 3.11s\tremaining: 8m 13s\n",
      "1252:\tlearn: 3.7337039\ttest: 5.6811102\tbest: 5.6811102 (1252)\ttotal: 3.11s\tremaining: 8m 13s\n",
      "1253:\tlearn: 3.7336593\ttest: 5.6811454\tbest: 5.6811102 (1252)\ttotal: 3.11s\tremaining: 8m 13s\n",
      "1254:\tlearn: 3.7334988\ttest: 5.6812205\tbest: 5.6811102 (1252)\ttotal: 3.11s\tremaining: 8m 12s\n",
      "1255:\tlearn: 3.7330375\ttest: 5.6814244\tbest: 5.6811102 (1252)\ttotal: 3.12s\tremaining: 8m 12s\n",
      "1256:\tlearn: 3.7323564\ttest: 5.6816756\tbest: 5.6811102 (1252)\ttotal: 3.12s\tremaining: 8m 12s\n",
      "1257:\tlearn: 3.7299434\ttest: 5.6802575\tbest: 5.6802575 (1257)\ttotal: 3.12s\tremaining: 8m 12s\n",
      "1258:\tlearn: 3.7295826\ttest: 5.6799745\tbest: 5.6799745 (1258)\ttotal: 3.12s\tremaining: 8m 13s\n",
      "1259:\tlearn: 3.7287429\ttest: 5.6800636\tbest: 5.6799745 (1258)\ttotal: 3.13s\tremaining: 8m 12s\n",
      "1260:\tlearn: 3.7284793\ttest: 5.6796094\tbest: 5.6796094 (1260)\ttotal: 3.13s\tremaining: 8m 12s\n",
      "1261:\tlearn: 3.7279706\ttest: 5.6790383\tbest: 5.6790383 (1261)\ttotal: 3.13s\tremaining: 8m 12s\n",
      "1262:\tlearn: 3.7270498\ttest: 5.6778995\tbest: 5.6778995 (1262)\ttotal: 3.13s\tremaining: 8m 12s\n",
      "1263:\tlearn: 3.7260582\ttest: 5.6773779\tbest: 5.6773779 (1263)\ttotal: 3.13s\tremaining: 8m 12s\n",
      "1264:\tlearn: 3.7251458\ttest: 5.6764938\tbest: 5.6764938 (1264)\ttotal: 3.14s\tremaining: 8m 12s\n",
      "1265:\tlearn: 3.7250861\ttest: 5.6764578\tbest: 5.6764578 (1265)\ttotal: 3.14s\tremaining: 8m 12s\n",
      "1266:\tlearn: 3.7242083\ttest: 5.6760555\tbest: 5.6760555 (1266)\ttotal: 3.14s\tremaining: 8m 12s\n",
      "1267:\tlearn: 3.7233608\ttest: 5.6753060\tbest: 5.6753060 (1267)\ttotal: 3.14s\tremaining: 8m 12s\n",
      "1268:\tlearn: 3.7231046\ttest: 5.6750542\tbest: 5.6750542 (1268)\ttotal: 3.15s\tremaining: 8m 12s\n",
      "1269:\tlearn: 3.7214484\ttest: 5.6748451\tbest: 5.6748451 (1269)\ttotal: 3.15s\tremaining: 8m 12s\n",
      "1270:\tlearn: 3.7212852\ttest: 5.6747973\tbest: 5.6747973 (1270)\ttotal: 3.15s\tremaining: 8m 12s\n",
      "1271:\tlearn: 3.7211480\ttest: 5.6748348\tbest: 5.6747973 (1270)\ttotal: 3.15s\tremaining: 8m 12s\n",
      "1272:\tlearn: 3.7209399\ttest: 5.6748582\tbest: 5.6747973 (1270)\ttotal: 3.15s\tremaining: 8m 12s\n",
      "1273:\tlearn: 3.7204149\ttest: 5.6746854\tbest: 5.6746854 (1273)\ttotal: 3.16s\tremaining: 8m 12s\n",
      "1274:\tlearn: 3.7197338\ttest: 5.6746754\tbest: 5.6746754 (1274)\ttotal: 3.16s\tremaining: 8m 12s\n",
      "1275:\tlearn: 3.7189875\ttest: 5.6749862\tbest: 5.6746754 (1274)\ttotal: 3.16s\tremaining: 8m 12s\n",
      "1276:\tlearn: 3.7185579\ttest: 5.6752592\tbest: 5.6746754 (1274)\ttotal: 3.16s\tremaining: 8m 12s\n",
      "1277:\tlearn: 3.7184377\ttest: 5.6752856\tbest: 5.6746754 (1274)\ttotal: 3.17s\tremaining: 8m 12s\n",
      "1278:\tlearn: 3.7179727\ttest: 5.6748438\tbest: 5.6746754 (1274)\ttotal: 3.17s\tremaining: 8m 12s\n",
      "1279:\tlearn: 3.7175397\ttest: 5.6746301\tbest: 5.6746301 (1279)\ttotal: 3.17s\tremaining: 8m 12s\n",
      "1280:\tlearn: 3.7165814\ttest: 5.6745772\tbest: 5.6745772 (1280)\ttotal: 3.17s\tremaining: 8m 12s\n",
      "1281:\tlearn: 3.7158232\ttest: 5.6739071\tbest: 5.6739071 (1281)\ttotal: 3.17s\tremaining: 8m 12s\n",
      "1282:\tlearn: 3.7150456\ttest: 5.6737913\tbest: 5.6737913 (1282)\ttotal: 3.18s\tremaining: 8m 12s\n",
      "1283:\tlearn: 3.7147220\ttest: 5.6737677\tbest: 5.6737677 (1283)\ttotal: 3.18s\tremaining: 8m 12s\n",
      "1284:\tlearn: 3.7143376\ttest: 5.6738004\tbest: 5.6737677 (1283)\ttotal: 3.18s\tremaining: 8m 12s\n",
      "1285:\tlearn: 3.7142379\ttest: 5.6737091\tbest: 5.6737091 (1285)\ttotal: 3.18s\tremaining: 8m 11s\n",
      "1286:\tlearn: 3.7139236\ttest: 5.6736666\tbest: 5.6736666 (1286)\ttotal: 3.19s\tremaining: 8m 11s\n",
      "1287:\tlearn: 3.7134685\ttest: 5.6736778\tbest: 5.6736666 (1286)\ttotal: 3.19s\tremaining: 8m 11s\n",
      "1288:\tlearn: 3.7131256\ttest: 5.6736469\tbest: 5.6736469 (1288)\ttotal: 3.19s\tremaining: 8m 11s\n",
      "1289:\tlearn: 3.7128555\ttest: 5.6735699\tbest: 5.6735699 (1289)\ttotal: 3.19s\tremaining: 8m 11s\n",
      "1290:\tlearn: 3.7120494\ttest: 5.6727384\tbest: 5.6727384 (1290)\ttotal: 3.2s\tremaining: 8m 12s\n",
      "1291:\tlearn: 3.7116612\ttest: 5.6728247\tbest: 5.6727384 (1290)\ttotal: 3.2s\tremaining: 8m 12s\n",
      "1292:\tlearn: 3.7102734\ttest: 5.6720471\tbest: 5.6720471 (1292)\ttotal: 3.2s\tremaining: 8m 12s\n",
      "1293:\tlearn: 3.7098486\ttest: 5.6717197\tbest: 5.6717197 (1293)\ttotal: 3.2s\tremaining: 8m 12s\n",
      "1294:\tlearn: 3.7091663\ttest: 5.6711236\tbest: 5.6711236 (1294)\ttotal: 3.21s\tremaining: 8m 12s\n",
      "1295:\tlearn: 3.7077411\ttest: 5.6707221\tbest: 5.6707221 (1295)\ttotal: 3.21s\tremaining: 8m 12s\n",
      "1296:\tlearn: 3.7073452\ttest: 5.6706782\tbest: 5.6706782 (1296)\ttotal: 3.21s\tremaining: 8m 12s\n",
      "1297:\tlearn: 3.7071053\ttest: 5.6706127\tbest: 5.6706127 (1297)\ttotal: 3.21s\tremaining: 8m 12s\n",
      "1298:\tlearn: 3.7055139\ttest: 5.6695661\tbest: 5.6695661 (1298)\ttotal: 3.22s\tremaining: 8m 12s\n",
      "1299:\tlearn: 3.7050422\ttest: 5.6697121\tbest: 5.6695661 (1298)\ttotal: 3.22s\tremaining: 8m 12s\n",
      "1300:\tlearn: 3.7045031\ttest: 5.6694258\tbest: 5.6694258 (1300)\ttotal: 3.22s\tremaining: 8m 12s\n",
      "1301:\tlearn: 3.7038866\ttest: 5.6679858\tbest: 5.6679858 (1301)\ttotal: 3.22s\tremaining: 8m 12s\n",
      "1302:\tlearn: 3.7034562\ttest: 5.6679193\tbest: 5.6679193 (1302)\ttotal: 3.23s\tremaining: 8m 12s\n",
      "1303:\tlearn: 3.7028096\ttest: 5.6678443\tbest: 5.6678443 (1303)\ttotal: 3.23s\tremaining: 8m 12s\n",
      "1304:\tlearn: 3.7024139\ttest: 5.6675815\tbest: 5.6675815 (1304)\ttotal: 3.23s\tremaining: 8m 11s\n",
      "1305:\tlearn: 3.7014897\ttest: 5.6660742\tbest: 5.6660742 (1305)\ttotal: 3.23s\tremaining: 8m 12s\n",
      "1306:\tlearn: 3.7013366\ttest: 5.6657749\tbest: 5.6657749 (1306)\ttotal: 3.24s\tremaining: 8m 12s\n",
      "1307:\tlearn: 3.7010279\ttest: 5.6659418\tbest: 5.6657749 (1306)\ttotal: 3.24s\tremaining: 8m 11s\n",
      "1308:\tlearn: 3.7003001\ttest: 5.6658794\tbest: 5.6657749 (1306)\ttotal: 3.24s\tremaining: 8m 11s\n",
      "1309:\tlearn: 3.7001005\ttest: 5.6655511\tbest: 5.6655511 (1309)\ttotal: 3.24s\tremaining: 8m 11s\n",
      "1310:\tlearn: 3.6999322\ttest: 5.6655932\tbest: 5.6655511 (1309)\ttotal: 3.25s\tremaining: 8m 11s\n",
      "1311:\tlearn: 3.6990850\ttest: 5.6651221\tbest: 5.6651221 (1311)\ttotal: 3.25s\tremaining: 8m 11s\n",
      "1312:\tlearn: 3.6987181\ttest: 5.6648664\tbest: 5.6648664 (1312)\ttotal: 3.25s\tremaining: 8m 11s\n",
      "1313:\tlearn: 3.6981477\ttest: 5.6638093\tbest: 5.6638093 (1313)\ttotal: 3.25s\tremaining: 8m 11s\n",
      "1314:\tlearn: 3.6979364\ttest: 5.6633373\tbest: 5.6633373 (1314)\ttotal: 3.26s\tremaining: 8m 11s\n",
      "1315:\tlearn: 3.6973550\ttest: 5.6620579\tbest: 5.6620579 (1315)\ttotal: 3.26s\tremaining: 8m 12s\n",
      "1316:\tlearn: 3.6971313\ttest: 5.6618775\tbest: 5.6618775 (1316)\ttotal: 3.26s\tremaining: 8m 12s\n",
      "1317:\tlearn: 3.6969814\ttest: 5.6617331\tbest: 5.6617331 (1317)\ttotal: 3.26s\tremaining: 8m 12s\n",
      "1318:\tlearn: 3.6968451\ttest: 5.6617928\tbest: 5.6617331 (1317)\ttotal: 3.27s\tremaining: 8m 12s\n",
      "1319:\tlearn: 3.6963600\ttest: 5.6618406\tbest: 5.6617331 (1317)\ttotal: 3.27s\tremaining: 8m 12s\n",
      "1320:\tlearn: 3.6956027\ttest: 5.6619569\tbest: 5.6617331 (1317)\ttotal: 3.27s\tremaining: 8m 11s\n",
      "1321:\tlearn: 3.6951298\ttest: 5.6620728\tbest: 5.6617331 (1317)\ttotal: 3.27s\tremaining: 8m 11s\n",
      "1322:\tlearn: 3.6950078\ttest: 5.6622394\tbest: 5.6617331 (1317)\ttotal: 3.27s\tremaining: 8m 11s\n",
      "1323:\tlearn: 3.6948141\ttest: 5.6621107\tbest: 5.6617331 (1317)\ttotal: 3.28s\tremaining: 8m 11s\n",
      "1324:\tlearn: 3.6923318\ttest: 5.6674401\tbest: 5.6617331 (1317)\ttotal: 3.28s\tremaining: 8m 11s\n",
      "1325:\tlearn: 3.6919194\ttest: 5.6668003\tbest: 5.6617331 (1317)\ttotal: 3.28s\tremaining: 8m 12s\n",
      "1326:\tlearn: 3.6907923\ttest: 5.6660258\tbest: 5.6617331 (1317)\ttotal: 3.29s\tremaining: 8m 12s\n",
      "1327:\tlearn: 3.6893479\ttest: 5.6643127\tbest: 5.6617331 (1317)\ttotal: 3.29s\tremaining: 8m 11s\n",
      "1328:\tlearn: 3.6889471\ttest: 5.6644255\tbest: 5.6617331 (1317)\ttotal: 3.29s\tremaining: 8m 11s\n",
      "1329:\tlearn: 3.6867285\ttest: 5.6662198\tbest: 5.6617331 (1317)\ttotal: 3.29s\tremaining: 8m 11s\n",
      "1330:\tlearn: 3.6846885\ttest: 5.6667099\tbest: 5.6617331 (1317)\ttotal: 3.29s\tremaining: 8m 11s\n",
      "1331:\tlearn: 3.6841633\ttest: 5.6662375\tbest: 5.6617331 (1317)\ttotal: 3.3s\tremaining: 8m 11s\n",
      "1332:\tlearn: 3.6833625\ttest: 5.6660181\tbest: 5.6617331 (1317)\ttotal: 3.3s\tremaining: 8m 11s\n",
      "1333:\tlearn: 3.6823387\ttest: 5.6653615\tbest: 5.6617331 (1317)\ttotal: 3.3s\tremaining: 8m 11s\n",
      "1334:\tlearn: 3.6805393\ttest: 5.6650532\tbest: 5.6617331 (1317)\ttotal: 3.3s\tremaining: 8m 11s\n",
      "1335:\tlearn: 3.6791820\ttest: 5.6648742\tbest: 5.6617331 (1317)\ttotal: 3.31s\tremaining: 8m 11s\n",
      "1336:\tlearn: 3.6779077\ttest: 5.6640461\tbest: 5.6617331 (1317)\ttotal: 3.31s\tremaining: 8m 11s\n",
      "1337:\tlearn: 3.6774395\ttest: 5.6635439\tbest: 5.6617331 (1317)\ttotal: 3.31s\tremaining: 8m 11s\n",
      "1338:\tlearn: 3.6764263\ttest: 5.6638308\tbest: 5.6617331 (1317)\ttotal: 3.31s\tremaining: 8m 11s\n",
      "1339:\tlearn: 3.6760807\ttest: 5.6630476\tbest: 5.6617331 (1317)\ttotal: 3.32s\tremaining: 8m 11s\n",
      "1340:\tlearn: 3.6758344\ttest: 5.6626464\tbest: 5.6617331 (1317)\ttotal: 3.32s\tremaining: 8m 11s\n",
      "1341:\tlearn: 3.6755429\ttest: 5.6628562\tbest: 5.6617331 (1317)\ttotal: 3.32s\tremaining: 8m 11s\n",
      "1342:\tlearn: 3.6744854\ttest: 5.6636291\tbest: 5.6617331 (1317)\ttotal: 3.32s\tremaining: 8m 11s\n",
      "1343:\tlearn: 3.6742879\ttest: 5.6636786\tbest: 5.6617331 (1317)\ttotal: 3.33s\tremaining: 8m 11s\n",
      "1344:\tlearn: 3.6731261\ttest: 5.6627727\tbest: 5.6617331 (1317)\ttotal: 3.33s\tremaining: 8m 11s\n",
      "1345:\tlearn: 3.6726053\ttest: 5.6633189\tbest: 5.6617331 (1317)\ttotal: 3.33s\tremaining: 8m 11s\n",
      "1346:\tlearn: 3.6718962\ttest: 5.6667725\tbest: 5.6617331 (1317)\ttotal: 3.33s\tremaining: 8m 11s\n",
      "1347:\tlearn: 3.6715092\ttest: 5.6664018\tbest: 5.6617331 (1317)\ttotal: 3.33s\tremaining: 8m 11s\n",
      "1348:\tlearn: 3.6692840\ttest: 5.6658302\tbest: 5.6617331 (1317)\ttotal: 3.34s\tremaining: 8m 11s\n",
      "1349:\tlearn: 3.6685873\ttest: 5.6653705\tbest: 5.6617331 (1317)\ttotal: 3.34s\tremaining: 8m 11s\n",
      "1350:\tlearn: 3.6676116\ttest: 5.6657355\tbest: 5.6617331 (1317)\ttotal: 3.34s\tremaining: 8m 11s\n",
      "1351:\tlearn: 3.6672999\ttest: 5.6655586\tbest: 5.6617331 (1317)\ttotal: 3.35s\tremaining: 8m 11s\n",
      "1352:\tlearn: 3.6670323\ttest: 5.6653971\tbest: 5.6617331 (1317)\ttotal: 3.35s\tremaining: 8m 11s\n",
      "1353:\tlearn: 3.6665417\ttest: 5.6655249\tbest: 5.6617331 (1317)\ttotal: 3.35s\tremaining: 8m 11s\n",
      "1354:\tlearn: 3.6661354\ttest: 5.6656014\tbest: 5.6617331 (1317)\ttotal: 3.35s\tremaining: 8m 11s\n",
      "1355:\tlearn: 3.6632802\ttest: 5.6656096\tbest: 5.6617331 (1317)\ttotal: 3.35s\tremaining: 8m 11s\n",
      "1356:\tlearn: 3.6624305\ttest: 5.6645182\tbest: 5.6617331 (1317)\ttotal: 3.36s\tremaining: 8m 11s\n",
      "1357:\tlearn: 3.6621138\ttest: 5.6642912\tbest: 5.6617331 (1317)\ttotal: 3.36s\tremaining: 8m 11s\n",
      "1358:\tlearn: 3.6613133\ttest: 5.6641224\tbest: 5.6617331 (1317)\ttotal: 3.36s\tremaining: 8m 11s\n",
      "1359:\tlearn: 3.6605401\ttest: 5.6640319\tbest: 5.6617331 (1317)\ttotal: 3.36s\tremaining: 8m 11s\n",
      "1360:\tlearn: 3.6576124\ttest: 5.6647325\tbest: 5.6617331 (1317)\ttotal: 3.37s\tremaining: 8m 11s\n",
      "1361:\tlearn: 3.6548645\ttest: 5.6633192\tbest: 5.6617331 (1317)\ttotal: 3.37s\tremaining: 8m 11s\n",
      "1362:\tlearn: 3.6530940\ttest: 5.6637208\tbest: 5.6617331 (1317)\ttotal: 3.37s\tremaining: 8m 11s\n",
      "1363:\tlearn: 3.6521869\ttest: 5.6632577\tbest: 5.6617331 (1317)\ttotal: 3.37s\tremaining: 8m 11s\n",
      "1364:\tlearn: 3.6514399\ttest: 5.6623036\tbest: 5.6617331 (1317)\ttotal: 3.38s\tremaining: 8m 11s\n",
      "1365:\tlearn: 3.6500827\ttest: 5.6619274\tbest: 5.6617331 (1317)\ttotal: 3.38s\tremaining: 8m 11s\n",
      "1366:\tlearn: 3.6495532\ttest: 5.6616853\tbest: 5.6616853 (1366)\ttotal: 3.38s\tremaining: 8m 11s\n",
      "1367:\tlearn: 3.6476513\ttest: 5.6615954\tbest: 5.6615954 (1367)\ttotal: 3.38s\tremaining: 8m 11s\n",
      "1368:\tlearn: 3.6473497\ttest: 5.6613087\tbest: 5.6613087 (1368)\ttotal: 3.38s\tremaining: 8m 11s\n",
      "1369:\tlearn: 3.6468433\ttest: 5.6610499\tbest: 5.6610499 (1369)\ttotal: 3.39s\tremaining: 8m 11s\n",
      "1370:\tlearn: 3.6464068\ttest: 5.6612664\tbest: 5.6610499 (1369)\ttotal: 3.39s\tremaining: 8m 10s\n",
      "1371:\tlearn: 3.6455200\ttest: 5.6605618\tbest: 5.6605618 (1371)\ttotal: 3.39s\tremaining: 8m 10s\n",
      "1372:\tlearn: 3.6453444\ttest: 5.6606833\tbest: 5.6605618 (1371)\ttotal: 3.39s\tremaining: 8m 10s\n",
      "1373:\tlearn: 3.6452743\ttest: 5.6606485\tbest: 5.6605618 (1371)\ttotal: 3.4s\tremaining: 8m 10s\n",
      "1374:\tlearn: 3.6448840\ttest: 5.6608586\tbest: 5.6605618 (1371)\ttotal: 3.4s\tremaining: 8m 10s\n",
      "1375:\tlearn: 3.6441309\ttest: 5.6605519\tbest: 5.6605519 (1375)\ttotal: 3.4s\tremaining: 8m 10s\n",
      "1376:\tlearn: 3.6437903\ttest: 5.6604008\tbest: 5.6604008 (1376)\ttotal: 3.4s\tremaining: 8m 10s\n",
      "1377:\tlearn: 3.6436496\ttest: 5.6604125\tbest: 5.6604008 (1376)\ttotal: 3.4s\tremaining: 8m 10s\n",
      "1378:\tlearn: 3.6432616\ttest: 5.6602727\tbest: 5.6602727 (1378)\ttotal: 3.41s\tremaining: 8m 10s\n",
      "1379:\tlearn: 3.6431234\ttest: 5.6603465\tbest: 5.6602727 (1378)\ttotal: 3.41s\tremaining: 8m 10s\n",
      "1380:\tlearn: 3.6412478\ttest: 5.6593950\tbest: 5.6593950 (1380)\ttotal: 3.41s\tremaining: 8m 11s\n",
      "1381:\tlearn: 3.6398699\ttest: 5.6576218\tbest: 5.6576218 (1381)\ttotal: 3.42s\tremaining: 8m 11s\n",
      "1382:\tlearn: 3.6384190\ttest: 5.6577709\tbest: 5.6576218 (1381)\ttotal: 3.42s\tremaining: 8m 11s\n",
      "1383:\tlearn: 3.6370827\ttest: 5.6577118\tbest: 5.6576218 (1381)\ttotal: 3.42s\tremaining: 8m 11s\n",
      "1384:\tlearn: 3.6366889\ttest: 5.6575783\tbest: 5.6575783 (1384)\ttotal: 3.42s\tremaining: 8m 11s\n",
      "1385:\tlearn: 3.6360627\ttest: 5.6573491\tbest: 5.6573491 (1385)\ttotal: 3.43s\tremaining: 8m 11s\n",
      "1386:\tlearn: 3.6357320\ttest: 5.6574106\tbest: 5.6573491 (1385)\ttotal: 3.43s\tremaining: 8m 11s\n",
      "1387:\tlearn: 3.6349657\ttest: 5.6574207\tbest: 5.6573491 (1385)\ttotal: 3.43s\tremaining: 8m 11s\n",
      "1388:\tlearn: 3.6328814\ttest: 5.6557675\tbest: 5.6557675 (1388)\ttotal: 3.43s\tremaining: 8m 11s\n",
      "1389:\tlearn: 3.6325974\ttest: 5.6553936\tbest: 5.6553936 (1389)\ttotal: 3.44s\tremaining: 8m 11s\n",
      "1390:\tlearn: 3.6317712\ttest: 5.6539884\tbest: 5.6539884 (1390)\ttotal: 3.44s\tremaining: 8m 11s\n",
      "1391:\tlearn: 3.6313574\ttest: 5.6541233\tbest: 5.6539884 (1390)\ttotal: 3.44s\tremaining: 8m 11s\n",
      "1392:\tlearn: 3.6307491\ttest: 5.6541489\tbest: 5.6539884 (1390)\ttotal: 3.44s\tremaining: 8m 11s\n",
      "1393:\tlearn: 3.6284187\ttest: 5.6513562\tbest: 5.6513562 (1393)\ttotal: 3.45s\tremaining: 8m 11s\n",
      "1394:\tlearn: 3.6265958\ttest: 5.6500971\tbest: 5.6500971 (1394)\ttotal: 3.45s\tremaining: 8m 11s\n",
      "1395:\tlearn: 3.6238418\ttest: 5.6473301\tbest: 5.6473301 (1395)\ttotal: 3.45s\tremaining: 8m 11s\n",
      "1396:\tlearn: 3.6226840\ttest: 5.6458688\tbest: 5.6458688 (1396)\ttotal: 3.45s\tremaining: 8m 11s\n",
      "1397:\tlearn: 3.6202634\ttest: 5.6464384\tbest: 5.6458688 (1396)\ttotal: 3.46s\tremaining: 8m 11s\n",
      "1398:\tlearn: 3.6168297\ttest: 5.6477285\tbest: 5.6458688 (1396)\ttotal: 3.46s\tremaining: 8m 11s\n",
      "1399:\tlearn: 3.6160052\ttest: 5.6468271\tbest: 5.6458688 (1396)\ttotal: 3.46s\tremaining: 8m 11s\n",
      "1400:\tlearn: 3.6135817\ttest: 5.6455430\tbest: 5.6455430 (1400)\ttotal: 3.47s\tremaining: 8m 11s\n",
      "1401:\tlearn: 3.6118844\ttest: 5.6450473\tbest: 5.6450473 (1401)\ttotal: 3.47s\tremaining: 8m 11s\n",
      "1402:\tlearn: 3.6082144\ttest: 5.6416677\tbest: 5.6416677 (1402)\ttotal: 3.47s\tremaining: 8m 11s\n",
      "1403:\tlearn: 3.6072516\ttest: 5.6406483\tbest: 5.6406483 (1403)\ttotal: 3.47s\tremaining: 8m 11s\n",
      "1404:\tlearn: 3.6060107\ttest: 5.6400849\tbest: 5.6400849 (1404)\ttotal: 3.48s\tremaining: 8m 11s\n",
      "1405:\tlearn: 3.6055286\ttest: 5.6398139\tbest: 5.6398139 (1405)\ttotal: 3.48s\tremaining: 8m 11s\n",
      "1406:\tlearn: 3.6039621\ttest: 5.6384196\tbest: 5.6384196 (1406)\ttotal: 3.48s\tremaining: 8m 11s\n",
      "1407:\tlearn: 3.6036994\ttest: 5.6384764\tbest: 5.6384196 (1406)\ttotal: 3.48s\tremaining: 8m 11s\n",
      "1408:\tlearn: 3.6029060\ttest: 5.6383274\tbest: 5.6383274 (1408)\ttotal: 3.48s\tremaining: 8m 11s\n",
      "1409:\tlearn: 3.6019469\ttest: 5.6378957\tbest: 5.6378957 (1409)\ttotal: 3.49s\tremaining: 8m 11s\n",
      "1410:\tlearn: 3.6015874\ttest: 5.6375223\tbest: 5.6375223 (1410)\ttotal: 3.49s\tremaining: 8m 11s\n",
      "1411:\tlearn: 3.6013071\ttest: 5.6374140\tbest: 5.6374140 (1411)\ttotal: 3.49s\tremaining: 8m 11s\n",
      "1412:\tlearn: 3.6010292\ttest: 5.6373494\tbest: 5.6373494 (1412)\ttotal: 3.49s\tremaining: 8m 11s\n",
      "1413:\tlearn: 3.6004857\ttest: 5.6367889\tbest: 5.6367889 (1413)\ttotal: 3.5s\tremaining: 8m 11s\n",
      "1414:\tlearn: 3.5997450\ttest: 5.6355436\tbest: 5.6355436 (1414)\ttotal: 3.5s\tremaining: 8m 11s\n",
      "1415:\tlearn: 3.5994716\ttest: 5.6356038\tbest: 5.6355436 (1414)\ttotal: 3.5s\tremaining: 8m 11s\n",
      "1416:\tlearn: 3.5992501\ttest: 5.6355842\tbest: 5.6355436 (1414)\ttotal: 3.5s\tremaining: 8m 11s\n",
      "1417:\tlearn: 3.5984329\ttest: 5.6353913\tbest: 5.6353913 (1417)\ttotal: 3.51s\tremaining: 8m 11s\n",
      "1418:\tlearn: 3.5969020\ttest: 5.6352317\tbest: 5.6352317 (1418)\ttotal: 3.51s\tremaining: 8m 11s\n",
      "1419:\tlearn: 3.5957383\ttest: 5.6342926\tbest: 5.6342926 (1419)\ttotal: 3.51s\tremaining: 8m 10s\n",
      "1420:\tlearn: 3.5945976\ttest: 5.6344264\tbest: 5.6342926 (1419)\ttotal: 3.51s\tremaining: 8m 10s\n",
      "1421:\tlearn: 3.5938492\ttest: 5.6340594\tbest: 5.6340594 (1421)\ttotal: 3.52s\tremaining: 8m 10s\n",
      "1422:\tlearn: 3.5932709\ttest: 5.6334416\tbest: 5.6334416 (1422)\ttotal: 3.52s\tremaining: 8m 10s\n",
      "1423:\tlearn: 3.5927122\ttest: 5.6334324\tbest: 5.6334324 (1423)\ttotal: 3.52s\tremaining: 8m 10s\n",
      "1424:\tlearn: 3.5924555\ttest: 5.6332633\tbest: 5.6332633 (1424)\ttotal: 3.52s\tremaining: 8m 10s\n",
      "1425:\tlearn: 3.5916646\ttest: 5.6328971\tbest: 5.6328971 (1425)\ttotal: 3.52s\tremaining: 8m 10s\n",
      "1426:\tlearn: 3.5913328\ttest: 5.6328151\tbest: 5.6328151 (1426)\ttotal: 3.53s\tremaining: 8m 10s\n",
      "1427:\tlearn: 3.5910294\ttest: 5.6325528\tbest: 5.6325528 (1427)\ttotal: 3.53s\tremaining: 8m 10s\n",
      "1428:\tlearn: 3.5898838\ttest: 5.6326606\tbest: 5.6325528 (1427)\ttotal: 3.53s\tremaining: 8m 10s\n",
      "1429:\tlearn: 3.5894619\ttest: 5.6323648\tbest: 5.6323648 (1429)\ttotal: 3.53s\tremaining: 8m 10s\n",
      "1430:\tlearn: 3.5889660\ttest: 5.6325372\tbest: 5.6323648 (1429)\ttotal: 3.54s\tremaining: 8m 10s\n",
      "1431:\tlearn: 3.5880375\ttest: 5.6317489\tbest: 5.6317489 (1431)\ttotal: 3.54s\tremaining: 8m 10s\n",
      "1432:\tlearn: 3.5876299\ttest: 5.6314175\tbest: 5.6314175 (1432)\ttotal: 3.54s\tremaining: 8m 10s\n",
      "1433:\tlearn: 3.5872236\ttest: 5.6308518\tbest: 5.6308518 (1433)\ttotal: 3.54s\tremaining: 8m 10s\n",
      "1434:\tlearn: 3.5869461\ttest: 5.6310400\tbest: 5.6308518 (1433)\ttotal: 3.54s\tremaining: 8m 10s\n",
      "1435:\tlearn: 3.5865387\ttest: 5.6310478\tbest: 5.6308518 (1433)\ttotal: 3.55s\tremaining: 8m 10s\n",
      "1436:\tlearn: 3.5861845\ttest: 5.6309995\tbest: 5.6308518 (1433)\ttotal: 3.55s\tremaining: 8m 10s\n",
      "1437:\tlearn: 3.5860674\ttest: 5.6311476\tbest: 5.6308518 (1433)\ttotal: 3.55s\tremaining: 8m 10s\n",
      "1438:\tlearn: 3.5855028\ttest: 5.6305131\tbest: 5.6305131 (1438)\ttotal: 3.55s\tremaining: 8m 10s\n",
      "1439:\tlearn: 3.5853600\ttest: 5.6304825\tbest: 5.6304825 (1439)\ttotal: 3.56s\tremaining: 8m 10s\n",
      "1440:\tlearn: 3.5844637\ttest: 5.6305955\tbest: 5.6304825 (1439)\ttotal: 3.56s\tremaining: 8m 10s\n",
      "1441:\tlearn: 3.5834365\ttest: 5.6299126\tbest: 5.6299126 (1441)\ttotal: 3.56s\tremaining: 8m 10s\n",
      "1442:\tlearn: 3.5831647\ttest: 5.6295039\tbest: 5.6295039 (1442)\ttotal: 3.56s\tremaining: 8m 10s\n",
      "1443:\tlearn: 3.5818843\ttest: 5.6279885\tbest: 5.6279885 (1443)\ttotal: 3.56s\tremaining: 8m 10s\n",
      "1444:\tlearn: 3.5814871\ttest: 5.6272950\tbest: 5.6272950 (1444)\ttotal: 3.57s\tremaining: 8m 10s\n",
      "1445:\tlearn: 3.5808714\ttest: 5.6270190\tbest: 5.6270190 (1445)\ttotal: 3.57s\tremaining: 8m 10s\n",
      "1446:\tlearn: 3.5803500\ttest: 5.6262195\tbest: 5.6262195 (1446)\ttotal: 3.57s\tremaining: 8m 10s\n",
      "1447:\tlearn: 3.5797897\ttest: 5.6260834\tbest: 5.6260834 (1447)\ttotal: 3.57s\tremaining: 8m 10s\n",
      "1448:\tlearn: 3.5776141\ttest: 5.6248584\tbest: 5.6248584 (1448)\ttotal: 3.58s\tremaining: 8m 10s\n",
      "1449:\tlearn: 3.5761538\ttest: 5.6245689\tbest: 5.6245689 (1449)\ttotal: 3.58s\tremaining: 8m 10s\n",
      "1450:\tlearn: 3.5756656\ttest: 5.6243544\tbest: 5.6243544 (1450)\ttotal: 3.58s\tremaining: 8m 10s\n",
      "1451:\tlearn: 3.5748266\ttest: 5.6243450\tbest: 5.6243450 (1451)\ttotal: 3.58s\tremaining: 8m 10s\n",
      "1452:\tlearn: 3.5744651\ttest: 5.6244295\tbest: 5.6243450 (1451)\ttotal: 3.59s\tremaining: 8m 10s\n",
      "1453:\tlearn: 3.5744235\ttest: 5.6243811\tbest: 5.6243450 (1451)\ttotal: 3.59s\tremaining: 8m 10s\n",
      "1454:\tlearn: 3.5743491\ttest: 5.6244676\tbest: 5.6243450 (1451)\ttotal: 3.59s\tremaining: 8m 10s\n",
      "1455:\tlearn: 3.5740457\ttest: 5.6244241\tbest: 5.6243450 (1451)\ttotal: 3.59s\tremaining: 8m 10s\n",
      "1456:\tlearn: 3.5739536\ttest: 5.6243664\tbest: 5.6243450 (1451)\ttotal: 3.6s\tremaining: 8m 10s\n",
      "1457:\tlearn: 3.5718338\ttest: 5.6230610\tbest: 5.6230610 (1457)\ttotal: 3.6s\tremaining: 8m 10s\n",
      "1458:\tlearn: 3.5702689\ttest: 5.6231130\tbest: 5.6230610 (1457)\ttotal: 3.6s\tremaining: 8m 10s\n",
      "1459:\tlearn: 3.5688768\ttest: 5.6229830\tbest: 5.6229830 (1459)\ttotal: 3.6s\tremaining: 8m 10s\n",
      "1460:\tlearn: 3.5674256\ttest: 5.6236378\tbest: 5.6229830 (1459)\ttotal: 3.61s\tremaining: 8m 10s\n",
      "1461:\tlearn: 3.5669051\ttest: 5.6229323\tbest: 5.6229323 (1461)\ttotal: 3.61s\tremaining: 8m 10s\n",
      "1462:\tlearn: 3.5653929\ttest: 5.6242687\tbest: 5.6229323 (1461)\ttotal: 3.61s\tremaining: 8m 10s\n",
      "1463:\tlearn: 3.5652046\ttest: 5.6243123\tbest: 5.6229323 (1461)\ttotal: 3.62s\tremaining: 8m 10s\n",
      "1464:\tlearn: 3.5632903\ttest: 5.6248663\tbest: 5.6229323 (1461)\ttotal: 3.62s\tremaining: 8m 10s\n",
      "1465:\tlearn: 3.5628205\ttest: 5.6252570\tbest: 5.6229323 (1461)\ttotal: 3.62s\tremaining: 8m 10s\n",
      "1466:\tlearn: 3.5625854\ttest: 5.6255879\tbest: 5.6229323 (1461)\ttotal: 3.62s\tremaining: 8m 10s\n",
      "1467:\tlearn: 3.5620451\ttest: 5.6258695\tbest: 5.6229323 (1461)\ttotal: 3.62s\tremaining: 8m 10s\n",
      "1468:\tlearn: 3.5611058\ttest: 5.6254322\tbest: 5.6229323 (1461)\ttotal: 3.63s\tremaining: 8m 10s\n",
      "1469:\tlearn: 3.5608798\ttest: 5.6253495\tbest: 5.6229323 (1461)\ttotal: 3.63s\tremaining: 8m 10s\n",
      "1470:\tlearn: 3.5601930\ttest: 5.6240969\tbest: 5.6229323 (1461)\ttotal: 3.63s\tremaining: 8m 10s\n",
      "1471:\tlearn: 3.5595156\ttest: 5.6229061\tbest: 5.6229061 (1471)\ttotal: 3.63s\tremaining: 8m 10s\n",
      "1472:\tlearn: 3.5574608\ttest: 5.6217345\tbest: 5.6217345 (1472)\ttotal: 3.64s\tremaining: 8m 10s\n",
      "1473:\tlearn: 3.5568599\ttest: 5.6206983\tbest: 5.6206983 (1473)\ttotal: 3.64s\tremaining: 8m 10s\n",
      "1474:\tlearn: 3.5566722\ttest: 5.6205319\tbest: 5.6205319 (1474)\ttotal: 3.64s\tremaining: 8m 10s\n",
      "1475:\tlearn: 3.5557251\ttest: 5.6200590\tbest: 5.6200590 (1475)\ttotal: 3.64s\tremaining: 8m 10s\n",
      "1476:\tlearn: 3.5544481\ttest: 5.6196749\tbest: 5.6196749 (1476)\ttotal: 3.65s\tremaining: 8m 10s\n",
      "1477:\tlearn: 3.5541858\ttest: 5.6196081\tbest: 5.6196081 (1477)\ttotal: 3.65s\tremaining: 8m 10s\n",
      "1478:\tlearn: 3.5536950\ttest: 5.6193644\tbest: 5.6193644 (1478)\ttotal: 3.65s\tremaining: 8m 10s\n",
      "1479:\tlearn: 3.5534306\ttest: 5.6191882\tbest: 5.6191882 (1479)\ttotal: 3.65s\tremaining: 8m 10s\n",
      "1480:\tlearn: 3.5530709\ttest: 5.6187363\tbest: 5.6187363 (1480)\ttotal: 3.66s\tremaining: 8m 10s\n",
      "1481:\tlearn: 3.5525506\ttest: 5.6183563\tbest: 5.6183563 (1481)\ttotal: 3.66s\tremaining: 8m 10s\n",
      "1482:\tlearn: 3.5524968\ttest: 5.6183673\tbest: 5.6183563 (1481)\ttotal: 3.66s\tremaining: 8m 10s\n",
      "1483:\tlearn: 3.5520772\ttest: 5.6179166\tbest: 5.6179166 (1483)\ttotal: 3.66s\tremaining: 8m 10s\n",
      "1484:\tlearn: 3.5492423\ttest: 5.6175984\tbest: 5.6175984 (1484)\ttotal: 3.67s\tremaining: 8m 10s\n",
      "1485:\tlearn: 3.5485347\ttest: 5.6172219\tbest: 5.6172219 (1485)\ttotal: 3.67s\tremaining: 8m 10s\n",
      "1486:\tlearn: 3.5477689\ttest: 5.6162194\tbest: 5.6162194 (1486)\ttotal: 3.67s\tremaining: 8m 10s\n",
      "1487:\tlearn: 3.5473464\ttest: 5.6160818\tbest: 5.6160818 (1487)\ttotal: 3.67s\tremaining: 8m 10s\n",
      "1488:\tlearn: 3.5461672\ttest: 5.6144313\tbest: 5.6144313 (1488)\ttotal: 3.68s\tremaining: 8m 10s\n",
      "1489:\tlearn: 3.5457304\ttest: 5.6135698\tbest: 5.6135698 (1489)\ttotal: 3.68s\tremaining: 8m 10s\n",
      "1490:\tlearn: 3.5456255\ttest: 5.6134202\tbest: 5.6134202 (1490)\ttotal: 3.68s\tremaining: 8m 10s\n",
      "1491:\tlearn: 3.5437049\ttest: 5.6137345\tbest: 5.6134202 (1490)\ttotal: 3.68s\tremaining: 8m 10s\n",
      "1492:\tlearn: 3.5429756\ttest: 5.6130868\tbest: 5.6130868 (1492)\ttotal: 3.69s\tremaining: 8m 10s\n",
      "1493:\tlearn: 3.5417472\ttest: 5.6130432\tbest: 5.6130432 (1493)\ttotal: 3.69s\tremaining: 8m 10s\n",
      "1494:\tlearn: 3.5413365\ttest: 5.6127419\tbest: 5.6127419 (1494)\ttotal: 3.69s\tremaining: 8m 10s\n",
      "1495:\tlearn: 3.5407451\ttest: 5.6121443\tbest: 5.6121443 (1495)\ttotal: 3.69s\tremaining: 8m 10s\n",
      "1496:\tlearn: 3.5401174\ttest: 5.6119104\tbest: 5.6119104 (1496)\ttotal: 3.7s\tremaining: 8m 10s\n",
      "1497:\tlearn: 3.5393315\ttest: 5.6115870\tbest: 5.6115870 (1497)\ttotal: 3.7s\tremaining: 8m 10s\n",
      "1498:\tlearn: 3.5382869\ttest: 5.6108399\tbest: 5.6108399 (1498)\ttotal: 3.7s\tremaining: 8m 10s\n",
      "1499:\tlearn: 3.5369972\ttest: 5.6111289\tbest: 5.6108399 (1498)\ttotal: 3.7s\tremaining: 8m 10s\n",
      "1500:\tlearn: 3.5366258\ttest: 5.6112131\tbest: 5.6108399 (1498)\ttotal: 3.71s\tremaining: 8m 10s\n",
      "1501:\tlearn: 3.5345530\ttest: 5.6105828\tbest: 5.6105828 (1501)\ttotal: 3.71s\tremaining: 8m 10s\n",
      "1502:\tlearn: 3.5343347\ttest: 5.6104895\tbest: 5.6104895 (1502)\ttotal: 3.71s\tremaining: 8m 10s\n",
      "1503:\tlearn: 3.5328322\ttest: 5.6094875\tbest: 5.6094875 (1503)\ttotal: 3.71s\tremaining: 8m 10s\n",
      "1504:\tlearn: 3.5326728\ttest: 5.6093008\tbest: 5.6093008 (1504)\ttotal: 3.71s\tremaining: 8m 9s\n",
      "1505:\tlearn: 3.5324778\ttest: 5.6091409\tbest: 5.6091409 (1505)\ttotal: 3.72s\tremaining: 8m 9s\n",
      "1506:\tlearn: 3.5313440\ttest: 5.6079749\tbest: 5.6079749 (1506)\ttotal: 3.72s\tremaining: 8m 9s\n",
      "1507:\tlearn: 3.5301999\ttest: 5.6072822\tbest: 5.6072822 (1507)\ttotal: 3.72s\tremaining: 8m 9s\n",
      "1508:\tlearn: 3.5289549\ttest: 5.6063645\tbest: 5.6063645 (1508)\ttotal: 3.72s\tremaining: 8m 9s\n",
      "1509:\tlearn: 3.5286004\ttest: 5.6063380\tbest: 5.6063380 (1509)\ttotal: 3.73s\tremaining: 8m 9s\n",
      "1510:\tlearn: 3.5276894\ttest: 5.6057289\tbest: 5.6057289 (1510)\ttotal: 3.73s\tremaining: 8m 9s\n",
      "1511:\tlearn: 3.5272048\ttest: 5.6059968\tbest: 5.6057289 (1510)\ttotal: 3.73s\tremaining: 8m 9s\n",
      "1512:\tlearn: 3.5269517\ttest: 5.6061540\tbest: 5.6057289 (1510)\ttotal: 3.73s\tremaining: 8m 9s\n",
      "1513:\tlearn: 3.5268899\ttest: 5.6060174\tbest: 5.6057289 (1510)\ttotal: 3.73s\tremaining: 8m 9s\n",
      "1514:\tlearn: 3.5246344\ttest: 5.6062577\tbest: 5.6057289 (1510)\ttotal: 3.74s\tremaining: 8m 9s\n",
      "1515:\tlearn: 3.5242828\ttest: 5.6058625\tbest: 5.6057289 (1510)\ttotal: 3.74s\tremaining: 8m 9s\n",
      "1516:\tlearn: 3.5237944\ttest: 5.6054271\tbest: 5.6054271 (1516)\ttotal: 3.74s\tremaining: 8m 9s\n",
      "1517:\tlearn: 3.5233722\ttest: 5.6052313\tbest: 5.6052313 (1517)\ttotal: 3.74s\tremaining: 8m 9s\n",
      "1518:\tlearn: 3.5227538\ttest: 5.6053693\tbest: 5.6052313 (1517)\ttotal: 3.75s\tremaining: 8m 9s\n",
      "1519:\tlearn: 3.5225115\ttest: 5.6055793\tbest: 5.6052313 (1517)\ttotal: 3.75s\tremaining: 8m 9s\n",
      "1520:\tlearn: 3.5223259\ttest: 5.6055476\tbest: 5.6052313 (1517)\ttotal: 3.75s\tremaining: 8m 9s\n",
      "1521:\tlearn: 3.5217798\ttest: 5.6052977\tbest: 5.6052313 (1517)\ttotal: 3.75s\tremaining: 8m 9s\n",
      "1522:\tlearn: 3.5211313\ttest: 5.6046310\tbest: 5.6046310 (1522)\ttotal: 3.76s\tremaining: 8m 9s\n",
      "1523:\tlearn: 3.5210999\ttest: 5.6045319\tbest: 5.6045319 (1523)\ttotal: 3.76s\tremaining: 8m 9s\n",
      "1524:\tlearn: 3.5206672\ttest: 5.6043794\tbest: 5.6043794 (1524)\ttotal: 3.76s\tremaining: 8m 9s\n",
      "1525:\tlearn: 3.5200435\ttest: 5.6042339\tbest: 5.6042339 (1525)\ttotal: 3.77s\tremaining: 8m 9s\n",
      "1526:\tlearn: 3.5195677\ttest: 5.6044345\tbest: 5.6042339 (1525)\ttotal: 3.77s\tremaining: 8m 10s\n",
      "1527:\tlearn: 3.5186980\ttest: 5.6043686\tbest: 5.6042339 (1525)\ttotal: 3.77s\tremaining: 8m 10s\n",
      "1528:\tlearn: 3.5175138\ttest: 5.6019290\tbest: 5.6019290 (1528)\ttotal: 3.78s\tremaining: 8m 10s\n",
      "1529:\tlearn: 3.5171248\ttest: 5.6018052\tbest: 5.6018052 (1529)\ttotal: 3.78s\tremaining: 8m 10s\n",
      "1530:\tlearn: 3.5169275\ttest: 5.6019063\tbest: 5.6018052 (1529)\ttotal: 3.78s\tremaining: 8m 10s\n",
      "1531:\tlearn: 3.5149222\ttest: 5.6011605\tbest: 5.6011605 (1531)\ttotal: 3.79s\tremaining: 8m 10s\n",
      "1532:\tlearn: 3.5132421\ttest: 5.6023918\tbest: 5.6011605 (1531)\ttotal: 3.79s\tremaining: 8m 10s\n",
      "1533:\tlearn: 3.5120878\ttest: 5.6007485\tbest: 5.6007485 (1533)\ttotal: 3.79s\tremaining: 8m 10s\n",
      "1534:\tlearn: 3.5115172\ttest: 5.5998648\tbest: 5.5998648 (1534)\ttotal: 3.79s\tremaining: 8m 10s\n",
      "1535:\tlearn: 3.5114237\ttest: 5.5998132\tbest: 5.5998132 (1535)\ttotal: 3.8s\tremaining: 8m 10s\n",
      "1536:\tlearn: 3.5111450\ttest: 5.5994845\tbest: 5.5994845 (1536)\ttotal: 3.8s\tremaining: 8m 10s\n",
      "1537:\tlearn: 3.5108525\ttest: 5.5990777\tbest: 5.5990777 (1537)\ttotal: 3.8s\tremaining: 8m 10s\n",
      "1538:\tlearn: 3.5095936\ttest: 5.5985749\tbest: 5.5985749 (1538)\ttotal: 3.81s\tremaining: 8m 10s\n",
      "1539:\tlearn: 3.5073114\ttest: 5.5988895\tbest: 5.5985749 (1538)\ttotal: 3.81s\tremaining: 8m 10s\n",
      "1540:\tlearn: 3.5067703\ttest: 5.5985553\tbest: 5.5985553 (1540)\ttotal: 3.81s\tremaining: 8m 10s\n",
      "1541:\tlearn: 3.5056243\ttest: 5.5985465\tbest: 5.5985465 (1541)\ttotal: 3.81s\tremaining: 8m 10s\n",
      "1542:\tlearn: 3.5040096\ttest: 5.5973632\tbest: 5.5973632 (1542)\ttotal: 3.81s\tremaining: 8m 10s\n",
      "1543:\tlearn: 3.5033128\ttest: 5.5968361\tbest: 5.5968361 (1543)\ttotal: 3.82s\tremaining: 8m 10s\n",
      "1544:\tlearn: 3.5028503\ttest: 5.5964662\tbest: 5.5964662 (1544)\ttotal: 3.82s\tremaining: 8m 10s\n",
      "1545:\tlearn: 3.5023305\ttest: 5.5967963\tbest: 5.5964662 (1544)\ttotal: 3.82s\tremaining: 8m 10s\n",
      "1546:\tlearn: 3.5005725\ttest: 5.5953079\tbest: 5.5953079 (1546)\ttotal: 3.82s\tremaining: 8m 10s\n",
      "1547:\tlearn: 3.4993692\ttest: 5.5957396\tbest: 5.5953079 (1546)\ttotal: 3.83s\tremaining: 8m 10s\n",
      "1548:\tlearn: 3.4987526\ttest: 5.5958860\tbest: 5.5953079 (1546)\ttotal: 3.83s\tremaining: 8m 10s\n",
      "1549:\tlearn: 3.4973679\ttest: 5.5958754\tbest: 5.5953079 (1546)\ttotal: 3.83s\tremaining: 8m 10s\n",
      "1550:\tlearn: 3.4968142\ttest: 5.5954631\tbest: 5.5953079 (1546)\ttotal: 3.83s\tremaining: 8m 10s\n",
      "1551:\tlearn: 3.4966304\ttest: 5.5957034\tbest: 5.5953079 (1546)\ttotal: 3.84s\tremaining: 8m 10s\n",
      "1552:\tlearn: 3.4962500\ttest: 5.5957874\tbest: 5.5953079 (1546)\ttotal: 3.84s\tremaining: 8m 10s\n",
      "1553:\tlearn: 3.4936264\ttest: 5.5944468\tbest: 5.5944468 (1553)\ttotal: 3.84s\tremaining: 8m 10s\n",
      "1554:\tlearn: 3.4935485\ttest: 5.5943584\tbest: 5.5943584 (1554)\ttotal: 3.84s\tremaining: 8m 10s\n",
      "1555:\tlearn: 3.4932138\ttest: 5.5941162\tbest: 5.5941162 (1555)\ttotal: 3.85s\tremaining: 8m 10s\n",
      "1556:\tlearn: 3.4919726\ttest: 5.5948283\tbest: 5.5941162 (1555)\ttotal: 3.85s\tremaining: 8m 10s\n",
      "1557:\tlearn: 3.4917213\ttest: 5.5945575\tbest: 5.5941162 (1555)\ttotal: 3.85s\tremaining: 8m 10s\n",
      "1558:\tlearn: 3.4909220\ttest: 5.5939157\tbest: 5.5939157 (1558)\ttotal: 3.85s\tremaining: 8m 10s\n",
      "1559:\tlearn: 3.4903226\ttest: 5.5938275\tbest: 5.5938275 (1559)\ttotal: 3.85s\tremaining: 8m 10s\n",
      "1560:\tlearn: 3.4900753\ttest: 5.5937220\tbest: 5.5937220 (1560)\ttotal: 3.86s\tremaining: 8m 10s\n",
      "1561:\tlearn: 3.4873077\ttest: 5.5927893\tbest: 5.5927893 (1561)\ttotal: 3.86s\tremaining: 8m 10s\n",
      "1562:\tlearn: 3.4869989\ttest: 5.5927738\tbest: 5.5927738 (1562)\ttotal: 3.86s\tremaining: 8m 10s\n",
      "1563:\tlearn: 3.4854189\ttest: 5.5931139\tbest: 5.5927738 (1562)\ttotal: 3.87s\tremaining: 8m 10s\n",
      "1564:\tlearn: 3.4842740\ttest: 5.5931836\tbest: 5.5927738 (1562)\ttotal: 3.87s\tremaining: 8m 10s\n",
      "1565:\tlearn: 3.4833024\ttest: 5.5923600\tbest: 5.5923600 (1565)\ttotal: 3.87s\tremaining: 8m 10s\n",
      "1566:\tlearn: 3.4825067\ttest: 5.5923673\tbest: 5.5923600 (1565)\ttotal: 3.87s\tremaining: 8m 10s\n",
      "1567:\tlearn: 3.4824300\ttest: 5.5923942\tbest: 5.5923600 (1565)\ttotal: 3.87s\tremaining: 8m 10s\n",
      "1568:\tlearn: 3.4811006\ttest: 5.5908952\tbest: 5.5908952 (1568)\ttotal: 3.88s\tremaining: 8m 10s\n",
      "1569:\tlearn: 3.4807419\ttest: 5.5909571\tbest: 5.5908952 (1568)\ttotal: 3.88s\tremaining: 8m 10s\n",
      "1570:\tlearn: 3.4787434\ttest: 5.5891306\tbest: 5.5891306 (1570)\ttotal: 3.88s\tremaining: 8m 10s\n",
      "1571:\tlearn: 3.4779631\ttest: 5.5888571\tbest: 5.5888571 (1571)\ttotal: 3.88s\tremaining: 8m 10s\n",
      "1572:\tlearn: 3.4771490\ttest: 5.5889825\tbest: 5.5888571 (1571)\ttotal: 3.89s\tremaining: 8m 10s\n",
      "1573:\tlearn: 3.4759728\ttest: 5.5883440\tbest: 5.5883440 (1573)\ttotal: 3.89s\tremaining: 8m 10s\n",
      "1574:\tlearn: 3.4753600\ttest: 5.5878073\tbest: 5.5878073 (1574)\ttotal: 3.89s\tremaining: 8m 10s\n",
      "1575:\tlearn: 3.4748512\ttest: 5.5870795\tbest: 5.5870795 (1575)\ttotal: 3.9s\tremaining: 8m 10s\n",
      "1576:\tlearn: 3.4744562\ttest: 5.5868526\tbest: 5.5868526 (1576)\ttotal: 3.9s\tremaining: 8m 10s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9447960d60f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m test_pool = Pool(X_test,\n\u001b[0;32m      4\u001b[0m                  Y_test) \n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Verbose'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4478\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4479\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4480\u001b[1;33m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1730\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1733\u001b[0m             )\n\u001b[0;32m   1734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_pool = Pool(X_train,\n",
    "                  Y_train)\n",
    "test_pool = Pool(X_test,\n",
    "                 Y_test) \n",
    "best_model.fit(train_pool, eval_set=(test_pool), logging_level='Verbose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/simple.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0bd645510ac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/simple.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/simple.xlsx'"
     ]
    }
   ],
   "source": [
    "simple=pd.read_excel('data/simple.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
